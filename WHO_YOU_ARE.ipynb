{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannymeyer/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from pandas import read_csv\n",
    "from Audio.Components.MidiPlayer import MidiPlayer\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from NN.networks.simple_model import create_model\n",
    "\n",
    "from Audio.Components.helpers.prepare_arrays import get_categorized_variables\n",
    "from Audio.Components.helpers.save_model import save_model\n",
    "from Audio.Components.helpers.make_encoded_prediction import make_encoded_prediction\n",
    "from Audio.Components.helpers.create_categorical_indicies import create_category_indicies, create_lookup_indicies\n",
    "from Audio.Components.helpers.generate_phrases import generate_phrases\n",
    "from Audio.Components.helpers.decode_predictions import decode_predictions\n",
    "from Audio.Components.helpers.play_generated_phrase import play_generated_phrase\n",
    "from Audio.Components.helpers.vectorize_phrases import vectorize_phrases\n",
    "from Audio.Components.helpers.logger import logger\n",
    "from Helpers.map_midi_to_note_number import map_midi_to_note_number\n",
    "from Helpers.map_midi_to_interval import map_midi_to_interval\n",
    "import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IAC Driver Bus 1', 'IAC Driver LocalMidi']\n"
     ]
    }
   ],
   "source": [
    "player = MidiPlayer()\n",
    "dropout = 0.5\n",
    "n_time_steps = constants.n_time_steps\n",
    "semi_redundancy_step = constants.semi_redundancy_step\n",
    "lstm_size = 10\n",
    "lr = constants.lr\n",
    "epochs = constants.epochs\n",
    "batch_size = constants.batch_size\n",
    "n_to_generate = constants.n_to_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            PREPROCESSING\n",
      "          **********************************\n",
      "corpus length: 808\n"
     ]
    }
   ],
   "source": [
    "logger('PREPROCESSING')\n",
    "corpus = read_csv('Audio/data/input.csv', header=1)\n",
    "print('corpus length:', len(corpus))\n",
    "notes_corpus = corpus.values[:, 0]\n",
    "note_name_corpus = corpus.values[:, 1]\n",
    "interval_corpus = corpus.values[:, 2]\n",
    "length_corpus = corpus.values[:, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorized_variables = get_categorized_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup_indicies = create_lookup_indicies(categorized_variables)\n",
    "\n",
    "note_phrases, next_note = generate_phrases(notes_corpus, n_time_steps, semi_redundancy_step)\n",
    "note_name_phrases, next_note_name = generate_phrases(note_name_corpus, n_time_steps, semi_redundancy_step)\n",
    "interval_phrases, next_interval = generate_phrases(interval_corpus, n_time_steps, semi_redundancy_step)\n",
    "length_phrases, next_length = generate_phrases(length_corpus, n_time_steps, semi_redundancy_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778, 30, 128) note_x.shape\n",
      "(778, 30, 141) length_x.shape\n",
      "(778, 30, 49) interval_x.shape\n",
      "(778, 30, 13) note_name_x.shape\n",
      "(778, 128) note_y.shape\n",
      "(778, 141) length_y.shape\n",
      "(778, 49) interval_y.shape\n",
      "(778, 13) note_name_y.shape\n"
     ]
    }
   ],
   "source": [
    "note_x, note_y = vectorize_phrases(\n",
    "    phrases=note_phrases,\n",
    "    n_categories=len(categorized_variables['note_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_index'],\n",
    "    next_lookup_index=next_note\n",
    "    )\n",
    "\n",
    "interval_x, interval_y = vectorize_phrases(\n",
    "    phrases=interval_phrases,\n",
    "    n_categories=len(categorized_variables['interval_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['interval_index'],\n",
    "    next_lookup_index=next_interval\n",
    ")\n",
    "\n",
    "note_name_x, note_name_y = vectorize_phrases(\n",
    "    phrases=note_name_phrases,\n",
    "    n_categories=len(categorized_variables['note_name_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_name_index'],\n",
    "    next_lookup_index=next_note_name\n",
    ")\n",
    "\n",
    "length_x, length_y = vectorize_phrases(\n",
    "    phrases=length_phrases,\n",
    "    n_categories=len(categorized_variables['length_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['length_index'],\n",
    "    next_lookup_index=next_length\n",
    ")\n",
    "\n",
    "print(note_x.shape, 'note_x.shape')\n",
    "print(length_x.shape, 'length_x.shape')\n",
    "print(interval_x.shape, 'interval_x.shape')\n",
    "print(note_name_x.shape, 'note_name_x.shape')\n",
    "print(note_y.shape, 'note_y.shape')\n",
    "print(length_y.shape, 'length_y.shape')\n",
    "print(interval_y.shape, 'interval_y.shape')\n",
    "print(note_name_y.shape, 'note_name_y.shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    categorized_variables=categorized_variables,\n",
    "    lstm_size=lstm_size,\n",
    "    lr=0.001,\n",
    "    n_time_steps=n_time_steps,\n",
    "    dropout=dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "note_input (InputLayer)         (None, 30, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "note_name_input (InputLayer)    (None, 30, 13)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "interval_input (InputLayer)     (None, 30, 49)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "length_input (InputLayer)       (None, 30, 141)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 331)      0           note_input[0][0]                 \n",
      "                                                                 note_name_input[0][0]            \n",
      "                                                                 interval_input[0][0]             \n",
      "                                                                 length_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 20)       27360       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 20)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 20)           2480        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "note_output (Dense)             (None, 128)          2688        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "length_output (Dense)           (None, 141)          2961        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 35,489\n",
      "Trainable params: 35,489\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 709.91 410.00\" width=\"710pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 705.9106,-406 705.9106,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 103670612992 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>103670612992</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 145.4658,-401.5 145.4658,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"72.7329\" y=\"-379.3\">note_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 103670614672 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>103670614672</title>\n",
       "<polygon fill=\"none\" points=\"263.4136,-292.5 263.4136,-328.5 436.0522,-328.5 436.0522,-292.5 263.4136,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-306.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 103670612992&#45;&gt;103670614672 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>103670612992-&gt;103670614672</title>\n",
       "<path d=\"M141.2048,-365.4551C180.6579,-355.0577 230.399,-341.949 271.4047,-331.1424\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"272.3108,-334.5232 281.0887,-328.5904 270.5269,-327.7544 272.3108,-334.5232\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 103670615064 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>103670615064</title>\n",
       "<polygon fill=\"none\" points=\"163.3413,-365.5 163.3413,-401.5 346.1245,-401.5 346.1245,-365.5 163.3413,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.7329\" y=\"-379.3\">note_name_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 103670615064&#45;&gt;103670614672 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>103670615064-&gt;103670614672</title>\n",
       "<path d=\"M278.2161,-365.4551C290.2054,-356.2422 304.965,-344.9006 317.956,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"320.3939,-337.4587 326.1907,-328.5904 316.1287,-331.9082 320.3939,-337.4587\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4709170368 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4709170368</title>\n",
       "<polygon fill=\"none\" points=\"363.6724,-365.5 363.6724,-401.5 527.7935,-401.5 527.7935,-365.5 363.6724,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445.7329\" y=\"-379.3\">interval_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4709170368&#45;&gt;103670614672 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4709170368-&gt;103670614672</title>\n",
       "<path d=\"M422.0026,-365.4551C409.887,-356.2422 394.9721,-344.9006 381.8443,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"383.6016,-331.8573 373.523,-328.5904 379.3645,-337.4293 383.6016,-331.8573\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 103670615400 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>103670615400</title>\n",
       "<polygon fill=\"none\" points=\"545.5552,-365.5 545.5552,-401.5 701.9106,-401.5 701.9106,-365.5 545.5552,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.7329\" y=\"-379.3\">length_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 103670615400&#45;&gt;103670614672 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>103670615400-&gt;103670614672</title>\n",
       "<path d=\"M556.0026,-365.4551C517.0592,-355.0796 467.982,-342.0043 427.4696,-331.2109\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"428.1977,-327.7828 417.6337,-328.5904 426.3956,-334.5469 428.1977,-327.7828\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 103670641720 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>103670641720</title>\n",
       "<polygon fill=\"none\" points=\"212.0654,-219.5 212.0654,-255.5 487.4004,-255.5 487.4004,-219.5 212.0654,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-233.3\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 103670614672&#45;&gt;103670641720 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>103670614672-&gt;103670641720</title>\n",
       "<path d=\"M349.7329,-292.4551C349.7329,-284.3828 349.7329,-274.6764 349.7329,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-265.5903 349.7329,-255.5904 346.233,-265.5904 353.233,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 103670642112 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>103670642112</title>\n",
       "<polygon fill=\"none\" points=\"285.9312,-146.5 285.9312,-182.5 413.5347,-182.5 413.5347,-146.5 285.9312,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-160.3\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 103670641720&#45;&gt;103670642112 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>103670641720-&gt;103670642112</title>\n",
       "<path d=\"M349.7329,-219.4551C349.7329,-211.3828 349.7329,-201.6764 349.7329,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-192.5903 349.7329,-182.5904 346.233,-192.5904 353.233,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 103684561776 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>103684561776</title>\n",
       "<polygon fill=\"none\" points=\"212.0654,-73.5 212.0654,-109.5 487.4004,-109.5 487.4004,-73.5 212.0654,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-87.3\">bidirectional_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 103670642112&#45;&gt;103684561776 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>103670642112-&gt;103684561776</title>\n",
       "<path d=\"M349.7329,-146.4551C349.7329,-138.3828 349.7329,-128.6764 349.7329,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-119.5903 349.7329,-109.5904 346.233,-119.5904 353.233,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 103684667544 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>103684667544</title>\n",
       "<polygon fill=\"none\" points=\"213.1035,-.5 213.1035,-36.5 338.3623,-36.5 338.3623,-.5 213.1035,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.7329\" y=\"-14.3\">note_output: Dense</text>\n",
       "</g>\n",
       "<!-- 103684561776&#45;&gt;103684667544 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>103684561776-&gt;103684667544</title>\n",
       "<path d=\"M331.4408,-73.4551C322.3685,-64.5054 311.26,-53.547 301.3561,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"303.6481,-41.1215 294.0711,-36.5904 298.7321,-46.1049 303.6481,-41.1215\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 103688182808 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>103688182808</title>\n",
       "<polygon fill=\"none\" points=\"356.6587,-.5 356.6587,-36.5 492.8071,-36.5 492.8071,-.5 356.6587,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.7329\" y=\"-14.3\">length_output: Dense</text>\n",
       "</g>\n",
       "<!-- 103684561776&#45;&gt;103688182808 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>103684561776-&gt;103688182808</title>\n",
       "<path d=\"M368.2722,-73.4551C377.4671,-64.5054 388.7258,-53.547 398.7634,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"401.4221,-46.0734 406.1469,-36.5904 396.5397,-41.0572 401.4221,-46.0734\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.1\n",
    "\tdrop = 0.6\n",
    "\tepochs_drop = 25\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listen_callback(epoch, logs):\n",
    "    if epoch % 100 == 0 and epoch > -1: \n",
    "    # if epoch < -2:\n",
    "        print('----- Generating melody after Epoch: %d' % epoch)\n",
    "        \n",
    "        start_index = random.randint(0, 7000)\n",
    "        for diversity in [0.5]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            current_note_phrase = notes_corpus[start_index: start_index + n_time_steps]\n",
    "            current_interval_phrase = interval_corpus[start_index: start_index + n_time_steps]\n",
    "            current_note_name_phrase = note_name_corpus[start_index: start_index + n_time_steps]\n",
    "            current_length_phrase = length_corpus[start_index: start_index + n_time_steps]\n",
    "\n",
    "            phrases = {\n",
    "                'note_phrase': current_note_phrase, \n",
    "                'length_phrase': current_length_phrase,\n",
    "                'interval_phrase': current_interval_phrase,\n",
    "                'note_name_phrase': current_note_name_phrase,\n",
    "            }\n",
    "\n",
    "            generated_notes = []\n",
    "            generated_lengths = []\n",
    "            generated_notes.extend(current_note_phrase)\n",
    "            generated_lengths.extend(current_length_phrase)\n",
    "\n",
    "            # model, phrases,categorized_variables, lookup_indicies, n_time_steps, diversity, n_to_generate\n",
    "            for step in range(40):\n",
    "                encoded_prediction = make_encoded_prediction(\n",
    "                    model=model,\n",
    "                    phrases=phrases,\n",
    "                    categorized_variables=categorized_variables,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    n_time_steps=n_time_steps\n",
    "                )\n",
    "\n",
    "                predictions = decode_predictions(\n",
    "                    encoded_prediction=encoded_prediction,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    temperature=diversity\n",
    "                )\n",
    "\n",
    "                generated_notes.append(predictions['note_prediction']) \n",
    "                generated_lengths.append(predictions['length_prediction']) \n",
    "\n",
    "\n",
    "                last = generated_notes[0]\n",
    "                phrases['note_phrase'] = np.append(phrases['note_phrase'][1:], predictions['note_prediction'])\n",
    "                phrases['interval_phrase'] = map_midi_to_interval(phrases['note_phrase'], last)\n",
    "                phrases['note_name_phrase'] = map_midi_to_note_number(phrases['note_phrase'])\n",
    "                phrases['length_phrase'] = np.append(phrases['length_phrase'][1:], predictions['length_prediction'])\n",
    "\n",
    "                print\n",
    "                \n",
    "            play_generated_phrase(\n",
    "                generated_notes=generated_notes[10:],\n",
    "                generated_lengths=generated_lengths[10:],\n",
    "                player=player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(datetime.datetime.now()), histogram_freq=0, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listen_callback = LambdaCallback(on_epoch_end=listen_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            TRAINING\n",
      "          **********************************\n",
      "Epoch 1/300\n",
      "768/778 [============================>.] - ETA: 0s - loss: 4.1226 - note_output_loss: 2.6509 - length_output_loss: 2.9434----- Generating melody after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "63.0 | 0.46\n",
      "68.0 | 0.46\n",
      "70.0 | 0.51\n",
      "63.0 | 0.42\n",
      "66.0 | 0.46\n",
      "69.0 | 0.37\n",
      "71.0 | 0.28\n",
      "72.0 | 0.37\n",
      "64.0 | 0.79\n",
      "0 | 2.5\n",
      "72.0 | 0.37\n",
      "70.0 | 0.23\n",
      "68.0 | 0.28\n",
      "67.0 | 0.33\n",
      "66.0 | 0.37\n",
      "63.0 | 0.33\n",
      "59.0 | 0.28\n",
      "58.0 | 0.42\n",
      "60.0 | 0.37\n",
      "61.0 | 0.42\n",
      "0 | 0.51\n",
      "66 | 0.56\n",
      "68 | 0.37\n",
      "69 | 0.42\n",
      "0 | 0.42\n",
      "0 | 0.37\n",
      "0 | 0.51\n",
      "68 | 0.56\n",
      "67 | 0.56\n",
      "65 | 0.23\n",
      "60 | 0.28\n",
      "62 | 0.28\n",
      "70 | 0.33\n",
      "55 | 0.33\n",
      "59 | 0.33\n",
      "60 | 0.33\n",
      "62 | 0.23\n",
      "62 | 0.33\n",
      "65 | 0.23\n",
      "62 | 0.23\n",
      "65 | 0.28\n",
      "67 | 0.51\n",
      "70 | 0.28\n",
      "60 | 0.28\n",
      "67 | 0.28\n",
      "60 | 0.28\n",
      "69 | 0.28\n",
      "69 | 0.28\n",
      "68 | 0.28\n",
      "69 | 0.19\n",
      "0 | 0.28\n",
      "69 | 0.33\n",
      "67 | 0.28\n",
      "67 | 0.28\n",
      "71 | 0.28\n",
      "69 | 0.28\n",
      "0 | 0.28\n",
      "63 | 0.28\n",
      "50 | 0.28\n",
      "75 | 0.28\n",
      "778/778 [==============================] - 25s 32ms/step - loss: 4.1217 - note_output_loss: 2.6450 - length_output_loss: 2.9535\n",
      "Epoch 2/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.1447 - note_output_loss: 2.6552 - length_output_loss: 2.9791\n",
      "Epoch 3/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0967 - note_output_loss: 2.6216 - length_output_loss: 2.9502\n",
      "Epoch 4/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.1070 - note_output_loss: 2.6256 - length_output_loss: 2.9629\n",
      "Epoch 5/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.1098 - note_output_loss: 2.6355 - length_output_loss: 2.9486\n",
      "Epoch 6/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.1069 - note_output_loss: 2.6341 - length_output_loss: 2.9457\n",
      "Epoch 7/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.1117 - note_output_loss: 2.6346 - length_output_loss: 2.9543\n",
      "Epoch 8/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0821 - note_output_loss: 2.6132 - length_output_loss: 2.9378\n",
      "Epoch 9/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0901 - note_output_loss: 2.6191 - length_output_loss: 2.9420\n",
      "Epoch 10/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0874 - note_output_loss: 2.6135 - length_output_loss: 2.9479\n",
      "Epoch 11/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0996 - note_output_loss: 2.6249 - length_output_loss: 2.9495\n",
      "Epoch 12/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0796 - note_output_loss: 2.6082 - length_output_loss: 2.9428\n",
      "Epoch 13/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0964 - note_output_loss: 2.6203 - length_output_loss: 2.9522\n",
      "Epoch 14/300\n",
      "778/778 [==============================] - 1s 989us/step - loss: 4.0771 - note_output_loss: 2.6072 - length_output_loss: 2.9397\n",
      "Epoch 15/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0815 - note_output_loss: 2.6100 - length_output_loss: 2.9431\n",
      "Epoch 16/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0740 - note_output_loss: 2.6043 - length_output_loss: 2.9392\n",
      "Epoch 17/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0764 - note_output_loss: 2.6026 - length_output_loss: 2.9477\n",
      "Epoch 18/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.1033 - note_output_loss: 2.6230 - length_output_loss: 2.9605\n",
      "Epoch 19/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0641 - note_output_loss: 2.5955 - length_output_loss: 2.9372\n",
      "Epoch 20/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0682 - note_output_loss: 2.6008 - length_output_loss: 2.9346\n",
      "Epoch 21/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0870 - note_output_loss: 2.6132 - length_output_loss: 2.9475\n",
      "Epoch 22/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0792 - note_output_loss: 2.6102 - length_output_loss: 2.9380\n",
      "Epoch 23/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0560 - note_output_loss: 2.5911 - length_output_loss: 2.9297\n",
      "Epoch 24/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0706 - note_output_loss: 2.5957 - length_output_loss: 2.9498\n",
      "Epoch 25/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0651 - note_output_loss: 2.6018 - length_output_loss: 2.9267\n",
      "Epoch 26/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0853 - note_output_loss: 2.6123 - length_output_loss: 2.9459\n",
      "Epoch 27/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0512 - note_output_loss: 2.5831 - length_output_loss: 2.9362\n",
      "Epoch 28/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0765 - note_output_loss: 2.6052 - length_output_loss: 2.9426\n",
      "Epoch 29/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0615 - note_output_loss: 2.5931 - length_output_loss: 2.9367\n",
      "Epoch 30/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0551 - note_output_loss: 2.5914 - length_output_loss: 2.9272\n",
      "Epoch 31/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0570 - note_output_loss: 2.5882 - length_output_loss: 2.9376\n",
      "Epoch 32/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0500 - note_output_loss: 2.5834 - length_output_loss: 2.9333\n",
      "Epoch 33/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0741 - note_output_loss: 2.6058 - length_output_loss: 2.9367\n",
      "Epoch 34/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0405 - note_output_loss: 2.5774 - length_output_loss: 2.9261\n",
      "Epoch 35/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0670 - note_output_loss: 2.5981 - length_output_loss: 2.9377\n",
      "Epoch 36/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0434 - note_output_loss: 2.5802 - length_output_loss: 2.9264\n",
      "Epoch 37/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0533 - note_output_loss: 2.5878 - length_output_loss: 2.9311\n",
      "Epoch 38/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0483 - note_output_loss: 2.5785 - length_output_loss: 2.9397\n",
      "Epoch 39/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0693 - note_output_loss: 2.6058 - length_output_loss: 2.9270\n",
      "Epoch 40/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 4.0486 - note_output_loss: 2.5856 - length_output_loss: 2.9259\n",
      "Epoch 41/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0617 - note_output_loss: 2.5849 - length_output_loss: 2.9537\n",
      "Epoch 42/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0320 - note_output_loss: 2.5678 - length_output_loss: 2.9284\n",
      "Epoch 43/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0308 - note_output_loss: 2.5647 - length_output_loss: 2.9322\n",
      "Epoch 44/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0307 - note_output_loss: 2.5645 - length_output_loss: 2.9324\n",
      "Epoch 45/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0380 - note_output_loss: 2.5730 - length_output_loss: 2.9299\n",
      "Epoch 46/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0556 - note_output_loss: 2.5832 - length_output_loss: 2.9447\n",
      "Epoch 47/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0396 - note_output_loss: 2.5720 - length_output_loss: 2.9351\n",
      "Epoch 48/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0175 - note_output_loss: 2.5515 - length_output_loss: 2.9320\n",
      "Epoch 49/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0103 - note_output_loss: 2.5490 - length_output_loss: 2.9228\n",
      "Epoch 50/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0198 - note_output_loss: 2.5550 - length_output_loss: 2.9295\n",
      "Epoch 51/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0117 - note_output_loss: 2.5511 - length_output_loss: 2.9212\n",
      "Epoch 52/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0333 - note_output_loss: 2.5708 - length_output_loss: 2.9249\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0226 - note_output_loss: 2.5592 - length_output_loss: 2.9270\n",
      "Epoch 54/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0041 - note_output_loss: 2.5485 - length_output_loss: 2.9111\n",
      "Epoch 55/300\n",
      "778/778 [==============================] - 1s 967us/step - loss: 4.0128 - note_output_loss: 2.5505 - length_output_loss: 2.9247\n",
      "Epoch 56/300\n",
      "778/778 [==============================] - 1s 977us/step - loss: 4.0141 - note_output_loss: 2.5530 - length_output_loss: 2.9222\n",
      "Epoch 57/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0185 - note_output_loss: 2.5550 - length_output_loss: 2.9269\n",
      "Epoch 58/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0288 - note_output_loss: 2.5721 - length_output_loss: 2.9134\n",
      "Epoch 59/300\n",
      "778/778 [==============================] - 1s 997us/step - loss: 4.0180 - note_output_loss: 2.5554 - length_output_loss: 2.9253\n",
      "Epoch 60/300\n",
      "778/778 [==============================] - 1s 981us/step - loss: 4.0136 - note_output_loss: 2.5538 - length_output_loss: 2.9197\n",
      "Epoch 61/300\n",
      "778/778 [==============================] - 1s 977us/step - loss: 4.0118 - note_output_loss: 2.5515 - length_output_loss: 2.9206\n",
      "Epoch 62/300\n",
      "778/778 [==============================] - 1s 991us/step - loss: 4.0169 - note_output_loss: 2.5576 - length_output_loss: 2.9186\n",
      "Epoch 63/300\n",
      "778/778 [==============================] - 1s 979us/step - loss: 3.9950 - note_output_loss: 2.5414 - length_output_loss: 2.9072\n",
      "Epoch 64/300\n",
      "778/778 [==============================] - 1s 981us/step - loss: 4.0113 - note_output_loss: 2.5517 - length_output_loss: 2.9190\n",
      "Epoch 65/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0233 - note_output_loss: 2.5662 - length_output_loss: 2.9142\n",
      "Epoch 66/300\n",
      "778/778 [==============================] - 1s 976us/step - loss: 3.9999 - note_output_loss: 2.5398 - length_output_loss: 2.9202\n",
      "Epoch 67/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0217 - note_output_loss: 2.5512 - length_output_loss: 2.9409\n",
      "Epoch 68/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9876 - note_output_loss: 2.5358 - length_output_loss: 2.9035\n",
      "Epoch 69/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9836 - note_output_loss: 2.5308 - length_output_loss: 2.9056\n",
      "Epoch 70/300\n",
      "778/778 [==============================] - 1s 981us/step - loss: 4.0296 - note_output_loss: 2.5622 - length_output_loss: 2.9348\n",
      "Epoch 71/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 4.0093 - note_output_loss: 2.5529 - length_output_loss: 2.9127\n",
      "Epoch 72/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9765 - note_output_loss: 2.5182 - length_output_loss: 2.9165\n",
      "Epoch 73/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 4.0050 - note_output_loss: 2.5489 - length_output_loss: 2.9121\n",
      "Epoch 74/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.9865 - note_output_loss: 2.5346 - length_output_loss: 2.9037\n",
      "Epoch 75/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9735 - note_output_loss: 2.5172 - length_output_loss: 2.9125\n",
      "Epoch 76/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9840 - note_output_loss: 2.5250 - length_output_loss: 2.9181\n",
      "Epoch 77/300\n",
      "778/778 [==============================] - 1s 978us/step - loss: 3.9736 - note_output_loss: 2.5218 - length_output_loss: 2.9037\n",
      "Epoch 78/300\n",
      "778/778 [==============================] - 1s 934us/step - loss: 4.0049 - note_output_loss: 2.5436 - length_output_loss: 2.9226\n",
      "Epoch 79/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9790 - note_output_loss: 2.5278 - length_output_loss: 2.9026\n",
      "Epoch 80/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.9915 - note_output_loss: 2.5330 - length_output_loss: 2.9170\n",
      "Epoch 81/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9617 - note_output_loss: 2.5108 - length_output_loss: 2.9019\n",
      "Epoch 82/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9585 - note_output_loss: 2.5064 - length_output_loss: 2.9041\n",
      "Epoch 83/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9757 - note_output_loss: 2.5206 - length_output_loss: 2.9103\n",
      "Epoch 84/300\n",
      "778/778 [==============================] - 1s 998us/step - loss: 3.9753 - note_output_loss: 2.5213 - length_output_loss: 2.9079\n",
      "Epoch 85/300\n",
      "778/778 [==============================] - 1s 968us/step - loss: 3.9756 - note_output_loss: 2.5242 - length_output_loss: 2.9028\n",
      "Epoch 86/300\n",
      "778/778 [==============================] - 1s 932us/step - loss: 3.9740 - note_output_loss: 2.5186 - length_output_loss: 2.9107\n",
      "Epoch 87/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9729 - note_output_loss: 2.5205 - length_output_loss: 2.9049\n",
      "Epoch 88/300\n",
      "778/778 [==============================] - 1s 987us/step - loss: 3.9912 - note_output_loss: 2.5345 - length_output_loss: 2.9136\n",
      "Epoch 89/300\n",
      "778/778 [==============================] - 1s 928us/step - loss: 3.9579 - note_output_loss: 2.5128 - length_output_loss: 2.8902\n",
      "Epoch 90/300\n",
      "778/778 [==============================] - 1s 996us/step - loss: 3.9383 - note_output_loss: 2.4943 - length_output_loss: 2.8880\n",
      "Epoch 91/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9327 - note_output_loss: 2.4843 - length_output_loss: 2.8968\n",
      "Epoch 92/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9620 - note_output_loss: 2.5090 - length_output_loss: 2.9060\n",
      "Epoch 93/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.9647 - note_output_loss: 2.5112 - length_output_loss: 2.9069\n",
      "Epoch 94/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9652 - note_output_loss: 2.5140 - length_output_loss: 2.9025\n",
      "Epoch 95/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9520 - note_output_loss: 2.5002 - length_output_loss: 2.9036\n",
      "Epoch 96/300\n",
      "778/778 [==============================] - 1s 905us/step - loss: 3.9343 - note_output_loss: 2.4882 - length_output_loss: 2.8921\n",
      "Epoch 97/300\n",
      "778/778 [==============================] - 1s 907us/step - loss: 3.9622 - note_output_loss: 2.5040 - length_output_loss: 2.9165\n",
      "Epoch 98/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9383 - note_output_loss: 2.4922 - length_output_loss: 2.8923\n",
      "Epoch 99/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9664 - note_output_loss: 2.5133 - length_output_loss: 2.9062\n",
      "Epoch 100/300\n",
      "778/778 [==============================] - 1s 941us/step - loss: 3.9288 - note_output_loss: 2.4913 - length_output_loss: 2.8751\n",
      "Epoch 101/300\n",
      "768/778 [============================>.] - ETA: 0s - loss: 3.9462 - note_output_loss: 2.4996 - length_output_loss: 2.8931----- Generating melody after Epoch: 100\n",
      "----- diversity: 0.5\n",
      "47 | 0.33\n",
      "47 | 0.7\n",
      "45 | 0.28\n",
      "50 | 0.33\n",
      "46 | 0.33\n",
      "49 | 0.79\n",
      "55 | 0.19\n",
      "47 | 0.42\n",
      "49 | 0.33\n",
      "50 | 0.84\n",
      "46 | 0.28\n",
      "57 | 0.98\n",
      "47 | 0.23\n",
      "50 | 1.6\n",
      "47 | 0.32\n",
      "49 | 0.56\n",
      "46 | 0.37\n",
      "47 | 0.28\n",
      "48 | 1.4\n",
      "48 | 0.56\n",
      "67 | 0.19\n",
      "47 | 0.25\n",
      "46 | 0.74\n",
      "55 | 0.32\n",
      "48 | 4.5\n",
      "47 | 0.28\n",
      "71 | 0.33\n",
      "46 | 0.93\n",
      "59 | 0.42\n",
      "48 | 0.33\n",
      "778/778 [==============================] - 21s 27ms/step - loss: 3.9429 - note_output_loss: 2.4959 - length_output_loss: 2.8939\n",
      "Epoch 102/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9548 - note_output_loss: 2.5096 - length_output_loss: 2.8904\n",
      "Epoch 103/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9338 - note_output_loss: 2.4904 - length_output_loss: 2.8867\n",
      "Epoch 104/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9333 - note_output_loss: 2.4846 - length_output_loss: 2.8975\n",
      "Epoch 105/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9385 - note_output_loss: 2.4936 - length_output_loss: 2.8898\n",
      "Epoch 106/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9495 - note_output_loss: 2.4990 - length_output_loss: 2.9010\n",
      "Epoch 107/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9270 - note_output_loss: 2.4860 - length_output_loss: 2.8819\n",
      "Epoch 108/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9558 - note_output_loss: 2.5035 - length_output_loss: 2.9047\n",
      "Epoch 109/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9178 - note_output_loss: 2.4755 - length_output_loss: 2.8846\n",
      "Epoch 110/300\n",
      "778/778 [==============================] - 1s 954us/step - loss: 3.9713 - note_output_loss: 2.5182 - length_output_loss: 2.9062\n",
      "Epoch 111/300\n",
      "778/778 [==============================] - 1s 967us/step - loss: 3.9164 - note_output_loss: 2.4716 - length_output_loss: 2.8897\n",
      "Epoch 112/300\n",
      "778/778 [==============================] - 1s 974us/step - loss: 3.9167 - note_output_loss: 2.4674 - length_output_loss: 2.8986\n",
      "Epoch 113/300\n",
      "778/778 [==============================] - 1s 955us/step - loss: 3.9562 - note_output_loss: 2.5163 - length_output_loss: 2.8799\n",
      "Epoch 114/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9130 - note_output_loss: 2.4696 - length_output_loss: 2.8869\n",
      "Epoch 115/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9201 - note_output_loss: 2.4828 - length_output_loss: 2.8746\n",
      "Epoch 116/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9147 - note_output_loss: 2.4740 - length_output_loss: 2.8813\n",
      "Epoch 117/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9306 - note_output_loss: 2.4862 - length_output_loss: 2.8888\n",
      "Epoch 118/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9208 - note_output_loss: 2.4826 - length_output_loss: 2.8763\n",
      "Epoch 119/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9252 - note_output_loss: 2.4804 - length_output_loss: 2.8896\n",
      "Epoch 120/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9007 - note_output_loss: 2.4577 - length_output_loss: 2.8859\n",
      "Epoch 121/300\n",
      "778/778 [==============================] - 1s 1000us/step - loss: 3.9209 - note_output_loss: 2.4794 - length_output_loss: 2.8829\n",
      "Epoch 122/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9423 - note_output_loss: 2.4979 - length_output_loss: 2.8889\n",
      "Epoch 123/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9302 - note_output_loss: 2.4885 - length_output_loss: 2.8834\n",
      "Epoch 124/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.9298 - note_output_loss: 2.4881 - length_output_loss: 2.8834\n",
      "Epoch 125/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8834 - note_output_loss: 2.4463 - length_output_loss: 2.8742\n",
      "Epoch 126/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9001 - note_output_loss: 2.4598 - length_output_loss: 2.8807\n",
      "Epoch 127/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8935 - note_output_loss: 2.4509 - length_output_loss: 2.8852\n",
      "Epoch 128/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8955 - note_output_loss: 2.4563 - length_output_loss: 2.8785\n",
      "Epoch 129/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8914 - note_output_loss: 2.4525 - length_output_loss: 2.8777\n",
      "Epoch 130/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8789 - note_output_loss: 2.4408 - length_output_loss: 2.8763\n",
      "Epoch 131/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9493 - note_output_loss: 2.5005 - length_output_loss: 2.8976\n",
      "Epoch 132/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9074 - note_output_loss: 2.4715 - length_output_loss: 2.8719\n",
      "Epoch 133/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9155 - note_output_loss: 2.4716 - length_output_loss: 2.8879\n",
      "Epoch 134/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8921 - note_output_loss: 2.4544 - length_output_loss: 2.8752\n",
      "Epoch 135/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9056 - note_output_loss: 2.4634 - length_output_loss: 2.8845\n",
      "Epoch 136/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8714 - note_output_loss: 2.4358 - length_output_loss: 2.8711\n",
      "Epoch 137/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9029 - note_output_loss: 2.4607 - length_output_loss: 2.8845\n",
      "Epoch 138/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8956 - note_output_loss: 2.4535 - length_output_loss: 2.8843\n",
      "Epoch 139/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.9186 - note_output_loss: 2.4761 - length_output_loss: 2.8850\n",
      "Epoch 140/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.8797 - note_output_loss: 2.4427 - length_output_loss: 2.8742\n",
      "Epoch 141/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8975 - note_output_loss: 2.4593 - length_output_loss: 2.8764\n",
      "Epoch 142/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.9037 - note_output_loss: 2.4639 - length_output_loss: 2.8795\n",
      "Epoch 143/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8853 - note_output_loss: 2.4506 - length_output_loss: 2.8694\n",
      "Epoch 144/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8861 - note_output_loss: 2.4462 - length_output_loss: 2.8798\n",
      "Epoch 145/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8611 - note_output_loss: 2.4281 - length_output_loss: 2.8658\n",
      "Epoch 146/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8730 - note_output_loss: 2.4383 - length_output_loss: 2.8695\n",
      "Epoch 147/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8700 - note_output_loss: 2.4343 - length_output_loss: 2.8713\n",
      "Epoch 148/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8625 - note_output_loss: 2.4324 - length_output_loss: 2.8603\n",
      "Epoch 149/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8995 - note_output_loss: 2.4565 - length_output_loss: 2.8860\n",
      "Epoch 150/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8750 - note_output_loss: 2.4358 - length_output_loss: 2.8785\n",
      "Epoch 151/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8875 - note_output_loss: 2.4457 - length_output_loss: 2.8835\n",
      "Epoch 152/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8495 - note_output_loss: 2.4149 - length_output_loss: 2.8692\n",
      "Epoch 153/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8839 - note_output_loss: 2.4424 - length_output_loss: 2.8831\n",
      "Epoch 154/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8566 - note_output_loss: 2.4201 - length_output_loss: 2.8729\n",
      "Epoch 155/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8517 - note_output_loss: 2.4200 - length_output_loss: 2.8633\n",
      "Epoch 156/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8587 - note_output_loss: 2.4233 - length_output_loss: 2.8708\n",
      "Epoch 157/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8929 - note_output_loss: 2.4465 - length_output_loss: 2.8928\n",
      "Epoch 158/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8642 - note_output_loss: 2.4322 - length_output_loss: 2.8639\n",
      "Epoch 159/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8725 - note_output_loss: 2.4310 - length_output_loss: 2.8829\n",
      "Epoch 160/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8434 - note_output_loss: 2.4140 - length_output_loss: 2.8588\n",
      "Epoch 161/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.9028 - note_output_loss: 2.4594 - length_output_loss: 2.8869\n",
      "Epoch 162/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.9203 - note_output_loss: 2.4787 - length_output_loss: 2.8832\n",
      "Epoch 163/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.8262 - note_output_loss: 2.3965 - length_output_loss: 2.8593\n",
      "Epoch 164/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8573 - note_output_loss: 2.4252 - length_output_loss: 2.8642\n",
      "Epoch 165/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8351 - note_output_loss: 2.4007 - length_output_loss: 2.8688\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 1s 2ms/step - loss: 3.8634 - note_output_loss: 2.4276 - length_output_loss: 2.8716\n",
      "Epoch 167/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8389 - note_output_loss: 2.4074 - length_output_loss: 2.8631\n",
      "Epoch 168/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8527 - note_output_loss: 2.4219 - length_output_loss: 2.8616\n",
      "Epoch 169/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8608 - note_output_loss: 2.4333 - length_output_loss: 2.8551\n",
      "Epoch 170/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8442 - note_output_loss: 2.4136 - length_output_loss: 2.8612\n",
      "Epoch 171/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8541 - note_output_loss: 2.4281 - length_output_loss: 2.8521\n",
      "Epoch 172/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8237 - note_output_loss: 2.3972 - length_output_loss: 2.8531\n",
      "Epoch 173/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8492 - note_output_loss: 2.4270 - length_output_loss: 2.8444\n",
      "Epoch 174/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8362 - note_output_loss: 2.4059 - length_output_loss: 2.8606\n",
      "Epoch 175/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8225 - note_output_loss: 2.4015 - length_output_loss: 2.8421\n",
      "Epoch 176/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8266 - note_output_loss: 2.3989 - length_output_loss: 2.8555\n",
      "Epoch 177/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8317 - note_output_loss: 2.4002 - length_output_loss: 2.8630\n",
      "Epoch 178/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8493 - note_output_loss: 2.4125 - length_output_loss: 2.8736\n",
      "Epoch 179/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8224 - note_output_loss: 2.3974 - length_output_loss: 2.8500\n",
      "Epoch 180/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8341 - note_output_loss: 2.4039 - length_output_loss: 2.8604\n",
      "Epoch 181/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8590 - note_output_loss: 2.4171 - length_output_loss: 2.8836\n",
      "Epoch 182/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8365 - note_output_loss: 2.4109 - length_output_loss: 2.8513\n",
      "Epoch 183/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8085 - note_output_loss: 2.3817 - length_output_loss: 2.8536\n",
      "Epoch 184/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8326 - note_output_loss: 2.4014 - length_output_loss: 2.8624\n",
      "Epoch 185/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8021 - note_output_loss: 2.3803 - length_output_loss: 2.8436\n",
      "Epoch 186/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8494 - note_output_loss: 2.4128 - length_output_loss: 2.8733\n",
      "Epoch 187/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8165 - note_output_loss: 2.3884 - length_output_loss: 2.8562\n",
      "Epoch 188/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8430 - note_output_loss: 2.4102 - length_output_loss: 2.8657\n",
      "Epoch 189/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8186 - note_output_loss: 2.3944 - length_output_loss: 2.8484\n",
      "Epoch 190/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8135 - note_output_loss: 2.3858 - length_output_loss: 2.8554\n",
      "Epoch 191/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8246 - note_output_loss: 2.4061 - length_output_loss: 2.8370\n",
      "Epoch 192/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8011 - note_output_loss: 2.3780 - length_output_loss: 2.8462\n",
      "Epoch 193/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8024 - note_output_loss: 2.3798 - length_output_loss: 2.8452\n",
      "Epoch 194/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8103 - note_output_loss: 2.3911 - length_output_loss: 2.8385\n",
      "Epoch 195/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7928 - note_output_loss: 2.3676 - length_output_loss: 2.8504\n",
      "Epoch 196/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7966 - note_output_loss: 2.3762 - length_output_loss: 2.8408\n",
      "Epoch 197/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8195 - note_output_loss: 2.3948 - length_output_loss: 2.8493\n",
      "Epoch 198/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8333 - note_output_loss: 2.4118 - length_output_loss: 2.8430\n",
      "Epoch 199/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8145 - note_output_loss: 2.3898 - length_output_loss: 2.8494\n",
      "Epoch 200/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7980 - note_output_loss: 2.3782 - length_output_loss: 2.8395\n",
      "Epoch 201/300\n",
      "768/778 [============================>.] - ETA: 0s - loss: 3.8249 - note_output_loss: 2.3992 - length_output_loss: 2.8513----- Generating melody after Epoch: 200\n",
      "----- diversity: 0.5\n",
      "48 | 0.37\n",
      "46 | 4.3\n",
      "47 | 0.32\n",
      "71 | 0.33\n",
      "46 | 0.19\n",
      "75 | 0.14\n",
      "47 | 4.3\n",
      "48 | 0.33\n",
      "47 | 1.0\n",
      "47 | 0.43\n",
      "47 | 0.32\n",
      "71 | 0.23\n",
      "47 | 0.28\n",
      "46 | 0.23\n",
      "47 | 0.74\n",
      "46 | 0.93\n",
      "51 | 2.4\n",
      "50 | 0.14\n",
      "48 | 0.32\n",
      "50 | 0.65\n",
      "46 | 0.33\n",
      "46 | 0.33\n",
      "54 | 0.51\n",
      "50 | 1.3\n",
      "47 | 0.56\n",
      "48 | 0.33\n",
      "45 | 0.33\n",
      "46 | 0.46\n",
      "51 | 1.5\n",
      "63 | 1.5\n",
      "778/778 [==============================] - 27s 34ms/step - loss: 3.8236 - note_output_loss: 2.3971 - length_output_loss: 2.8529\n",
      "Epoch 202/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7938 - note_output_loss: 2.3677 - length_output_loss: 2.8521\n",
      "Epoch 203/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8045 - note_output_loss: 2.3790 - length_output_loss: 2.8510\n",
      "Epoch 204/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8146 - note_output_loss: 2.3964 - length_output_loss: 2.8365\n",
      "Epoch 205/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.8120 - note_output_loss: 2.3833 - length_output_loss: 2.8574\n",
      "Epoch 206/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7898 - note_output_loss: 2.3707 - length_output_loss: 2.8382\n",
      "Epoch 207/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8419 - note_output_loss: 2.4154 - length_output_loss: 2.8530\n",
      "Epoch 208/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7913 - note_output_loss: 2.3688 - length_output_loss: 2.8451\n",
      "Epoch 209/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7875 - note_output_loss: 2.3642 - length_output_loss: 2.8465\n",
      "Epoch 210/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7867 - note_output_loss: 2.3640 - length_output_loss: 2.8455\n",
      "Epoch 211/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7781 - note_output_loss: 2.3529 - length_output_loss: 2.8503\n",
      "Epoch 212/300\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3.8002 - note_output_loss: 2.3821 - length_output_loss: 2.8361\n",
      "Epoch 213/300\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3.7972 - note_output_loss: 2.3707 - length_output_loss: 2.8531\n",
      "Epoch 214/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7836 - note_output_loss: 2.3602 - length_output_loss: 2.8469\n",
      "Epoch 215/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.8260 - note_output_loss: 2.3958 - length_output_loss: 2.8605\n",
      "Epoch 216/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7944 - note_output_loss: 2.3674 - length_output_loss: 2.8540\n",
      "Epoch 217/300\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3.7717 - note_output_loss: 2.3496 - length_output_loss: 2.8442\n",
      "Epoch 218/300\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3.7844 - note_output_loss: 2.3593 - length_output_loss: 2.8501\n",
      "Epoch 219/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7665 - note_output_loss: 2.3444 - length_output_loss: 2.8443\n",
      "Epoch 220/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7475 - note_output_loss: 2.3223 - length_output_loss: 2.8503\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7819 - note_output_loss: 2.3588 - length_output_loss: 2.8462\n",
      "Epoch 222/300\n",
      "778/778 [==============================] - 1s 981us/step - loss: 3.8111 - note_output_loss: 2.3877 - length_output_loss: 2.8469\n",
      "Epoch 223/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7705 - note_output_loss: 2.3515 - length_output_loss: 2.8381\n",
      "Epoch 224/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7658 - note_output_loss: 2.3463 - length_output_loss: 2.8389\n",
      "Epoch 225/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7685 - note_output_loss: 2.3450 - length_output_loss: 2.8469\n",
      "Epoch 226/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7465 - note_output_loss: 2.3252 - length_output_loss: 2.8427\n",
      "Epoch 227/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7486 - note_output_loss: 2.3301 - length_output_loss: 2.8371\n",
      "Epoch 228/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8220 - note_output_loss: 2.3955 - length_output_loss: 2.8530\n",
      "Epoch 229/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7497 - note_output_loss: 2.3339 - length_output_loss: 2.8315\n",
      "Epoch 230/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7430 - note_output_loss: 2.3284 - length_output_loss: 2.8293\n",
      "Epoch 231/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7231 - note_output_loss: 2.3114 - length_output_loss: 2.8234\n",
      "Epoch 232/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7503 - note_output_loss: 2.3379 - length_output_loss: 2.8249\n",
      "Epoch 233/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7544 - note_output_loss: 2.3417 - length_output_loss: 2.8253\n",
      "Epoch 234/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.8333 - note_output_loss: 2.4093 - length_output_loss: 2.8481\n",
      "Epoch 235/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7505 - note_output_loss: 2.3327 - length_output_loss: 2.8355\n",
      "Epoch 236/300\n",
      "778/778 [==============================] - 1s 986us/step - loss: 3.7554 - note_output_loss: 2.3403 - length_output_loss: 2.8302\n",
      "Epoch 237/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7605 - note_output_loss: 2.3443 - length_output_loss: 2.8324\n",
      "Epoch 238/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7589 - note_output_loss: 2.3386 - length_output_loss: 2.8407\n",
      "Epoch 239/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7358 - note_output_loss: 2.3216 - length_output_loss: 2.8285\n",
      "Epoch 240/300\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3.7495 - note_output_loss: 2.3286 - length_output_loss: 2.8418\n",
      "Epoch 241/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7403 - note_output_loss: 2.3300 - length_output_loss: 2.8208\n",
      "Epoch 242/300\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3.7408 - note_output_loss: 2.3330 - length_output_loss: 2.8155\n",
      "Epoch 243/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7924 - note_output_loss: 2.3698 - length_output_loss: 2.8451\n",
      "Epoch 244/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7619 - note_output_loss: 2.3470 - length_output_loss: 2.8298\n",
      "Epoch 245/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7201 - note_output_loss: 2.3060 - length_output_loss: 2.8281\n",
      "Epoch 246/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7594 - note_output_loss: 2.3380 - length_output_loss: 2.8429\n",
      "Epoch 247/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7768 - note_output_loss: 2.3659 - length_output_loss: 2.8218\n",
      "Epoch 248/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7221 - note_output_loss: 2.3080 - length_output_loss: 2.8282\n",
      "Epoch 249/300\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3.7723 - note_output_loss: 2.3574 - length_output_loss: 2.8298\n",
      "Epoch 250/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7336 - note_output_loss: 2.3181 - length_output_loss: 2.8311\n",
      "Epoch 251/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7345 - note_output_loss: 2.3210 - length_output_loss: 2.8269\n",
      "Epoch 252/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7464 - note_output_loss: 2.3251 - length_output_loss: 2.8426\n",
      "Epoch 253/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7247 - note_output_loss: 2.3090 - length_output_loss: 2.8315\n",
      "Epoch 254/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7586 - note_output_loss: 2.3385 - length_output_loss: 2.8402\n",
      "Epoch 255/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7588 - note_output_loss: 2.3452 - length_output_loss: 2.8271\n",
      "Epoch 256/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7234 - note_output_loss: 2.3107 - length_output_loss: 2.8254\n",
      "Epoch 257/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7406 - note_output_loss: 2.3306 - length_output_loss: 2.8199\n",
      "Epoch 258/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7327 - note_output_loss: 2.3172 - length_output_loss: 2.8309\n",
      "Epoch 259/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7250 - note_output_loss: 2.3115 - length_output_loss: 2.8269\n",
      "Epoch 260/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7409 - note_output_loss: 2.3236 - length_output_loss: 2.8346\n",
      "Epoch 261/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7151 - note_output_loss: 2.3047 - length_output_loss: 2.8208\n",
      "Epoch 262/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7203 - note_output_loss: 2.3093 - length_output_loss: 2.8221\n",
      "Epoch 263/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7143 - note_output_loss: 2.3045 - length_output_loss: 2.8195\n",
      "Epoch 264/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.6934 - note_output_loss: 2.2860 - length_output_loss: 2.8147\n",
      "Epoch 265/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6937 - note_output_loss: 2.2802 - length_output_loss: 2.8269\n",
      "Epoch 266/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7164 - note_output_loss: 2.3107 - length_output_loss: 2.8113\n",
      "Epoch 267/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7180 - note_output_loss: 2.3050 - length_output_loss: 2.8261\n",
      "Epoch 268/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7952 - note_output_loss: 2.3726 - length_output_loss: 2.8451\n",
      "Epoch 269/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7260 - note_output_loss: 2.3122 - length_output_loss: 2.8276\n",
      "Epoch 270/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6867 - note_output_loss: 2.2829 - length_output_loss: 2.8075\n",
      "Epoch 271/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.7013 - note_output_loss: 2.2910 - length_output_loss: 2.8205\n",
      "Epoch 272/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.6810 - note_output_loss: 2.2772 - length_output_loss: 2.8076\n",
      "Epoch 273/300\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 3.6988 - note_output_loss: 2.2930 - length_output_loss: 2.8117\n",
      "Epoch 274/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6916 - note_output_loss: 2.2817 - length_output_loss: 2.8198\n",
      "Epoch 275/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7010 - note_output_loss: 2.2940 - length_output_loss: 2.8141\n",
      "Epoch 276/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6918 - note_output_loss: 2.2909 - length_output_loss: 2.8017\n",
      "Epoch 277/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7039 - note_output_loss: 2.2988 - length_output_loss: 2.8103\n",
      "Epoch 278/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7580 - note_output_loss: 2.3396 - length_output_loss: 2.8367\n",
      "Epoch 279/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6908 - note_output_loss: 2.2804 - length_output_loss: 2.8208\n",
      "Epoch 280/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6839 - note_output_loss: 2.2796 - length_output_loss: 2.8085\n",
      "Epoch 281/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6723 - note_output_loss: 2.2655 - length_output_loss: 2.8136\n",
      "Epoch 282/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6860 - note_output_loss: 2.2841 - length_output_loss: 2.8039\n",
      "Epoch 283/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7394 - note_output_loss: 2.3226 - length_output_loss: 2.8338\n",
      "Epoch 284/300\n",
      "778/778 [==============================] - 1s 999us/step - loss: 3.7134 - note_output_loss: 2.3006 - length_output_loss: 2.8254\n",
      "Epoch 285/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6816 - note_output_loss: 2.2782 - length_output_loss: 2.8069\n",
      "Epoch 286/300\n",
      "778/778 [==============================] - 1s 963us/step - loss: 3.6702 - note_output_loss: 2.2643 - length_output_loss: 2.8117\n",
      "Epoch 287/300\n",
      "778/778 [==============================] - 1s 957us/step - loss: 3.6788 - note_output_loss: 2.2711 - length_output_loss: 2.8153\n",
      "Epoch 288/300\n",
      "778/778 [==============================] - 1s 989us/step - loss: 3.6744 - note_output_loss: 2.2702 - length_output_loss: 2.8084\n",
      "Epoch 289/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7115 - note_output_loss: 2.3022 - length_output_loss: 2.8186\n",
      "Epoch 290/300\n",
      "778/778 [==============================] - 1s 976us/step - loss: 3.7038 - note_output_loss: 2.2959 - length_output_loss: 2.8157\n",
      "Epoch 291/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6895 - note_output_loss: 2.2863 - length_output_loss: 2.8065\n",
      "Epoch 292/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6697 - note_output_loss: 2.2685 - length_output_loss: 2.8024\n",
      "Epoch 293/300\n",
      "778/778 [==============================] - 1s 997us/step - loss: 3.6842 - note_output_loss: 2.2806 - length_output_loss: 2.8071\n",
      "Epoch 294/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6599 - note_output_loss: 2.2576 - length_output_loss: 2.8045\n",
      "Epoch 295/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6813 - note_output_loss: 2.2695 - length_output_loss: 2.8237\n",
      "Epoch 296/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.7000 - note_output_loss: 2.2945 - length_output_loss: 2.8111\n",
      "Epoch 297/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6943 - note_output_loss: 2.2924 - length_output_loss: 2.8038\n",
      "Epoch 298/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6634 - note_output_loss: 2.2630 - length_output_loss: 2.8007\n",
      "Epoch 299/300\n",
      "778/778 [==============================] - 1s 1000us/step - loss: 3.6696 - note_output_loss: 2.2690 - length_output_loss: 2.8011\n",
      "Epoch 300/300\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 3.6700 - note_output_loss: 2.2664 - length_output_loss: 2.8071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c29443ba8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger('TRAINING')\n",
    "model.fit([note_x, note_name_x, interval_x, length_x], [note_y, length_y],\n",
    "          batch_size=batch_size,\n",
    "          epochs=1500,\n",
    "          callbacks=[\n",
    "              listen_callback,\n",
    "#               tensorboard,\n",
    "            ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_2.json and model_2.h5 to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
