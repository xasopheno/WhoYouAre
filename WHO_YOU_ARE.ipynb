{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannymeyer/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from pandas import read_csv\n",
    "from Audio.Components.MidiPlayer import MidiPlayer\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from NN.networks.windowed_model import create_model\n",
    "# from NN.models.separate_model import create_model\n",
    "\n",
    "from Audio.Components.helpers.prepare_arrays import prepare_notes, prepare_lengths\n",
    "from Audio.Components.helpers.save_model import save_model\n",
    "from Audio.Components.helpers.make_encoded_prediction import make_encoded_prediction\n",
    "from Audio.Components.helpers.create_categorical_indicies import create_category_indicies\n",
    "from Audio.Components.helpers.generate_phrases import generate_phrases\n",
    "from Audio.Components.helpers.decode_predictions import decode_predictions\n",
    "from Audio.Components.helpers.play_generated_phrase import play_generated_phrase\n",
    "from Audio.Components.helpers.vectorize_phrases import vectorize_phrases\n",
    "from Audio.Components.helpers.logger import logger\n",
    "import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IAC Driver Bus 1', 'IAC Driver LocalMidi']\n"
     ]
    }
   ],
   "source": [
    "player = MidiPlayer()\n",
    "dropout = 0.75\n",
    "n_time_steps = constants.n_time_steps\n",
    "semi_redundancy_step = constants.semi_redundancy_step\n",
    "lstm_size = 64\n",
    "lr = constants.lr\n",
    "epochs = constants.epochs\n",
    "batch_size = constants.batch_size\n",
    "n_to_generate = constants.n_to_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            PREPROCESSING\n",
      "          **********************************\n",
      "corpus length: 40774\n"
     ]
    }
   ],
   "source": [
    "logger('PREPROCESSING')\n",
    "corpus = read_csv('Audio/data/input.csv', header=1)\n",
    "print('corpus length:', len(corpus))\n",
    "notes_corpus = corpus.values[:, 0]\n",
    "length_corpus = corpus.values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorized_variables = {\n",
    "    'note_categories': prepare_notes(),\n",
    "    'length_categories': prepare_lengths()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'note'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-24c9f971e723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnote_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_note\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_phrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemi_redundancy_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mlength_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_phrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemi_redundancy_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/WhoYouAre/Audio/Components/helpers/generate_phrases.py\u001b[0m in \u001b[0;36mgenerate_phrases\u001b[0;34m(category_index, n_time_steps, semi_redundancy_step)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcategory_ys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_time_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'note'"
     ]
    }
   ],
   "source": [
    "note_index, index_note = create_category_indicies(categorized_variables['note_categories'])\n",
    "lengths_index, index_lengths = create_category_indicies(categorized_variables['length_categories'])\n",
    "\n",
    "lookup_indicies = {\n",
    "    'note_index': note_index,\n",
    "    'index_note': index_note,\n",
    "    'lengths_index': lengths_index,\n",
    "    'index_lengths': index_lengths,\n",
    "}\n",
    "\n",
    "note_phrases, next_note = generate_phrases(notes_corpus, n_time_steps, semi_redundancy_step)\n",
    "length_phrases, next_length = generate_phrases(length_corpus, n_time_steps, semi_redundancy_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_x, note_y = vectorize_phrases(\n",
    "    phrases=note_phrases,\n",
    "    n_categories=len(categorized_variables['note_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_index'],\n",
    "    next_lookup_index=next_note\n",
    "    )\n",
    "\n",
    "length_x, length_y = vectorize_phrases(\n",
    "    phrases=length_phrases,\n",
    "    n_categories=len(categorized_variables['length_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['lengths_index'],\n",
    "    next_lookup_index=next_length\n",
    ")\n",
    "\n",
    "print(note_x.shape, 'note_x.shape')\n",
    "print(length_x.shape, 'length_x.shape')\n",
    "print(note_y.shape, 'note_y.shape')\n",
    "print(length_y.shape, 'length_y.shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    categorized_variables=categorized_variables,\n",
    "    lstm_size=lstm_size,\n",
    "    lr=0.001,\n",
    "    n_time_steps=n_time_steps,\n",
    "    dropout=dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.1\n",
    "\tdrop = 0.6\n",
    "\tepochs_drop = 25\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listen_callback(epoch, logs):\n",
    "    if epoch % 20 == 0 and epoch > -1: \n",
    "    # if epoch < -2:\n",
    "        print('----- Generating melody after Epoch: %d' % epoch)\n",
    "        \n",
    "        start_index = random.randint(0, 7000)\n",
    "        for diversity in [0.5]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            current_note_phrase = notes_corpus[start_index: start_index + n_time_steps]\n",
    "            current_length_phrase = length_corpus[start_index: start_index + n_time_steps]\n",
    "\n",
    "            phrases = {'note_phrase': current_note_phrase, 'length_phrase': current_length_phrase}\n",
    "\n",
    "            generated_notes = []\n",
    "            generated_lengths = []\n",
    "            generated_notes.extend(current_note_phrase)\n",
    "            generated_lengths.extend(current_length_phrase)\n",
    "\n",
    "            # model, phrases,categorized_variables, lookup_indicies, n_time_steps, diversity, n_to_generate\n",
    "            for step in range(70):\n",
    "                encoded_prediction = make_encoded_prediction(\n",
    "                    model=model,\n",
    "                    phrases=phrases,\n",
    "                    categorized_variables=categorized_variables,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    n_time_steps=n_time_steps\n",
    "                )\n",
    "\n",
    "                predictions = decode_predictions(\n",
    "                    encoded_prediction=encoded_prediction,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    temperature=diversity\n",
    "                )\n",
    "\n",
    "                generated_notes.append(predictions['note_prediction']) \n",
    "                generated_lengths.append(predictions['length_prediction']) \n",
    "\n",
    "                phrases['note_phrase'] = np.append(phrases['note_phrase'][1:], predictions['note_prediction'])\n",
    "                phrases['length_phrase'] = np.append(phrases['length_phrase'][1:], predictions['length_prediction'])\n",
    "\n",
    "            play_generated_phrase(\n",
    "                generated_notes=generated_notes[10:],\n",
    "                generated_lengths=generated_lengths[10:],\n",
    "                player=player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(datetime.datetime.now()), histogram_freq=0, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listen_callback = LambdaCallback(on_epoch_end=listen_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger('TRAINING')\n",
    "model.fit([note_x, length_x], [note_y, length_y],\n",
    "          batch_size=batch_size,\n",
    "          epochs=300,\n",
    "          callbacks=[\n",
    "              listen_callback,\n",
    "#               tensorboard,\n",
    "            ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_2.json and model_2.h5 to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
