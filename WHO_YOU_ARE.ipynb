{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from pandas import read_csv\n",
    "from Audio.Components.MidiPlayer import MidiPlayer\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from NN.networks.simple_model import create_model\n",
    "\n",
    "from Audio.Components.helpers.prepare_arrays import get_categorized_variables\n",
    "from Audio.Components.helpers.save_model import save_model\n",
    "from Audio.Components.helpers.make_encoded_prediction import make_encoded_prediction\n",
    "from Audio.Components.helpers.create_categorical_indicies import create_category_indicies, create_lookup_indicies\n",
    "from Audio.Components.helpers.generate_phrases import generate_phrases\n",
    "from Audio.Components.helpers.decode_predictions import decode_predictions\n",
    "from Audio.Components.helpers.play_generated_phrase import play_generated_phrase\n",
    "from Audio.Components.helpers.vectorize_phrases import vectorize_phrases\n",
    "from Audio.Components.helpers.logger import logger\n",
    "from Helpers.map_midi_to_note_number import map_midi_to_note_number\n",
    "from Helpers.map_midi_to_interval import map_midi_to_interval\n",
    "import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Danny Bus 1', 'Danny IAC Bus 2']\n"
     ]
    }
   ],
   "source": [
    "player = MidiPlayer()\n",
    "dropout = 0.5\n",
    "n_time_steps = constants.n_time_steps\n",
    "semi_redundancy_step = constants.semi_redundancy_step\n",
    "lstm_size = 10\n",
    "lr = constants.lr\n",
    "epochs = constants.epochs\n",
    "batch_size = constants.batch_size\n",
    "n_to_generate = constants.n_to_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            PREPROCESSING\n",
      "          **********************************\n",
      "corpus length: 808\n"
     ]
    }
   ],
   "source": [
    "logger('PREPROCESSING')\n",
    "corpus = read_csv('Audio/data/input.csv', header=1)\n",
    "print('corpus length:', len(corpus))\n",
    "notes_corpus = corpus.values[:, 0]\n",
    "note_name_corpus = corpus.values[:, 1]\n",
    "interval_corpus = corpus.values[:, 2]\n",
    "length_corpus = corpus.values[:, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_variables = get_categorized_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_indicies = create_lookup_indicies(categorized_variables)\n",
    "\n",
    "note_phrases, next_note = generate_phrases(notes_corpus, n_time_steps, semi_redundancy_step)\n",
    "note_name_phrases, next_note_name = generate_phrases(note_name_corpus, n_time_steps, semi_redundancy_step)\n",
    "interval_phrases, next_interval = generate_phrases(interval_corpus, n_time_steps, semi_redundancy_step)\n",
    "length_phrases, next_length = generate_phrases(length_corpus, n_time_steps, semi_redundancy_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778, 30, 128) note_x.shape\n",
      "(778, 30, 141) length_x.shape\n",
      "(778, 30, 49) interval_x.shape\n",
      "(778, 30, 13) note_name_x.shape\n",
      "(778, 128) note_y.shape\n",
      "(778, 141) length_y.shape\n",
      "(778, 49) interval_y.shape\n",
      "(778, 13) note_name_y.shape\n"
     ]
    }
   ],
   "source": [
    "note_x, note_y = vectorize_phrases(\n",
    "    phrases=note_phrases,\n",
    "    n_categories=len(categorized_variables['note_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_index'],\n",
    "    next_lookup_index=next_note\n",
    "    )\n",
    "\n",
    "interval_x, interval_y = vectorize_phrases(\n",
    "    phrases=interval_phrases,\n",
    "    n_categories=len(categorized_variables['interval_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['interval_index'],\n",
    "    next_lookup_index=next_interval\n",
    ")\n",
    "\n",
    "note_name_x, note_name_y = vectorize_phrases(\n",
    "    phrases=note_name_phrases,\n",
    "    n_categories=len(categorized_variables['note_name_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_name_index'],\n",
    "    next_lookup_index=next_note_name\n",
    ")\n",
    "\n",
    "length_x, length_y = vectorize_phrases(\n",
    "    phrases=length_phrases,\n",
    "    n_categories=len(categorized_variables['length_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['length_index'],\n",
    "    next_lookup_index=next_length\n",
    ")\n",
    "\n",
    "print(note_x.shape, 'note_x.shape')\n",
    "print(length_x.shape, 'length_x.shape')\n",
    "print(interval_x.shape, 'interval_x.shape')\n",
    "print(note_name_x.shape, 'note_name_x.shape')\n",
    "print(note_y.shape, 'note_y.shape')\n",
    "print(length_y.shape, 'length_y.shape')\n",
    "print(interval_y.shape, 'interval_y.shape')\n",
    "print(note_name_y.shape, 'note_name_y.shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    categorized_variables=categorized_variables,\n",
    "    lstm_size=lstm_size,\n",
    "    lr=0.001,\n",
    "    n_time_steps=n_time_steps,\n",
    "    dropout=dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "note_input (InputLayer)         (None, 30, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "note_name_input (InputLayer)    (None, 30, 13)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "interval_input (InputLayer)     (None, 30, 49)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "length_input (InputLayer)       (None, 30, 141)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 331)      0           note_input[0][0]                 \n",
      "                                                                 note_name_input[0][0]            \n",
      "                                                                 interval_input[0][0]             \n",
      "                                                                 length_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 20)       27360       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 20)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 20)           2480        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "note_output (Dense)             (None, 128)          2688        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "length_output (Dense)           (None, 141)          2961        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 35,489\n",
      "Trainable params: 35,489\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 709.91 410.00\" width=\"710pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 705.9106,-406 705.9106,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4748963064 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4748963064</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 145.4658,-401.5 145.4658,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"72.7329\" y=\"-379.3\">note_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4748799560 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4748799560</title>\n",
       "<polygon fill=\"none\" points=\"263.4136,-292.5 263.4136,-328.5 436.0522,-328.5 436.0522,-292.5 263.4136,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-306.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 4748963064&#45;&gt;4748799560 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4748963064-&gt;4748799560</title>\n",
       "<path d=\"M141.2048,-365.4551C180.6579,-355.0577 230.399,-341.949 271.4047,-331.1424\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"272.3108,-334.5232 281.0887,-328.5904 270.5269,-327.7544 272.3108,-334.5232\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4748963624 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4748963624</title>\n",
       "<polygon fill=\"none\" points=\"163.3413,-365.5 163.3413,-401.5 346.1245,-401.5 346.1245,-365.5 163.3413,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.7329\" y=\"-379.3\">note_name_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4748963624&#45;&gt;4748799560 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4748963624-&gt;4748799560</title>\n",
       "<path d=\"M278.2161,-365.4551C290.2054,-356.2422 304.965,-344.9006 317.956,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"320.3939,-337.4587 326.1907,-328.5904 316.1287,-331.9082 320.3939,-337.4587\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4748963680 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4748963680</title>\n",
       "<polygon fill=\"none\" points=\"363.6724,-365.5 363.6724,-401.5 527.7935,-401.5 527.7935,-365.5 363.6724,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445.7329\" y=\"-379.3\">interval_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4748963680&#45;&gt;4748799560 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4748963680-&gt;4748799560</title>\n",
       "<path d=\"M422.0026,-365.4551C409.887,-356.2422 394.9721,-344.9006 381.8443,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"383.6016,-331.8573 373.523,-328.5904 379.3645,-337.4293 383.6016,-331.8573\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4748798160 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4748798160</title>\n",
       "<polygon fill=\"none\" points=\"545.5552,-365.5 545.5552,-401.5 701.9106,-401.5 701.9106,-365.5 545.5552,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.7329\" y=\"-379.3\">length_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4748798160&#45;&gt;4748799560 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4748798160-&gt;4748799560</title>\n",
       "<path d=\"M556.0026,-365.4551C517.0592,-355.0796 467.982,-342.0043 427.4696,-331.2109\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"428.1977,-327.7828 417.6337,-328.5904 426.3956,-334.5469 428.1977,-327.7828\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4796297960 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4796297960</title>\n",
       "<polygon fill=\"none\" points=\"212.0654,-219.5 212.0654,-255.5 487.4004,-255.5 487.4004,-219.5 212.0654,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-233.3\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 4748799560&#45;&gt;4796297960 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4748799560-&gt;4796297960</title>\n",
       "<path d=\"M349.7329,-292.4551C349.7329,-284.3828 349.7329,-274.6764 349.7329,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-265.5903 349.7329,-255.5904 346.233,-265.5904 353.233,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4796299808 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>4796299808</title>\n",
       "<polygon fill=\"none\" points=\"285.9312,-146.5 285.9312,-182.5 413.5347,-182.5 413.5347,-146.5 285.9312,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-160.3\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 4796297960&#45;&gt;4796299808 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>4796297960-&gt;4796299808</title>\n",
       "<path d=\"M349.7329,-219.4551C349.7329,-211.3828 349.7329,-201.6764 349.7329,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-192.5903 349.7329,-182.5904 346.233,-192.5904 353.233,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4803730624 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>4803730624</title>\n",
       "<polygon fill=\"none\" points=\"212.0654,-73.5 212.0654,-109.5 487.4004,-109.5 487.4004,-73.5 212.0654,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-87.3\">bidirectional_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 4796299808&#45;&gt;4803730624 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>4796299808-&gt;4803730624</title>\n",
       "<path d=\"M349.7329,-146.4551C349.7329,-138.3828 349.7329,-128.6764 349.7329,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-119.5903 349.7329,-109.5904 346.233,-119.5904 353.233,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4805206480 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>4805206480</title>\n",
       "<polygon fill=\"none\" points=\"213.1035,-.5 213.1035,-36.5 338.3623,-36.5 338.3623,-.5 213.1035,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.7329\" y=\"-14.3\">note_output: Dense</text>\n",
       "</g>\n",
       "<!-- 4803730624&#45;&gt;4805206480 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>4803730624-&gt;4805206480</title>\n",
       "<path d=\"M331.4408,-73.4551C322.3685,-64.5054 311.26,-53.547 301.3561,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"303.6481,-41.1215 294.0711,-36.5904 298.7321,-46.1049 303.6481,-41.1215\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4810159272 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>4810159272</title>\n",
       "<polygon fill=\"none\" points=\"356.6587,-.5 356.6587,-36.5 492.8071,-36.5 492.8071,-.5 356.6587,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.7329\" y=\"-14.3\">length_output: Dense</text>\n",
       "</g>\n",
       "<!-- 4803730624&#45;&gt;4810159272 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>4803730624-&gt;4810159272</title>\n",
       "<path d=\"M368.2722,-73.4551C377.4671,-64.5054 388.7258,-53.547 398.7634,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"401.4221,-46.0734 406.1469,-36.5904 396.5397,-41.0572 401.4221,-46.0734\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.1\n",
    "\tdrop = 0.6\n",
    "\tepochs_drop = 25\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_callback(epoch, logs):\n",
    "    if epoch % 100 == 0 and epoch > -1: \n",
    "    # if epoch < -2:\n",
    "        print('----- Generating melody after Epoch: %d' % epoch)\n",
    "        \n",
    "        start_index = random.randint(0, 7000)\n",
    "        for diversity in [0.5]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            current_note_phrase = notes_corpus[start_index: start_index + n_time_steps]\n",
    "            current_interval_phrase = interval_corpus[start_index: start_index + n_time_steps]\n",
    "            current_note_name_phrase = note_name_corpus[start_index: start_index + n_time_steps]\n",
    "            current_length_phrase = length_corpus[start_index: start_index + n_time_steps]\n",
    "\n",
    "            phrases = {\n",
    "                'note_phrase': current_note_phrase, \n",
    "                'length_phrase': current_length_phrase,\n",
    "                'interval_phrase': current_interval_phrase,\n",
    "                'note_name_phrase': current_note_name_phrase,\n",
    "            }\n",
    "\n",
    "            generated_notes = []\n",
    "            generated_lengths = []\n",
    "            generated_notes.extend(current_note_phrase)\n",
    "            generated_lengths.extend(current_length_phrase)\n",
    "\n",
    "            # model, phrases,categorized_variables, lookup_indicies, n_time_steps, diversity, n_to_generate\n",
    "            for step in range(20):\n",
    "                encoded_prediction = make_encoded_prediction(\n",
    "                    model=model,\n",
    "                    phrases=phrases,\n",
    "                    categorized_variables=categorized_variables,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    n_time_steps=n_time_steps\n",
    "                )\n",
    "\n",
    "                predictions = decode_predictions(\n",
    "                    encoded_prediction=encoded_prediction,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    temperature=diversity\n",
    "                )\n",
    "\n",
    "                generated_notes.append(predictions['note_prediction']) \n",
    "                generated_lengths.append(predictions['length_prediction']) \n",
    "\n",
    "\n",
    "                last = generated_notes[0]\n",
    "                phrases['note_phrase'] = np.append(phrases['note_phrase'][1:], predictions['note_prediction'])\n",
    "                phrases['interval_phrase'] = map_midi_to_interval(phrases['note_phrase'], last)\n",
    "                phrases['note_name_phrase'] = map_midi_to_note_number(phrases['note_phrase'])\n",
    "                phrases['length_phrase'] = np.append(phrases['length_phrase'][1:], predictions['length_prediction'])\n",
    "\n",
    "                print\n",
    "                \n",
    "            play_generated_phrase(\n",
    "                generated_notes=generated_notes[10:],\n",
    "                generated_lengths=generated_lengths[10:],\n",
    "                player=player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(datetime.datetime.now()), histogram_freq=0, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "listen_callback = LambdaCallback(on_epoch_end=listen_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            TRAINING\n",
      "          **********************************\n",
      "Epoch 1/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 5.6359 - note_output_loss: 3.7037 - length_output_loss: 3.8643\n",
      "----- Generating melody after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "0 | 1.8\n",
      "0 | 1.2\n",
      "66 | 0.33\n",
      "61 | 1.2\n",
      "71 | 0.42\n",
      "59 | 0.6\n",
      "0 | 0.79\n",
      "62 | 0.6\n",
      "72 | 0.65\n",
      "68 | 0.79\n",
      "Epoch 2/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 5.5506 - note_output_loss: 3.6473 - length_output_loss: 3.8066\n",
      "Epoch 3/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 5.4742 - note_output_loss: 3.5982 - length_output_loss: 3.7519\n",
      "Epoch 4/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 5.3958 - note_output_loss: 3.5484 - length_output_loss: 3.6948\n",
      "Epoch 5/300\n",
      "778/778 [==============================] - 0s 464us/step - loss: 5.3323 - note_output_loss: 3.5079 - length_output_loss: 3.6489\n",
      "Epoch 6/300\n",
      "778/778 [==============================] - 0s 462us/step - loss: 5.2724 - note_output_loss: 3.4707 - length_output_loss: 3.6035\n",
      "Epoch 7/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 5.2162 - note_output_loss: 3.4365 - length_output_loss: 3.5596\n",
      "Epoch 8/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 5.1606 - note_output_loss: 3.4013 - length_output_loss: 3.5185\n",
      "Epoch 9/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 5.1152 - note_output_loss: 3.3729 - length_output_loss: 3.4846\n",
      "Epoch 10/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 5.0752 - note_output_loss: 3.3497 - length_output_loss: 3.4510\n",
      "Epoch 11/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 5.0355 - note_output_loss: 3.3234 - length_output_loss: 3.4242\n",
      "Epoch 12/300\n",
      "778/778 [==============================] - 0s 452us/step - loss: 5.0054 - note_output_loss: 3.3063 - length_output_loss: 3.3983\n",
      "Epoch 13/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.9770 - note_output_loss: 3.2890 - length_output_loss: 3.3759\n",
      "Epoch 14/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.9522 - note_output_loss: 3.2743 - length_output_loss: 3.3557\n",
      "Epoch 15/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.9343 - note_output_loss: 3.2620 - length_output_loss: 3.3447\n",
      "Epoch 16/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.9162 - note_output_loss: 3.2519 - length_output_loss: 3.3287\n",
      "Epoch 17/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.9002 - note_output_loss: 3.2441 - length_output_loss: 3.3122\n",
      "Epoch 18/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.8875 - note_output_loss: 3.2359 - length_output_loss: 3.3033\n",
      "Epoch 19/300\n",
      "778/778 [==============================] - 0s 441us/step - loss: 4.8701 - note_output_loss: 3.2235 - length_output_loss: 3.2933\n",
      "Epoch 20/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.8585 - note_output_loss: 3.2165 - length_output_loss: 3.2839\n",
      "Epoch 21/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.8490 - note_output_loss: 3.2103 - length_output_loss: 3.2774\n",
      "Epoch 22/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.8393 - note_output_loss: 3.2033 - length_output_loss: 3.2720\n",
      "Epoch 23/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.8295 - note_output_loss: 3.1976 - length_output_loss: 3.2638\n",
      "Epoch 24/300\n",
      "778/778 [==============================] - 0s 441us/step - loss: 4.8237 - note_output_loss: 3.1937 - length_output_loss: 3.2599\n",
      "Epoch 25/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.8171 - note_output_loss: 3.1907 - length_output_loss: 3.2528\n",
      "Epoch 26/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.8100 - note_output_loss: 3.1851 - length_output_loss: 3.2498\n",
      "Epoch 27/300\n",
      "778/778 [==============================] - 0s 443us/step - loss: 4.8037 - note_output_loss: 3.1813 - length_output_loss: 3.2448\n",
      "Epoch 28/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.7972 - note_output_loss: 3.1761 - length_output_loss: 3.2421\n",
      "Epoch 29/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.7956 - note_output_loss: 3.1757 - length_output_loss: 3.2397\n",
      "Epoch 30/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.7875 - note_output_loss: 3.1695 - length_output_loss: 3.2360\n",
      "Epoch 31/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.7865 - note_output_loss: 3.1703 - length_output_loss: 3.2324\n",
      "Epoch 32/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.7818 - note_output_loss: 3.1660 - length_output_loss: 3.2316\n",
      "Epoch 33/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.7799 - note_output_loss: 3.1637 - length_output_loss: 3.2324\n",
      "Epoch 34/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 4.7778 - note_output_loss: 3.1631 - length_output_loss: 3.2292\n",
      "Epoch 35/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.7752 - note_output_loss: 3.1619 - length_output_loss: 3.2266\n",
      "Epoch 36/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.7738 - note_output_loss: 3.1613 - length_output_loss: 3.2250\n",
      "Epoch 37/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.7697 - note_output_loss: 3.1588 - length_output_loss: 3.2219\n",
      "Epoch 38/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.7668 - note_output_loss: 3.1560 - length_output_loss: 3.2217\n",
      "Epoch 39/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.7637 - note_output_loss: 3.1540 - length_output_loss: 3.2195\n",
      "Epoch 40/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.7609 - note_output_loss: 3.1521 - length_output_loss: 3.2176\n",
      "Epoch 41/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.7607 - note_output_loss: 3.1520 - length_output_loss: 3.2174\n",
      "Epoch 42/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.7592 - note_output_loss: 3.1516 - length_output_loss: 3.2152\n",
      "Epoch 43/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.7579 - note_output_loss: 3.1509 - length_output_loss: 3.2140\n",
      "Epoch 44/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.7543 - note_output_loss: 3.1478 - length_output_loss: 3.2131\n",
      "Epoch 45/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.7551 - note_output_loss: 3.1483 - length_output_loss: 3.2135\n",
      "Epoch 46/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.7551 - note_output_loss: 3.1488 - length_output_loss: 3.2126\n",
      "Epoch 47/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.7523 - note_output_loss: 3.1476 - length_output_loss: 3.2094\n",
      "Epoch 48/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.7505 - note_output_loss: 3.1459 - length_output_loss: 3.2092\n",
      "Epoch 49/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.7484 - note_output_loss: 3.1459 - length_output_loss: 3.2051\n",
      "Epoch 50/300\n",
      "778/778 [==============================] - 0s 467us/step - loss: 4.7469 - note_output_loss: 3.1437 - length_output_loss: 3.2063\n",
      "Epoch 51/300\n",
      "778/778 [==============================] - 0s 462us/step - loss: 4.7466 - note_output_loss: 3.1446 - length_output_loss: 3.2039\n",
      "Epoch 52/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.7435 - note_output_loss: 3.1415 - length_output_loss: 3.2040\n",
      "Epoch 53/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.7461 - note_output_loss: 3.1433 - length_output_loss: 3.2056\n",
      "Epoch 54/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.7428 - note_output_loss: 3.1403 - length_output_loss: 3.2049\n",
      "Epoch 55/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.7416 - note_output_loss: 3.1397 - length_output_loss: 3.2037\n",
      "Epoch 56/300\n",
      "778/778 [==============================] - 0s 468us/step - loss: 4.7397 - note_output_loss: 3.1390 - length_output_loss: 3.2014\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 0s 467us/step - loss: 4.7407 - note_output_loss: 3.1388 - length_output_loss: 3.2038\n",
      "Epoch 58/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.7388 - note_output_loss: 3.1376 - length_output_loss: 3.2025\n",
      "Epoch 59/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.7377 - note_output_loss: 3.1365 - length_output_loss: 3.2024\n",
      "Epoch 60/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.7399 - note_output_loss: 3.1390 - length_output_loss: 3.2018\n",
      "Epoch 61/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.7388 - note_output_loss: 3.1374 - length_output_loss: 3.2028\n",
      "Epoch 62/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.7384 - note_output_loss: 3.1384 - length_output_loss: 3.2000\n",
      "Epoch 63/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.7362 - note_output_loss: 3.1352 - length_output_loss: 3.2021\n",
      "Epoch 64/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.7358 - note_output_loss: 3.1361 - length_output_loss: 3.1993\n",
      "Epoch 65/300\n",
      "778/778 [==============================] - 0s 464us/step - loss: 4.7361 - note_output_loss: 3.1367 - length_output_loss: 3.1988\n",
      "Epoch 66/300\n",
      "778/778 [==============================] - 0s 511us/step - loss: 4.7353 - note_output_loss: 3.1358 - length_output_loss: 3.1991\n",
      "Epoch 67/300\n",
      "778/778 [==============================] - 0s 505us/step - loss: 4.7355 - note_output_loss: 3.1372 - length_output_loss: 3.1967\n",
      "Epoch 68/300\n",
      "778/778 [==============================] - 0s 500us/step - loss: 4.7357 - note_output_loss: 3.1365 - length_output_loss: 3.1984\n",
      "Epoch 69/300\n",
      "778/778 [==============================] - 0s 467us/step - loss: 4.7323 - note_output_loss: 3.1337 - length_output_loss: 3.1972\n",
      "Epoch 70/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.7336 - note_output_loss: 3.1334 - length_output_loss: 3.2003\n",
      "Epoch 71/300\n",
      "778/778 [==============================] - 0s 468us/step - loss: 4.7333 - note_output_loss: 3.1346 - length_output_loss: 3.1975\n",
      "Epoch 72/300\n",
      "778/778 [==============================] - 0s 462us/step - loss: 4.7332 - note_output_loss: 3.1341 - length_output_loss: 3.1982\n",
      "Epoch 73/300\n",
      "778/778 [==============================] - 0s 464us/step - loss: 4.7340 - note_output_loss: 3.1348 - length_output_loss: 3.1984\n",
      "Epoch 74/300\n",
      "778/778 [==============================] - 0s 479us/step - loss: 4.7335 - note_output_loss: 3.1351 - length_output_loss: 3.1968\n",
      "Epoch 75/300\n",
      "778/778 [==============================] - 0s 468us/step - loss: 4.7350 - note_output_loss: 3.1356 - length_output_loss: 3.1988\n",
      "Epoch 76/300\n",
      "778/778 [==============================] - 0s 470us/step - loss: 4.7332 - note_output_loss: 3.1341 - length_output_loss: 3.1982\n",
      "Epoch 77/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.7335 - note_output_loss: 3.1342 - length_output_loss: 3.1986\n",
      "Epoch 78/300\n",
      "778/778 [==============================] - 0s 464us/step - loss: 4.7328 - note_output_loss: 3.1343 - length_output_loss: 3.1971\n",
      "Epoch 79/300\n",
      "778/778 [==============================] - 0s 468us/step - loss: 4.7297 - note_output_loss: 3.1329 - length_output_loss: 3.1937\n",
      "Epoch 80/300\n",
      "778/778 [==============================] - 0s 471us/step - loss: 4.7315 - note_output_loss: 3.1329 - length_output_loss: 3.1972\n",
      "Epoch 81/300\n",
      "778/778 [==============================] - 0s 462us/step - loss: 4.7284 - note_output_loss: 3.1303 - length_output_loss: 3.1962\n",
      "Epoch 82/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.7303 - note_output_loss: 3.1315 - length_output_loss: 3.1976\n",
      "Epoch 83/300\n",
      "778/778 [==============================] - 0s 469us/step - loss: 4.7273 - note_output_loss: 3.1309 - length_output_loss: 3.1928\n",
      "Epoch 84/300\n",
      "778/778 [==============================] - 0s 468us/step - loss: 4.7257 - note_output_loss: 3.1294 - length_output_loss: 3.1926\n",
      "Epoch 85/300\n",
      "778/778 [==============================] - 0s 467us/step - loss: 4.7267 - note_output_loss: 3.1308 - length_output_loss: 3.1919\n",
      "Epoch 86/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.7234 - note_output_loss: 3.1285 - length_output_loss: 3.1898\n",
      "Epoch 87/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.7228 - note_output_loss: 3.1279 - length_output_loss: 3.1897\n",
      "Epoch 88/300\n",
      "778/778 [==============================] - 0s 467us/step - loss: 4.7239 - note_output_loss: 3.1295 - length_output_loss: 3.1888\n",
      "Epoch 89/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.7205 - note_output_loss: 3.1270 - length_output_loss: 3.1870\n",
      "Epoch 90/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.7195 - note_output_loss: 3.1263 - length_output_loss: 3.1863\n",
      "Epoch 91/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.7181 - note_output_loss: 3.1251 - length_output_loss: 3.1859\n",
      "Epoch 92/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.7144 - note_output_loss: 3.1235 - length_output_loss: 3.1818\n",
      "Epoch 93/300\n",
      "778/778 [==============================] - 0s 472us/step - loss: 4.7149 - note_output_loss: 3.1232 - length_output_loss: 3.1835\n",
      "Epoch 94/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.7100 - note_output_loss: 3.1184 - length_output_loss: 3.1832\n",
      "Epoch 95/300\n",
      "778/778 [==============================] - 0s 466us/step - loss: 4.7079 - note_output_loss: 3.1181 - length_output_loss: 3.1797\n",
      "Epoch 96/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.7130 - note_output_loss: 3.1219 - length_output_loss: 3.1820\n",
      "Epoch 97/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.7049 - note_output_loss: 3.1164 - length_output_loss: 3.1770\n",
      "Epoch 98/300\n",
      "778/778 [==============================] - 0s 470us/step - loss: 4.7044 - note_output_loss: 3.1161 - length_output_loss: 3.1765\n",
      "Epoch 99/300\n",
      "778/778 [==============================] - 0s 471us/step - loss: 4.6996 - note_output_loss: 3.1126 - length_output_loss: 3.1741\n",
      "Epoch 100/300\n",
      "778/778 [==============================] - 0s 471us/step - loss: 4.7012 - note_output_loss: 3.1148 - length_output_loss: 3.1728\n",
      "Epoch 101/300\n",
      "778/778 [==============================] - 0s 469us/step - loss: 4.6999 - note_output_loss: 3.1136 - length_output_loss: 3.1726\n",
      "----- Generating melody after Epoch: 100\n",
      "----- diversity: 0.5\n",
      "59 | 0.65\n",
      "55 | 0.6\n",
      "65 | 0.6\n",
      "66 | 0.56\n",
      "60 | 0.46\n",
      "0 | 2.0\n",
      "57 | 0.33\n",
      "67 | 0.46\n",
      "59 | 0.74\n",
      "63 | 0.7\n",
      "Epoch 102/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.6948 - note_output_loss: 3.1083 - length_output_loss: 3.1730\n",
      "Epoch 103/300\n",
      "778/778 [==============================] - 0s 452us/step - loss: 4.7042 - note_output_loss: 3.1158 - length_output_loss: 3.1768\n",
      "Epoch 104/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.6905 - note_output_loss: 3.1059 - length_output_loss: 3.1693\n",
      "Epoch 105/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 4.6976 - note_output_loss: 3.1104 - length_output_loss: 3.1744\n",
      "Epoch 106/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.6949 - note_output_loss: 3.1080 - length_output_loss: 3.1738\n",
      "Epoch 107/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.6898 - note_output_loss: 3.1065 - length_output_loss: 3.1667\n",
      "Epoch 108/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.6865 - note_output_loss: 3.1034 - length_output_loss: 3.1663\n",
      "Epoch 109/300\n",
      "778/778 [==============================] - 0s 442us/step - loss: 4.6861 - note_output_loss: 3.1020 - length_output_loss: 3.1681\n",
      "Epoch 110/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.6862 - note_output_loss: 3.1041 - length_output_loss: 3.1642\n",
      "Epoch 111/300\n",
      "778/778 [==============================] - 0s 442us/step - loss: 4.6781 - note_output_loss: 3.0971 - length_output_loss: 3.1621\n",
      "Epoch 112/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.6805 - note_output_loss: 3.0993 - length_output_loss: 3.1624\n",
      "Epoch 113/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.6827 - note_output_loss: 3.1018 - length_output_loss: 3.1618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/300\n",
      "778/778 [==============================] - 0s 443us/step - loss: 4.6724 - note_output_loss: 3.0941 - length_output_loss: 3.1566\n",
      "Epoch 115/300\n",
      "778/778 [==============================] - 0s 439us/step - loss: 4.6676 - note_output_loss: 3.0898 - length_output_loss: 3.1557\n",
      "Epoch 116/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 4.6748 - note_output_loss: 3.0922 - length_output_loss: 3.1651\n",
      "Epoch 117/300\n",
      "778/778 [==============================] - 0s 485us/step - loss: 4.6701 - note_output_loss: 3.0910 - length_output_loss: 3.1582\n",
      "Epoch 118/300\n",
      "778/778 [==============================] - 0s 442us/step - loss: 4.6716 - note_output_loss: 3.0939 - length_output_loss: 3.1553\n",
      "Epoch 119/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.6660 - note_output_loss: 3.0895 - length_output_loss: 3.1530\n",
      "Epoch 120/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.6597 - note_output_loss: 3.0864 - length_output_loss: 3.1467\n",
      "Epoch 121/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.6620 - note_output_loss: 3.0838 - length_output_loss: 3.1564\n",
      "Epoch 122/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.6577 - note_output_loss: 3.0799 - length_output_loss: 3.1556\n",
      "Epoch 123/300\n",
      "778/778 [==============================] - 0s 440us/step - loss: 4.6539 - note_output_loss: 3.0815 - length_output_loss: 3.1448\n",
      "Epoch 124/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.6578 - note_output_loss: 3.0820 - length_output_loss: 3.1517\n",
      "Epoch 125/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.6479 - note_output_loss: 3.0749 - length_output_loss: 3.1461\n",
      "Epoch 126/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.6563 - note_output_loss: 3.0779 - length_output_loss: 3.1568\n",
      "Epoch 127/300\n",
      "778/778 [==============================] - 0s 441us/step - loss: 4.6517 - note_output_loss: 3.0750 - length_output_loss: 3.1533\n",
      "Epoch 128/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.6398 - note_output_loss: 3.0693 - length_output_loss: 3.1410\n",
      "Epoch 129/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.6492 - note_output_loss: 3.0709 - length_output_loss: 3.1565\n",
      "Epoch 130/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.6468 - note_output_loss: 3.0695 - length_output_loss: 3.1546\n",
      "Epoch 131/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.6399 - note_output_loss: 3.0678 - length_output_loss: 3.1443\n",
      "Epoch 132/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.6345 - note_output_loss: 3.0614 - length_output_loss: 3.1461\n",
      "Epoch 133/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.6394 - note_output_loss: 3.0675 - length_output_loss: 3.1438\n",
      "Epoch 134/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.6519 - note_output_loss: 3.0727 - length_output_loss: 3.1585\n",
      "Epoch 135/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.6443 - note_output_loss: 3.0710 - length_output_loss: 3.1466\n",
      "Epoch 136/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.6349 - note_output_loss: 3.0650 - length_output_loss: 3.1399\n",
      "Epoch 137/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.6277 - note_output_loss: 3.0582 - length_output_loss: 3.1390\n",
      "Epoch 138/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.6304 - note_output_loss: 3.0637 - length_output_loss: 3.1335\n",
      "Epoch 139/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.6443 - note_output_loss: 3.0679 - length_output_loss: 3.1528\n",
      "Epoch 140/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.6361 - note_output_loss: 3.0656 - length_output_loss: 3.1408\n",
      "Epoch 141/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.6309 - note_output_loss: 3.0634 - length_output_loss: 3.1350\n",
      "Epoch 142/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.6244 - note_output_loss: 3.0585 - length_output_loss: 3.1318\n",
      "Epoch 143/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.6213 - note_output_loss: 3.0562 - length_output_loss: 3.1301\n",
      "Epoch 144/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.6174 - note_output_loss: 3.0538 - length_output_loss: 3.1273\n",
      "Epoch 145/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.6186 - note_output_loss: 3.0510 - length_output_loss: 3.1352\n",
      "Epoch 146/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.6180 - note_output_loss: 3.0509 - length_output_loss: 3.1342\n",
      "Epoch 147/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.6106 - note_output_loss: 3.0492 - length_output_loss: 3.1229\n",
      "Epoch 148/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.6098 - note_output_loss: 3.0433 - length_output_loss: 3.1330\n",
      "Epoch 149/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.6074 - note_output_loss: 3.0447 - length_output_loss: 3.1255\n",
      "Epoch 150/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.6143 - note_output_loss: 3.0514 - length_output_loss: 3.1257\n",
      "Epoch 151/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.6138 - note_output_loss: 3.0448 - length_output_loss: 3.1380\n",
      "Epoch 152/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.6089 - note_output_loss: 3.0458 - length_output_loss: 3.1261\n",
      "Epoch 153/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.6084 - note_output_loss: 3.0451 - length_output_loss: 3.1266\n",
      "Epoch 154/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.6072 - note_output_loss: 3.0446 - length_output_loss: 3.1251\n",
      "Epoch 155/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.5964 - note_output_loss: 3.0339 - length_output_loss: 3.1250\n",
      "Epoch 156/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.5940 - note_output_loss: 3.0342 - length_output_loss: 3.1195\n",
      "Epoch 157/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.5927 - note_output_loss: 3.0306 - length_output_loss: 3.1243\n",
      "Epoch 158/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.5947 - note_output_loss: 3.0361 - length_output_loss: 3.1172\n",
      "Epoch 159/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.5842 - note_output_loss: 3.0261 - length_output_loss: 3.1162\n",
      "Epoch 160/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.5942 - note_output_loss: 3.0373 - length_output_loss: 3.1139\n",
      "Epoch 161/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.5796 - note_output_loss: 3.0231 - length_output_loss: 3.1131\n",
      "Epoch 162/300\n",
      "778/778 [==============================] - 0s 462us/step - loss: 4.5851 - note_output_loss: 3.0258 - length_output_loss: 3.1186\n",
      "Epoch 163/300\n",
      "778/778 [==============================] - 0s 466us/step - loss: 4.5908 - note_output_loss: 3.0308 - length_output_loss: 3.1201\n",
      "Epoch 164/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.5996 - note_output_loss: 3.0318 - length_output_loss: 3.1358\n",
      "Epoch 165/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.5840 - note_output_loss: 3.0222 - length_output_loss: 3.1236\n",
      "Epoch 166/300\n",
      "778/778 [==============================] - 0s 466us/step - loss: 4.5952 - note_output_loss: 3.0319 - length_output_loss: 3.1266\n",
      "Epoch 167/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.5866 - note_output_loss: 3.0270 - length_output_loss: 3.1194\n",
      "Epoch 168/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.5789 - note_output_loss: 3.0199 - length_output_loss: 3.1180\n",
      "Epoch 169/300\n",
      "778/778 [==============================] - 0s 468us/step - loss: 4.5785 - note_output_loss: 3.0199 - length_output_loss: 3.1172\n",
      "Epoch 170/300\n",
      "778/778 [==============================] - 0s 466us/step - loss: 4.5758 - note_output_loss: 3.0144 - length_output_loss: 3.1228\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 0s 463us/step - loss: 4.5681 - note_output_loss: 3.0120 - length_output_loss: 3.1121\n",
      "Epoch 172/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.5744 - note_output_loss: 3.0200 - length_output_loss: 3.1089\n",
      "Epoch 173/300\n",
      "778/778 [==============================] - 0s 465us/step - loss: 4.5732 - note_output_loss: 3.0168 - length_output_loss: 3.1127\n",
      "Epoch 174/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.5751 - note_output_loss: 3.0175 - length_output_loss: 3.1151\n",
      "Epoch 175/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.5686 - note_output_loss: 3.0119 - length_output_loss: 3.1134\n",
      "Epoch 176/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.5643 - note_output_loss: 3.0052 - length_output_loss: 3.1182\n",
      "Epoch 177/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.5523 - note_output_loss: 3.0010 - length_output_loss: 3.1026\n",
      "Epoch 178/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.5455 - note_output_loss: 2.9941 - length_output_loss: 3.1028\n",
      "Epoch 179/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.5480 - note_output_loss: 2.9921 - length_output_loss: 3.1118\n",
      "Epoch 180/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.5727 - note_output_loss: 3.0157 - length_output_loss: 3.1138\n",
      "Epoch 181/300\n",
      "778/778 [==============================] - 0s 452us/step - loss: 4.5679 - note_output_loss: 3.0084 - length_output_loss: 3.1190\n",
      "Epoch 182/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.5601 - note_output_loss: 3.0027 - length_output_loss: 3.1149\n",
      "Epoch 183/300\n",
      "778/778 [==============================] - 0s 470us/step - loss: 4.5466 - note_output_loss: 2.9896 - length_output_loss: 3.1140\n",
      "Epoch 184/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.5385 - note_output_loss: 2.9865 - length_output_loss: 3.1040\n",
      "Epoch 185/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.5360 - note_output_loss: 2.9865 - length_output_loss: 3.0989\n",
      "Epoch 186/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.5330 - note_output_loss: 2.9835 - length_output_loss: 3.0990\n",
      "Epoch 187/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.5243 - note_output_loss: 2.9773 - length_output_loss: 3.0940\n",
      "Epoch 188/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.5438 - note_output_loss: 2.9966 - length_output_loss: 3.0945\n",
      "Epoch 189/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.5264 - note_output_loss: 2.9781 - length_output_loss: 3.0967\n",
      "Epoch 190/300\n",
      "778/778 [==============================] - 0s 466us/step - loss: 4.5211 - note_output_loss: 2.9748 - length_output_loss: 3.0927\n",
      "Epoch 191/300\n",
      "778/778 [==============================] - 0s 469us/step - loss: 4.5313 - note_output_loss: 2.9807 - length_output_loss: 3.1012\n",
      "Epoch 192/300\n",
      "778/778 [==============================] - 0s 462us/step - loss: 4.5220 - note_output_loss: 2.9785 - length_output_loss: 3.0871\n",
      "Epoch 193/300\n",
      "778/778 [==============================] - 0s 466us/step - loss: 4.5302 - note_output_loss: 2.9820 - length_output_loss: 3.0965\n",
      "Epoch 194/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.5092 - note_output_loss: 2.9658 - length_output_loss: 3.0868\n",
      "Epoch 195/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.5211 - note_output_loss: 2.9815 - length_output_loss: 3.0793\n",
      "Epoch 196/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.5015 - note_output_loss: 2.9594 - length_output_loss: 3.0841\n",
      "Epoch 197/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.5160 - note_output_loss: 2.9737 - length_output_loss: 3.0847\n",
      "Epoch 198/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.5070 - note_output_loss: 2.9663 - length_output_loss: 3.0814\n",
      "Epoch 199/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.5003 - note_output_loss: 2.9596 - length_output_loss: 3.0813\n",
      "Epoch 200/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.5088 - note_output_loss: 2.9678 - length_output_loss: 3.0819\n",
      "Epoch 201/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 4.5045 - note_output_loss: 2.9631 - length_output_loss: 3.0828\n",
      "----- Generating melody after Epoch: 200\n",
      "----- diversity: 0.5\n",
      "0 | 0.46\n",
      "52 | 0.98\n",
      "57 | 0.84\n",
      "59 | 0.34\n",
      "52 | 3.2\n",
      "75 | 0.74\n",
      "64 | 0.88\n",
      "0 | 0.74\n",
      "52 | 2.1\n",
      "84 | 3.4\n",
      "Epoch 202/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 4.5401 - note_output_loss: 2.9911 - length_output_loss: 3.0979\n",
      "Epoch 203/300\n",
      "778/778 [==============================] - 0s 488us/step - loss: 4.5080 - note_output_loss: 2.9655 - length_output_loss: 3.0850\n",
      "Epoch 204/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.4994 - note_output_loss: 2.9563 - length_output_loss: 3.0863\n",
      "Epoch 205/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.4942 - note_output_loss: 2.9572 - length_output_loss: 3.0742\n",
      "Epoch 206/300\n",
      "778/778 [==============================] - 0s 440us/step - loss: 4.4839 - note_output_loss: 2.9486 - length_output_loss: 3.0706\n",
      "Epoch 207/300\n",
      "778/778 [==============================] - 0s 439us/step - loss: 4.4865 - note_output_loss: 2.9521 - length_output_loss: 3.0688\n",
      "Epoch 208/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.4825 - note_output_loss: 2.9483 - length_output_loss: 3.0685\n",
      "Epoch 209/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.5405 - note_output_loss: 2.9856 - length_output_loss: 3.1098\n",
      "Epoch 210/300\n",
      "778/778 [==============================] - 0s 438us/step - loss: 4.4875 - note_output_loss: 2.9470 - length_output_loss: 3.0810\n",
      "Epoch 211/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.4709 - note_output_loss: 2.9323 - length_output_loss: 3.0772\n",
      "Epoch 212/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.4786 - note_output_loss: 2.9421 - length_output_loss: 3.0731\n",
      "Epoch 213/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.4897 - note_output_loss: 2.9548 - length_output_loss: 3.0700\n",
      "Epoch 214/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.4649 - note_output_loss: 2.9323 - length_output_loss: 3.0651\n",
      "Epoch 215/300\n",
      "778/778 [==============================] - 0s 440us/step - loss: 4.4664 - note_output_loss: 2.9349 - length_output_loss: 3.0630\n",
      "Epoch 216/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.4733 - note_output_loss: 2.9304 - length_output_loss: 3.0856\n",
      "Epoch 217/300\n",
      "778/778 [==============================] - 0s 441us/step - loss: 4.4654 - note_output_loss: 2.9319 - length_output_loss: 3.0669\n",
      "Epoch 218/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.4700 - note_output_loss: 2.9391 - length_output_loss: 3.0618\n",
      "Epoch 219/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.4548 - note_output_loss: 2.9273 - length_output_loss: 3.0550\n",
      "Epoch 220/300\n",
      "778/778 [==============================] - 0s 438us/step - loss: 4.4525 - note_output_loss: 2.9230 - length_output_loss: 3.0591\n",
      "Epoch 221/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.4543 - note_output_loss: 2.9227 - length_output_loss: 3.0632\n",
      "Epoch 222/300\n",
      "778/778 [==============================] - 0s 443us/step - loss: 4.4460 - note_output_loss: 2.9180 - length_output_loss: 3.0559\n",
      "Epoch 223/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.4614 - note_output_loss: 2.9291 - length_output_loss: 3.0645\n",
      "Epoch 224/300\n",
      "778/778 [==============================] - 0s 443us/step - loss: 4.4616 - note_output_loss: 2.9272 - length_output_loss: 3.0688\n",
      "Epoch 225/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.4448 - note_output_loss: 2.9207 - length_output_loss: 3.0482\n",
      "Epoch 226/300\n",
      "778/778 [==============================] - 0s 436us/step - loss: 4.4335 - note_output_loss: 2.9102 - length_output_loss: 3.0467\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 0s 447us/step - loss: 4.4295 - note_output_loss: 2.9120 - length_output_loss: 3.0350\n",
      "Epoch 228/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.4247 - note_output_loss: 2.9038 - length_output_loss: 3.0419\n",
      "Epoch 229/300\n",
      "778/778 [==============================] - 0s 441us/step - loss: 4.4158 - note_output_loss: 2.8962 - length_output_loss: 3.0391\n",
      "Epoch 230/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.4309 - note_output_loss: 2.9075 - length_output_loss: 3.0468\n",
      "Epoch 231/300\n",
      "778/778 [==============================] - 0s 438us/step - loss: 4.4270 - note_output_loss: 2.9086 - length_output_loss: 3.0368\n",
      "Epoch 232/300\n",
      "778/778 [==============================] - 0s 442us/step - loss: 4.4195 - note_output_loss: 2.8993 - length_output_loss: 3.0403\n",
      "Epoch 233/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.4494 - note_output_loss: 2.9182 - length_output_loss: 3.0624\n",
      "Epoch 234/300\n",
      "778/778 [==============================] - 0s 443us/step - loss: 4.4177 - note_output_loss: 2.8973 - length_output_loss: 3.0409\n",
      "Epoch 235/300\n",
      "778/778 [==============================] - 0s 443us/step - loss: 4.4183 - note_output_loss: 2.8978 - length_output_loss: 3.0410\n",
      "Epoch 236/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.4693 - note_output_loss: 2.9397 - length_output_loss: 3.0590\n",
      "Epoch 237/300\n",
      "778/778 [==============================] - 0s 473us/step - loss: 4.4182 - note_output_loss: 2.8976 - length_output_loss: 3.0412\n",
      "Epoch 238/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.4185 - note_output_loss: 2.8984 - length_output_loss: 3.0403\n",
      "Epoch 239/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.4288 - note_output_loss: 2.9043 - length_output_loss: 3.0488\n",
      "Epoch 240/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.3967 - note_output_loss: 2.8803 - length_output_loss: 3.0328\n",
      "Epoch 241/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.4011 - note_output_loss: 2.8876 - length_output_loss: 3.0271\n",
      "Epoch 242/300\n",
      "778/778 [==============================] - 0s 440us/step - loss: 4.4299 - note_output_loss: 2.9091 - length_output_loss: 3.0414\n",
      "Epoch 243/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.3922 - note_output_loss: 2.8807 - length_output_loss: 3.0229\n",
      "Epoch 244/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.4028 - note_output_loss: 2.8888 - length_output_loss: 3.0280\n",
      "Epoch 245/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.3851 - note_output_loss: 2.8830 - length_output_loss: 3.0043\n",
      "Epoch 246/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.4158 - note_output_loss: 2.8969 - length_output_loss: 3.0377\n",
      "Epoch 247/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.3794 - note_output_loss: 2.8740 - length_output_loss: 3.0107\n",
      "Epoch 248/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.3905 - note_output_loss: 2.8760 - length_output_loss: 3.0290\n",
      "Epoch 249/300\n",
      "778/778 [==============================] - 0s 441us/step - loss: 4.3830 - note_output_loss: 2.8733 - length_output_loss: 3.0196\n",
      "Epoch 250/300\n",
      "778/778 [==============================] - 0s 447us/step - loss: 4.3749 - note_output_loss: 2.8683 - length_output_loss: 3.0132\n",
      "Epoch 251/300\n",
      "778/778 [==============================] - 0s 437us/step - loss: 4.3998 - note_output_loss: 2.8877 - length_output_loss: 3.0243\n",
      "Epoch 252/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.3796 - note_output_loss: 2.8698 - length_output_loss: 3.0195\n",
      "Epoch 253/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.3680 - note_output_loss: 2.8576 - length_output_loss: 3.0209\n",
      "Epoch 254/300\n",
      "778/778 [==============================] - 0s 450us/step - loss: 4.3756 - note_output_loss: 2.8729 - length_output_loss: 3.0053\n",
      "Epoch 255/300\n",
      "778/778 [==============================] - 0s 440us/step - loss: 4.3802 - note_output_loss: 2.8728 - length_output_loss: 3.0148\n",
      "Epoch 256/300\n",
      "778/778 [==============================] - 0s 444us/step - loss: 4.3704 - note_output_loss: 2.8639 - length_output_loss: 3.0130\n",
      "Epoch 257/300\n",
      "778/778 [==============================] - 0s 439us/step - loss: 4.3795 - note_output_loss: 2.8676 - length_output_loss: 3.0237\n",
      "Epoch 258/300\n",
      "778/778 [==============================] - 0s 448us/step - loss: 4.3602 - note_output_loss: 2.8559 - length_output_loss: 3.0086\n",
      "Epoch 259/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.3571 - note_output_loss: 2.8547 - length_output_loss: 3.0047\n",
      "Epoch 260/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.3738 - note_output_loss: 2.8628 - length_output_loss: 3.0220\n",
      "Epoch 261/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.3600 - note_output_loss: 2.8505 - length_output_loss: 3.0190\n",
      "Epoch 262/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.3490 - note_output_loss: 2.8443 - length_output_loss: 3.0094\n",
      "Epoch 263/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.3554 - note_output_loss: 2.8485 - length_output_loss: 3.0139\n",
      "Epoch 264/300\n",
      "778/778 [==============================] - 0s 468us/step - loss: 4.3371 - note_output_loss: 2.8330 - length_output_loss: 3.0081\n",
      "Epoch 265/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.3733 - note_output_loss: 2.8662 - length_output_loss: 3.0143\n",
      "Epoch 266/300\n",
      "778/778 [==============================] - 0s 462us/step - loss: 4.4449 - note_output_loss: 2.9150 - length_output_loss: 3.0597\n",
      "Epoch 267/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.3402 - note_output_loss: 2.8338 - length_output_loss: 3.0128\n",
      "Epoch 268/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.3495 - note_output_loss: 2.8446 - length_output_loss: 3.0098\n",
      "Epoch 269/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.3256 - note_output_loss: 2.8257 - length_output_loss: 2.9997\n",
      "Epoch 270/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.3244 - note_output_loss: 2.8297 - length_output_loss: 2.9894\n",
      "Epoch 271/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.3273 - note_output_loss: 2.8312 - length_output_loss: 2.9923\n",
      "Epoch 272/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.3166 - note_output_loss: 2.8228 - length_output_loss: 2.9876\n",
      "Epoch 273/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.3255 - note_output_loss: 2.8294 - length_output_loss: 2.9922\n",
      "Epoch 274/300\n",
      "778/778 [==============================] - 0s 459us/step - loss: 4.3138 - note_output_loss: 2.8213 - length_output_loss: 2.9849\n",
      "Epoch 275/300\n",
      "778/778 [==============================] - 0s 464us/step - loss: 4.3318 - note_output_loss: 2.8391 - length_output_loss: 2.9854\n",
      "Epoch 276/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.3183 - note_output_loss: 2.8237 - length_output_loss: 2.9893\n",
      "Epoch 277/300\n",
      "778/778 [==============================] - 0s 460us/step - loss: 4.3234 - note_output_loss: 2.8239 - length_output_loss: 2.9989\n",
      "Epoch 278/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.3105 - note_output_loss: 2.8162 - length_output_loss: 2.9885\n",
      "Epoch 279/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.3133 - note_output_loss: 2.8197 - length_output_loss: 2.9871\n",
      "Epoch 280/300\n",
      "778/778 [==============================] - 0s 473us/step - loss: 4.3148 - note_output_loss: 2.8211 - length_output_loss: 2.9874\n",
      "Epoch 281/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.3018 - note_output_loss: 2.8138 - length_output_loss: 2.9762\n",
      "Epoch 282/300\n",
      "778/778 [==============================] - 0s 466us/step - loss: 4.3283 - note_output_loss: 2.8315 - length_output_loss: 2.9936\n",
      "Epoch 283/300\n",
      "778/778 [==============================] - 0s 461us/step - loss: 4.3042 - note_output_loss: 2.8072 - length_output_loss: 2.9941\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 0s 464us/step - loss: 4.3072 - note_output_loss: 2.8101 - length_output_loss: 2.9942\n",
      "Epoch 285/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.2941 - note_output_loss: 2.8011 - length_output_loss: 2.9859\n",
      "Epoch 286/300\n",
      "778/778 [==============================] - 0s 454us/step - loss: 4.3096 - note_output_loss: 2.8134 - length_output_loss: 2.9923\n",
      "Epoch 287/300\n",
      "778/778 [==============================] - 0s 456us/step - loss: 4.2962 - note_output_loss: 2.8080 - length_output_loss: 2.9764\n",
      "Epoch 288/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.2763 - note_output_loss: 2.7925 - length_output_loss: 2.9675\n",
      "Epoch 289/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.2772 - note_output_loss: 2.7864 - length_output_loss: 2.9817\n",
      "Epoch 290/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.2851 - note_output_loss: 2.7980 - length_output_loss: 2.9743\n",
      "Epoch 291/300\n",
      "778/778 [==============================] - 0s 451us/step - loss: 4.3206 - note_output_loss: 2.8226 - length_output_loss: 2.9960\n",
      "Epoch 292/300\n",
      "778/778 [==============================] - 0s 449us/step - loss: 4.3026 - note_output_loss: 2.8149 - length_output_loss: 2.9755\n",
      "Epoch 293/300\n",
      "778/778 [==============================] - 0s 458us/step - loss: 4.2859 - note_output_loss: 2.8034 - length_output_loss: 2.9650\n",
      "Epoch 294/300\n",
      "778/778 [==============================] - 0s 443us/step - loss: 4.2826 - note_output_loss: 2.7923 - length_output_loss: 2.9806\n",
      "Epoch 295/300\n",
      "778/778 [==============================] - 0s 446us/step - loss: 4.2944 - note_output_loss: 2.8027 - length_output_loss: 2.9833\n",
      "Epoch 296/300\n",
      "778/778 [==============================] - 0s 445us/step - loss: 4.3066 - note_output_loss: 2.8148 - length_output_loss: 2.9835\n",
      "Epoch 297/300\n",
      "778/778 [==============================] - 0s 463us/step - loss: 4.2653 - note_output_loss: 2.7799 - length_output_loss: 2.9708\n",
      "Epoch 298/300\n",
      "778/778 [==============================] - 0s 453us/step - loss: 4.2707 - note_output_loss: 2.7910 - length_output_loss: 2.9594\n",
      "Epoch 299/300\n",
      "778/778 [==============================] - 0s 455us/step - loss: 4.2767 - note_output_loss: 2.7918 - length_output_loss: 2.9696\n",
      "Epoch 300/300\n",
      "778/778 [==============================] - 0s 457us/step - loss: 4.2939 - note_output_loss: 2.8013 - length_output_loss: 2.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ef265c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger('TRAINING')\n",
    "model.fit([note_x, note_name_x, interval_x, length_x], [note_y, length_y],\n",
    "          batch_size=batch_size,\n",
    "          epochs=300,\n",
    "          callbacks=[\n",
    "              listen_callback,\n",
    "#               tensorboard,\n",
    "            ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_2.json and model_2.h5 to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
