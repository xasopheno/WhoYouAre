{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from pandas import read_csv\n",
    "from Audio.Components.MidiPlayer import MidiPlayer\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from NN.networks.simple_model import create_model\n",
    "\n",
    "from Audio.Components.helpers.prepare_arrays import get_categorized_variables\n",
    "from Audio.Components.helpers.save_model import save_model\n",
    "from Audio.Components.helpers.make_encoded_prediction import make_encoded_prediction\n",
    "from Audio.Components.helpers.create_categorical_indicies import create_category_indicies, create_lookup_indicies\n",
    "from Audio.Components.helpers.generate_phrases import generate_phrases\n",
    "from Audio.Components.helpers.decode_predictions import decode_predictions\n",
    "from Audio.Components.helpers.play_generated_phrase import play_generated_phrase\n",
    "from Audio.Components.helpers.vectorize_phrases import vectorize_phrases\n",
    "from Audio.Components.helpers.logger import logger\n",
    "from Helpers.map_midi_to_note_number import map_midi_to_note_number\n",
    "from Helpers.map_midi_to_interval import map_midi_to_interval\n",
    "import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Danny Bus 1', 'Danny IAC Bus 2']\n"
     ]
    }
   ],
   "source": [
    "player = MidiPlayer()\n",
    "dropout = 0.5\n",
    "n_time_steps = constants.n_time_steps\n",
    "semi_redundancy_step = constants.semi_redundancy_step\n",
    "lstm_size = 32\n",
    "lr = constants.lr\n",
    "epochs = constants.epochs\n",
    "batch_size = constants.batch_size\n",
    "n_to_generate = constants.n_to_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            PREPROCESSING\n",
      "          **********************************\n",
      "corpus length: 10611\n"
     ]
    }
   ],
   "source": [
    "logger('PREPROCESSING')\n",
    "corpus = read_csv('Audio/data/input.csv', header=1)\n",
    "print('corpus length:', len(corpus))\n",
    "notes_corpus = corpus.values[:, 0]\n",
    "note_name_corpus = corpus.values[:, 1]\n",
    "interval_corpus = corpus.values[:, 2]\n",
    "length_corpus = corpus.values[:, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_variables = get_categorized_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_indicies = create_lookup_indicies(categorized_variables)\n",
    "\n",
    "note_phrases, next_note = generate_phrases(notes_corpus, n_time_steps, semi_redundancy_step)\n",
    "note_name_phrases, next_note_name = generate_phrases(note_name_corpus, n_time_steps, semi_redundancy_step)\n",
    "interval_phrases, next_interval = generate_phrases(interval_corpus, n_time_steps, semi_redundancy_step)\n",
    "length_phrases, next_length = generate_phrases(length_corpus, n_time_steps, semi_redundancy_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10581, 30, 128) note_x.shape\n",
      "(10581, 30, 141) length_x.shape\n",
      "(10581, 30, 49) interval_x.shape\n",
      "(10581, 30, 13) note_name_x.shape\n",
      "(10581, 128) note_y.shape\n",
      "(10581, 141) length_y.shape\n",
      "(10581, 49) interval_y.shape\n",
      "(10581, 13) note_name_y.shape\n"
     ]
    }
   ],
   "source": [
    "note_x, note_y = vectorize_phrases(\n",
    "    phrases=note_phrases,\n",
    "    n_categories=len(categorized_variables['note_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_index'],\n",
    "    next_lookup_index=next_note\n",
    "    )\n",
    "\n",
    "interval_x, interval_y = vectorize_phrases(\n",
    "    phrases=interval_phrases,\n",
    "    n_categories=len(categorized_variables['interval_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['interval_index'],\n",
    "    next_lookup_index=next_interval\n",
    ")\n",
    "\n",
    "note_name_x, note_name_y = vectorize_phrases(\n",
    "    phrases=note_name_phrases,\n",
    "    n_categories=len(categorized_variables['note_name_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_name_index'],\n",
    "    next_lookup_index=next_note_name\n",
    ")\n",
    "\n",
    "length_x, length_y = vectorize_phrases(\n",
    "    phrases=length_phrases,\n",
    "    n_categories=len(categorized_variables['length_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['length_index'],\n",
    "    next_lookup_index=next_length\n",
    ")\n",
    "\n",
    "print(note_x.shape, 'note_x.shape')\n",
    "print(length_x.shape, 'length_x.shape')\n",
    "print(interval_x.shape, 'interval_x.shape')\n",
    "print(note_name_x.shape, 'note_name_x.shape')\n",
    "print(note_y.shape, 'note_y.shape')\n",
    "print(length_y.shape, 'length_y.shape')\n",
    "print(interval_y.shape, 'interval_y.shape')\n",
    "print(note_name_y.shape, 'note_name_y.shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    categorized_variables=categorized_variables,\n",
    "    lstm_size=lstm_size,\n",
    "    lr=0.001,\n",
    "    n_time_steps=n_time_steps,\n",
    "    dropout=dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "note_input (InputLayer)         (None, 30, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "note_name_input (InputLayer)    (None, 30, 13)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "interval_input (InputLayer)     (None, 30, 49)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "length_input (InputLayer)       (None, 30, 141)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30, 331)      0           note_input[0][0]                 \n",
      "                                                                 note_name_input[0][0]            \n",
      "                                                                 interval_input[0][0]             \n",
      "                                                                 length_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 30, 64)       93184       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 64)       0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 64)           24832       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "note_output (Dense)             (None, 128)          8320        bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "length_output (Dense)           (None, 141)          9165        bidirectional_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 135,501\n",
      "Trainable params: 135,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 709.91 410.00\" width=\"710pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 705.9106,-406 705.9106,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5309723536 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5309723536</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 145.4658,-401.5 145.4658,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"72.7329\" y=\"-379.3\">note_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5309724936 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5309724936</title>\n",
       "<polygon fill=\"none\" points=\"263.4136,-292.5 263.4136,-328.5 436.0522,-328.5 436.0522,-292.5 263.4136,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-306.3\">concatenate_3: Concatenate</text>\n",
       "</g>\n",
       "<!-- 5309723536&#45;&gt;5309724936 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5309723536-&gt;5309724936</title>\n",
       "<path d=\"M141.2048,-365.4551C180.6579,-355.0577 230.399,-341.949 271.4047,-331.1424\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"272.3108,-334.5232 281.0887,-328.5904 270.5269,-327.7544 272.3108,-334.5232\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5309726000 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5309726000</title>\n",
       "<polygon fill=\"none\" points=\"163.3413,-365.5 163.3413,-401.5 346.1245,-401.5 346.1245,-365.5 163.3413,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.7329\" y=\"-379.3\">note_name_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5309726000&#45;&gt;5309724936 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5309726000-&gt;5309724936</title>\n",
       "<path d=\"M278.2161,-365.4551C290.2054,-356.2422 304.965,-344.9006 317.956,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"320.3939,-337.4587 326.1907,-328.5904 316.1287,-331.9082 320.3939,-337.4587\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5309725440 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5309725440</title>\n",
       "<polygon fill=\"none\" points=\"363.6724,-365.5 363.6724,-401.5 527.7935,-401.5 527.7935,-365.5 363.6724,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445.7329\" y=\"-379.3\">interval_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5309725440&#45;&gt;5309724936 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5309725440-&gt;5309724936</title>\n",
       "<path d=\"M422.0026,-365.4551C409.887,-356.2422 394.9721,-344.9006 381.8443,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"383.6016,-331.8573 373.523,-328.5904 379.3645,-337.4293 383.6016,-331.8573\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5309725160 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5309725160</title>\n",
       "<polygon fill=\"none\" points=\"545.5552,-365.5 545.5552,-401.5 701.9106,-401.5 701.9106,-365.5 545.5552,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.7329\" y=\"-379.3\">length_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5309725160&#45;&gt;5309724936 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5309725160-&gt;5309724936</title>\n",
       "<path d=\"M556.0026,-365.4551C517.0592,-355.0796 467.982,-342.0043 427.4696,-331.2109\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"428.1977,-327.7828 417.6337,-328.5904 426.3956,-334.5469 428.1977,-327.7828\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5310011712 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5310011712</title>\n",
       "<polygon fill=\"none\" points=\"212.0654,-219.5 212.0654,-255.5 487.4004,-255.5 487.4004,-219.5 212.0654,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-233.3\">bidirectional_5(lstm_5): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5309724936&#45;&gt;5310011712 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5309724936-&gt;5310011712</title>\n",
       "<path d=\"M349.7329,-292.4551C349.7329,-284.3828 349.7329,-274.6764 349.7329,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-265.5903 349.7329,-255.5904 346.233,-265.5904 353.233,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5310011936 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5310011936</title>\n",
       "<polygon fill=\"none\" points=\"285.9312,-146.5 285.9312,-182.5 413.5347,-182.5 413.5347,-146.5 285.9312,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-160.3\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 5310011712&#45;&gt;5310011936 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5310011712-&gt;5310011936</title>\n",
       "<path d=\"M349.7329,-219.4551C349.7329,-211.3828 349.7329,-201.6764 349.7329,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-192.5903 349.7329,-182.5904 346.233,-192.5904 353.233,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5325131504 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5325131504</title>\n",
       "<polygon fill=\"none\" points=\"212.0654,-73.5 212.0654,-109.5 487.4004,-109.5 487.4004,-73.5 212.0654,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-87.3\">bidirectional_6(lstm_6): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5310011936&#45;&gt;5325131504 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5310011936-&gt;5325131504</title>\n",
       "<path d=\"M349.7329,-146.4551C349.7329,-138.3828 349.7329,-128.6764 349.7329,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-119.5903 349.7329,-109.5904 346.233,-119.5904 353.233,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5325555192 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5325555192</title>\n",
       "<polygon fill=\"none\" points=\"213.1035,-.5 213.1035,-36.5 338.3623,-36.5 338.3623,-.5 213.1035,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.7329\" y=\"-14.3\">note_output: Dense</text>\n",
       "</g>\n",
       "<!-- 5325131504&#45;&gt;5325555192 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>5325131504-&gt;5325555192</title>\n",
       "<path d=\"M331.4408,-73.4551C322.3685,-64.5054 311.26,-53.547 301.3561,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"303.6481,-41.1215 294.0711,-36.5904 298.7321,-46.1049 303.6481,-41.1215\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5335027552 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>5335027552</title>\n",
       "<polygon fill=\"none\" points=\"356.6587,-.5 356.6587,-36.5 492.8071,-36.5 492.8071,-.5 356.6587,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.7329\" y=\"-14.3\">length_output: Dense</text>\n",
       "</g>\n",
       "<!-- 5325131504&#45;&gt;5335027552 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>5325131504-&gt;5335027552</title>\n",
       "<path d=\"M368.2722,-73.4551C377.4671,-64.5054 388.7258,-53.547 398.7634,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"401.4221,-46.0734 406.1469,-36.5904 396.5397,-41.0572 401.4221,-46.0734\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.1\n",
    "\tdrop = 0.1\n",
    "\tepochs_drop = 25\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_callback(epoch, logs):\n",
    "    if epoch % 100 == 0 and epoch > -1: \n",
    "    # if epoch < -2:\n",
    "        print('----- Generating melody after Epoch: %d' % epoch)\n",
    "        \n",
    "        start_index = random.randint(0, 7000)\n",
    "        for diversity in [0.5]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            current_note_phrase = notes_corpus[start_index: start_index + n_time_steps]\n",
    "            current_interval_phrase = interval_corpus[start_index: start_index + n_time_steps]\n",
    "            current_note_name_phrase = note_name_corpus[start_index: start_index + n_time_steps]\n",
    "            current_length_phrase = length_corpus[start_index: start_index + n_time_steps]\n",
    "\n",
    "            phrases = {\n",
    "                'note_phrase': current_note_phrase, \n",
    "                'length_phrase': current_length_phrase,\n",
    "                'interval_phrase': current_interval_phrase,\n",
    "                'note_name_phrase': current_note_name_phrase,\n",
    "            }\n",
    "\n",
    "            generated_notes = []\n",
    "            generated_lengths = []\n",
    "            generated_notes.extend(current_note_phrase)\n",
    "            generated_lengths.extend(current_length_phrase)\n",
    "\n",
    "            # model, phrases,categorized_variables, lookup_indicies, n_time_steps, diversity, n_to_generate\n",
    "            for step in range(70):\n",
    "                encoded_prediction = make_encoded_prediction(\n",
    "                    model=model,\n",
    "                    phrases=phrases,\n",
    "                    categorized_variables=categorized_variables,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    n_time_steps=n_time_steps\n",
    "                )\n",
    "\n",
    "                predictions = decode_predictions(\n",
    "                    encoded_prediction=encoded_prediction,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    temperature=diversity\n",
    "                )\n",
    "\n",
    "                generated_notes.append(predictions['note_prediction']) \n",
    "                generated_lengths.append(predictions['length_prediction']) \n",
    "\n",
    "\n",
    "                last = generated_notes[0]\n",
    "                phrases['note_phrase'] = np.append(phrases['note_phrase'][1:], predictions['note_prediction'])\n",
    "                phrases['interval_phrase'] = map_midi_to_interval(phrases['note_phrase'], last)\n",
    "                phrases['note_name_phrase'] = map_midi_to_note_number(phrases['note_phrase'])\n",
    "                phrases['length_phrase'] = np.append(phrases['length_phrase'][1:], predictions['length_prediction'])\n",
    "                \n",
    "            play_generated_phrase(\n",
    "                generated_notes=generated_notes[10:],\n",
    "                generated_lengths=generated_lengths[10:],\n",
    "                player=player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(datetime.datetime.now()), histogram_freq=0, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "listen_callback = LambdaCallback(on_epoch_end=listen_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            TRAINING\n",
      "          **********************************\n",
      "Train on 7089 samples, validate on 3492 samples\n",
      "Epoch 1/1500\n",
      "7089/7089 [==============================] - 7s 949us/step - loss: 5.7209 - note_output_loss: 3.7914 - length_output_loss: 3.8591 - val_loss: 4.9842 - val_note_output_loss: 3.3293 - val_length_output_loss: 3.3099\n",
      "Epoch 2/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 4.7960 - note_output_loss: 3.1965 - length_output_loss: 3.1990 - val_loss: 4.8906 - val_note_output_loss: 3.2660 - val_length_output_loss: 3.2493\n",
      "Epoch 3/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 4.7486 - note_output_loss: 3.1647 - length_output_loss: 3.1678 - val_loss: 4.8682 - val_note_output_loss: 3.2528 - val_length_output_loss: 3.2308\n",
      "Epoch 4/1500\n",
      "7089/7089 [==============================] - 5s 696us/step - loss: 4.7317 - note_output_loss: 3.1519 - length_output_loss: 3.1598 - val_loss: 4.8405 - val_note_output_loss: 3.2290 - val_length_output_loss: 3.2229\n",
      "Epoch 5/1500\n",
      "7089/7089 [==============================] - 5s 689us/step - loss: 4.6981 - note_output_loss: 3.1200 - length_output_loss: 3.1563 - val_loss: 4.8168 - val_note_output_loss: 3.2032 - val_length_output_loss: 3.2271\n",
      "Epoch 6/1500\n",
      "7089/7089 [==============================] - 5s 707us/step - loss: 4.6406 - note_output_loss: 3.0633 - length_output_loss: 3.1545 - val_loss: 4.7516 - val_note_output_loss: 3.1334 - val_length_output_loss: 3.2363\n",
      "Epoch 7/1500\n",
      "7089/7089 [==============================] - 5s 711us/step - loss: 4.5728 - note_output_loss: 2.9974 - length_output_loss: 3.1509 - val_loss: 4.7065 - val_note_output_loss: 3.0932 - val_length_output_loss: 3.2266\n",
      "Epoch 8/1500\n",
      "7089/7089 [==============================] - 5s 726us/step - loss: 4.5049 - note_output_loss: 2.9332 - length_output_loss: 3.1435 - val_loss: 4.6681 - val_note_output_loss: 3.0543 - val_length_output_loss: 3.2277\n",
      "Epoch 9/1500\n",
      "7089/7089 [==============================] - 5s 710us/step - loss: 4.4425 - note_output_loss: 2.8713 - length_output_loss: 3.1425 - val_loss: 4.5936 - val_note_output_loss: 2.9692 - val_length_output_loss: 3.2490\n",
      "Epoch 10/1500\n",
      "7089/7089 [==============================] - 5s 710us/step - loss: 4.3928 - note_output_loss: 2.8233 - length_output_loss: 3.1390 - val_loss: 4.5596 - val_note_output_loss: 2.9421 - val_length_output_loss: 3.2349\n",
      "Epoch 11/1500\n",
      "7089/7089 [==============================] - 5s 746us/step - loss: 4.3545 - note_output_loss: 2.7863 - length_output_loss: 3.1364 - val_loss: 4.5269 - val_note_output_loss: 2.9006 - val_length_output_loss: 3.2526\n",
      "Epoch 12/1500\n",
      "7089/7089 [==============================] - 5s 736us/step - loss: 4.3118 - note_output_loss: 2.7452 - length_output_loss: 3.1331 - val_loss: 4.5321 - val_note_output_loss: 2.9057 - val_length_output_loss: 3.2529\n",
      "Epoch 13/1500\n",
      "7089/7089 [==============================] - 5s 708us/step - loss: 4.2860 - note_output_loss: 2.7183 - length_output_loss: 3.1354 - val_loss: 4.5451 - val_note_output_loss: 2.9216 - val_length_output_loss: 3.2470\n",
      "Epoch 14/1500\n",
      "7089/7089 [==============================] - 5s 741us/step - loss: 4.2579 - note_output_loss: 2.6919 - length_output_loss: 3.1319 - val_loss: 4.4831 - val_note_output_loss: 2.8586 - val_length_output_loss: 3.2489\n",
      "Epoch 15/1500\n",
      "7089/7089 [==============================] - 5s 724us/step - loss: 4.2427 - note_output_loss: 2.6775 - length_output_loss: 3.1304 - val_loss: 4.4937 - val_note_output_loss: 2.8667 - val_length_output_loss: 3.2539\n",
      "Epoch 16/1500\n",
      "7089/7089 [==============================] - 5s 754us/step - loss: 4.2160 - note_output_loss: 2.6525 - length_output_loss: 3.1269 - val_loss: 4.4738 - val_note_output_loss: 2.8499 - val_length_output_loss: 3.2478\n",
      "Epoch 17/1500\n",
      "7089/7089 [==============================] - 5s 739us/step - loss: 4.2003 - note_output_loss: 2.6404 - length_output_loss: 3.1199 - val_loss: 4.4762 - val_note_output_loss: 2.8543 - val_length_output_loss: 3.2438\n",
      "Epoch 18/1500\n",
      "7089/7089 [==============================] - 5s 736us/step - loss: 4.1856 - note_output_loss: 2.6285 - length_output_loss: 3.1142 - val_loss: 4.4742 - val_note_output_loss: 2.8528 - val_length_output_loss: 3.2428\n",
      "Epoch 19/1500\n",
      "7089/7089 [==============================] - 5s 737us/step - loss: 4.1714 - note_output_loss: 2.6139 - length_output_loss: 3.1149 - val_loss: 4.4792 - val_note_output_loss: 2.8573 - val_length_output_loss: 3.2437\n",
      "Epoch 20/1500\n",
      "7089/7089 [==============================] - 5s 695us/step - loss: 4.1615 - note_output_loss: 2.6057 - length_output_loss: 3.1117 - val_loss: 4.4725 - val_note_output_loss: 2.8497 - val_length_output_loss: 3.2457\n",
      "Epoch 21/1500\n",
      "7089/7089 [==============================] - 5s 715us/step - loss: 4.1478 - note_output_loss: 2.5943 - length_output_loss: 3.1070 - val_loss: 4.4869 - val_note_output_loss: 2.8662 - val_length_output_loss: 3.2413\n",
      "Epoch 22/1500\n",
      "7089/7089 [==============================] - 5s 700us/step - loss: 4.1394 - note_output_loss: 2.5881 - length_output_loss: 3.1028 - val_loss: 4.4745 - val_note_output_loss: 2.8493 - val_length_output_loss: 3.2506\n",
      "Epoch 23/1500\n",
      "7089/7089 [==============================] - 5s 694us/step - loss: 4.1258 - note_output_loss: 2.5746 - length_output_loss: 3.1024 - val_loss: 4.4858 - val_note_output_loss: 2.8629 - val_length_output_loss: 3.2458\n",
      "Epoch 24/1500\n",
      "7089/7089 [==============================] - 5s 681us/step - loss: 4.1128 - note_output_loss: 2.5624 - length_output_loss: 3.1008 - val_loss: 4.4673 - val_note_output_loss: 2.8466 - val_length_output_loss: 3.2413\n",
      "Epoch 25/1500\n",
      "7089/7089 [==============================] - 5s 714us/step - loss: 4.0990 - note_output_loss: 2.5516 - length_output_loss: 3.0948 - val_loss: 4.4768 - val_note_output_loss: 2.8557 - val_length_output_loss: 3.2423\n",
      "Epoch 26/1500\n",
      "7089/7089 [==============================] - 5s 737us/step - loss: 4.0876 - note_output_loss: 2.5416 - length_output_loss: 3.0919 - val_loss: 4.4666 - val_note_output_loss: 2.8481 - val_length_output_loss: 3.2371\n",
      "Epoch 27/1500\n",
      "7089/7089 [==============================] - 5s 705us/step - loss: 4.0795 - note_output_loss: 2.5350 - length_output_loss: 3.0890 - val_loss: 4.4619 - val_note_output_loss: 2.8457 - val_length_output_loss: 3.2323\n",
      "Epoch 28/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 4.0651 - note_output_loss: 2.5219 - length_output_loss: 3.0863 - val_loss: 4.5001 - val_note_output_loss: 2.8850 - val_length_output_loss: 3.2301\n",
      "Epoch 29/1500\n",
      "7089/7089 [==============================] - 5s 689us/step - loss: 4.0538 - note_output_loss: 2.5133 - length_output_loss: 3.0810 - val_loss: 4.4676 - val_note_output_loss: 2.8512 - val_length_output_loss: 3.2328\n",
      "Epoch 30/1500\n",
      "7089/7089 [==============================] - 5s 685us/step - loss: 4.0460 - note_output_loss: 2.5077 - length_output_loss: 3.0768 - val_loss: 4.4611 - val_note_output_loss: 2.8464 - val_length_output_loss: 3.2295\n",
      "Epoch 31/1500\n",
      "7089/7089 [==============================] - 5s 688us/step - loss: 4.0356 - note_output_loss: 2.5000 - length_output_loss: 3.0713 - val_loss: 4.4702 - val_note_output_loss: 2.8529 - val_length_output_loss: 3.2347\n",
      "Epoch 32/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 4.0281 - note_output_loss: 2.4933 - length_output_loss: 3.0697 - val_loss: 4.4659 - val_note_output_loss: 2.8509 - val_length_output_loss: 3.2300\n",
      "Epoch 33/1500\n",
      "7089/7089 [==============================] - 5s 684us/step - loss: 4.0125 - note_output_loss: 2.4807 - length_output_loss: 3.0636 - val_loss: 4.4759 - val_note_output_loss: 2.8587 - val_length_output_loss: 3.2345\n",
      "Epoch 34/1500\n",
      "7089/7089 [==============================] - 5s 678us/step - loss: 4.0066 - note_output_loss: 2.4766 - length_output_loss: 3.0601 - val_loss: 4.4770 - val_note_output_loss: 2.8651 - val_length_output_loss: 3.2238\n",
      "Epoch 35/1500\n",
      "7089/7089 [==============================] - 5s 698us/step - loss: 3.9930 - note_output_loss: 2.4654 - length_output_loss: 3.0552 - val_loss: 4.4714 - val_note_output_loss: 2.8602 - val_length_output_loss: 3.2225\n",
      "Epoch 36/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7089/7089 [==============================] - 5s 688us/step - loss: 3.9837 - note_output_loss: 2.4592 - length_output_loss: 3.0491 - val_loss: 4.4990 - val_note_output_loss: 2.8889 - val_length_output_loss: 3.2201\n",
      "Epoch 37/1500\n",
      "7089/7089 [==============================] - 5s 687us/step - loss: 3.9674 - note_output_loss: 2.4478 - length_output_loss: 3.0392 - val_loss: 4.4797 - val_note_output_loss: 2.8669 - val_length_output_loss: 3.2256\n",
      "Epoch 38/1500\n",
      "7089/7089 [==============================] - 5s 676us/step - loss: 3.9607 - note_output_loss: 2.4405 - length_output_loss: 3.0404 - val_loss: 4.4617 - val_note_output_loss: 2.8527 - val_length_output_loss: 3.2180\n",
      "Epoch 39/1500\n",
      "7089/7089 [==============================] - 5s 700us/step - loss: 3.9442 - note_output_loss: 2.4284 - length_output_loss: 3.0315 - val_loss: 4.4695 - val_note_output_loss: 2.8599 - val_length_output_loss: 3.2190\n",
      "Epoch 40/1500\n",
      "7089/7089 [==============================] - 5s 674us/step - loss: 3.9354 - note_output_loss: 2.4196 - length_output_loss: 3.0316 - val_loss: 4.4737 - val_note_output_loss: 2.8699 - val_length_output_loss: 3.2078\n",
      "Epoch 41/1500\n",
      "7089/7089 [==============================] - 5s 685us/step - loss: 3.9214 - note_output_loss: 2.4104 - length_output_loss: 3.0220 - val_loss: 4.4915 - val_note_output_loss: 2.8875 - val_length_output_loss: 3.2080\n",
      "Epoch 42/1500\n",
      "7089/7089 [==============================] - 5s 741us/step - loss: 3.9153 - note_output_loss: 2.4049 - length_output_loss: 3.0208 - val_loss: 4.4740 - val_note_output_loss: 2.8665 - val_length_output_loss: 3.2150\n",
      "Epoch 43/1500\n",
      "7089/7089 [==============================] - 5s 698us/step - loss: 3.8977 - note_output_loss: 2.3915 - length_output_loss: 3.0122 - val_loss: 4.4924 - val_note_output_loss: 2.8919 - val_length_output_loss: 3.2010\n",
      "Epoch 44/1500\n",
      "7089/7089 [==============================] - 5s 709us/step - loss: 3.8881 - note_output_loss: 2.3836 - length_output_loss: 3.0089 - val_loss: 4.4780 - val_note_output_loss: 2.8712 - val_length_output_loss: 3.2136\n",
      "Epoch 45/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 3.8803 - note_output_loss: 2.3783 - length_output_loss: 3.0040 - val_loss: 4.4766 - val_note_output_loss: 2.8744 - val_length_output_loss: 3.2044\n",
      "Epoch 46/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 3.8633 - note_output_loss: 2.3642 - length_output_loss: 2.9982 - val_loss: 4.4939 - val_note_output_loss: 2.8941 - val_length_output_loss: 3.1996\n",
      "Epoch 47/1500\n",
      "7089/7089 [==============================] - 5s 693us/step - loss: 3.8487 - note_output_loss: 2.3546 - length_output_loss: 2.9882 - val_loss: 4.4807 - val_note_output_loss: 2.8834 - val_length_output_loss: 3.1945\n",
      "Epoch 48/1500\n",
      "7089/7089 [==============================] - 5s 678us/step - loss: 3.8409 - note_output_loss: 2.3465 - length_output_loss: 2.9889 - val_loss: 4.4714 - val_note_output_loss: 2.8732 - val_length_output_loss: 3.1963\n",
      "Epoch 49/1500\n",
      "7089/7089 [==============================] - 5s 737us/step - loss: 3.8264 - note_output_loss: 2.3352 - length_output_loss: 2.9824 - val_loss: 4.4784 - val_note_output_loss: 2.8797 - val_length_output_loss: 3.1974\n",
      "Epoch 50/1500\n",
      "7089/7089 [==============================] - 5s 701us/step - loss: 3.8150 - note_output_loss: 2.3263 - length_output_loss: 2.9773 - val_loss: 4.4785 - val_note_output_loss: 2.8806 - val_length_output_loss: 3.1957\n",
      "Epoch 51/1500\n",
      "7089/7089 [==============================] - 5s 709us/step - loss: 3.8044 - note_output_loss: 2.3187 - length_output_loss: 2.9715 - val_loss: 4.4965 - val_note_output_loss: 2.9040 - val_length_output_loss: 3.1849\n",
      "Epoch 52/1500\n",
      "7089/7089 [==============================] - 5s 729us/step - loss: 3.7842 - note_output_loss: 2.3014 - length_output_loss: 2.9656 - val_loss: 4.5016 - val_note_output_loss: 2.8997 - val_length_output_loss: 3.2038\n",
      "Epoch 53/1500\n",
      "7089/7089 [==============================] - 5s 756us/step - loss: 3.7752 - note_output_loss: 2.2930 - length_output_loss: 2.9644 - val_loss: 4.4816 - val_note_output_loss: 2.8863 - val_length_output_loss: 3.1906\n",
      "Epoch 54/1500\n",
      "7089/7089 [==============================] - 5s 717us/step - loss: 3.7682 - note_output_loss: 2.2911 - length_output_loss: 2.9543 - val_loss: 4.4831 - val_note_output_loss: 2.8887 - val_length_output_loss: 3.1887\n",
      "Epoch 55/1500\n",
      "7089/7089 [==============================] - 5s 734us/step - loss: 3.7579 - note_output_loss: 2.2806 - length_output_loss: 2.9547 - val_loss: 4.4904 - val_note_output_loss: 2.8971 - val_length_output_loss: 3.1865\n",
      "Epoch 56/1500\n",
      "7089/7089 [==============================] - 5s 721us/step - loss: 3.7443 - note_output_loss: 2.2680 - length_output_loss: 2.9526 - val_loss: 4.4889 - val_note_output_loss: 2.8932 - val_length_output_loss: 3.1914\n",
      "Epoch 57/1500\n",
      "7089/7089 [==============================] - 5s 695us/step - loss: 3.7339 - note_output_loss: 2.2613 - length_output_loss: 2.9450 - val_loss: 4.5034 - val_note_output_loss: 2.9094 - val_length_output_loss: 3.1880\n",
      "Epoch 58/1500\n",
      "7089/7089 [==============================] - 5s 719us/step - loss: 3.7192 - note_output_loss: 2.2496 - length_output_loss: 2.9393 - val_loss: 4.4891 - val_note_output_loss: 2.8944 - val_length_output_loss: 3.1894\n",
      "Epoch 59/1500\n",
      "7089/7089 [==============================] - 5s 706us/step - loss: 3.7117 - note_output_loss: 2.2427 - length_output_loss: 2.9381 - val_loss: 4.4981 - val_note_output_loss: 2.9030 - val_length_output_loss: 3.1902\n",
      "Epoch 60/1500\n",
      "7089/7089 [==============================] - 5s 705us/step - loss: 3.7035 - note_output_loss: 2.2352 - length_output_loss: 2.9366 - val_loss: 4.5251 - val_note_output_loss: 2.9291 - val_length_output_loss: 3.1921\n",
      "Epoch 61/1500\n",
      "7089/7089 [==============================] - 5s 690us/step - loss: 3.6852 - note_output_loss: 2.2195 - length_output_loss: 2.9315 - val_loss: 4.5035 - val_note_output_loss: 2.9088 - val_length_output_loss: 3.1895\n",
      "Epoch 62/1500\n",
      "7089/7089 [==============================] - 5s 690us/step - loss: 3.6935 - note_output_loss: 2.2265 - length_output_loss: 2.9339 - val_loss: 4.5225 - val_note_output_loss: 2.9275 - val_length_output_loss: 3.1900\n",
      "Epoch 63/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 3.6680 - note_output_loss: 2.2051 - length_output_loss: 2.9259 - val_loss: 4.5404 - val_note_output_loss: 2.9443 - val_length_output_loss: 3.1923\n",
      "Epoch 64/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 3.6678 - note_output_loss: 2.2064 - length_output_loss: 2.9230 - val_loss: 4.5493 - val_note_output_loss: 2.9535 - val_length_output_loss: 3.1916\n",
      "Epoch 65/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 3.6446 - note_output_loss: 2.1835 - length_output_loss: 2.9222 - val_loss: 4.5525 - val_note_output_loss: 2.9556 - val_length_output_loss: 3.1937\n",
      "Epoch 66/1500\n",
      "7089/7089 [==============================] - 5s 736us/step - loss: 3.6392 - note_output_loss: 2.1813 - length_output_loss: 2.9158 - val_loss: 4.5342 - val_note_output_loss: 2.9379 - val_length_output_loss: 3.1927\n",
      "Epoch 67/1500\n",
      "7089/7089 [==============================] - 6s 835us/step - loss: 3.6381 - note_output_loss: 2.1789 - length_output_loss: 2.9185 - val_loss: 4.5472 - val_note_output_loss: 2.9521 - val_length_output_loss: 3.1901\n",
      "Epoch 68/1500\n",
      "7089/7089 [==============================] - 5s 744us/step - loss: 3.6093 - note_output_loss: 2.1525 - length_output_loss: 2.9136 - val_loss: 4.5533 - val_note_output_loss: 2.9537 - val_length_output_loss: 3.1991\n",
      "Epoch 69/1500\n",
      "7089/7089 [==============================] - 6s 805us/step - loss: 3.6114 - note_output_loss: 2.1532 - length_output_loss: 2.9163 - val_loss: 4.5701 - val_note_output_loss: 2.9729 - val_length_output_loss: 3.1944\n",
      "Epoch 70/1500\n",
      "7089/7089 [==============================] - 5s 762us/step - loss: 3.5993 - note_output_loss: 2.1451 - length_output_loss: 2.9084 - val_loss: 4.5669 - val_note_output_loss: 2.9613 - val_length_output_loss: 3.2113\n",
      "Epoch 71/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 3.5983 - note_output_loss: 2.1465 - length_output_loss: 2.9036 - val_loss: 4.5897 - val_note_output_loss: 2.9849 - val_length_output_loss: 3.2096\n",
      "Epoch 72/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7089/7089 [==============================] - 5s 712us/step - loss: 3.5828 - note_output_loss: 2.1319 - length_output_loss: 2.9018 - val_loss: 4.5684 - val_note_output_loss: 2.9639 - val_length_output_loss: 3.2089\n",
      "Epoch 73/1500\n",
      "7089/7089 [==============================] - 5s 679us/step - loss: 3.5814 - note_output_loss: 2.1315 - length_output_loss: 2.8997 - val_loss: 4.5858 - val_note_output_loss: 2.9886 - val_length_output_loss: 3.1945\n",
      "Epoch 74/1500\n",
      "7089/7089 [==============================] - 5s 723us/step - loss: 3.5648 - note_output_loss: 2.1164 - length_output_loss: 2.8966 - val_loss: 4.5952 - val_note_output_loss: 2.9948 - val_length_output_loss: 3.2008\n",
      "Epoch 75/1500\n",
      "7089/7089 [==============================] - 5s 688us/step - loss: 3.5552 - note_output_loss: 2.1103 - length_output_loss: 2.8897 - val_loss: 4.5815 - val_note_output_loss: 2.9828 - val_length_output_loss: 3.1974\n",
      "Epoch 76/1500\n",
      "7089/7089 [==============================] - 5s 689us/step - loss: 3.5481 - note_output_loss: 2.1017 - length_output_loss: 2.8927 - val_loss: 4.6191 - val_note_output_loss: 3.0170 - val_length_output_loss: 3.2042\n",
      "Epoch 77/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 3.5437 - note_output_loss: 2.0989 - length_output_loss: 2.8896 - val_loss: 4.6002 - val_note_output_loss: 3.0006 - val_length_output_loss: 3.1992\n",
      "Epoch 78/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.5348 - note_output_loss: 2.0925 - length_output_loss: 2.8847 - val_loss: 4.6293 - val_note_output_loss: 3.0258 - val_length_output_loss: 3.2070\n",
      "Epoch 79/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 3.5150 - note_output_loss: 2.0723 - length_output_loss: 2.8853 - val_loss: 4.6648 - val_note_output_loss: 3.0585 - val_length_output_loss: 3.2126\n",
      "Epoch 80/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.5213 - note_output_loss: 2.0812 - length_output_loss: 2.8802 - val_loss: 4.6026 - val_note_output_loss: 2.9970 - val_length_output_loss: 3.2112\n",
      "Epoch 81/1500\n",
      "7089/7089 [==============================] - 5s 639us/step - loss: 3.4961 - note_output_loss: 2.0560 - length_output_loss: 2.8800 - val_loss: 4.6491 - val_note_output_loss: 3.0422 - val_length_output_loss: 3.2138\n",
      "Epoch 82/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 3.4986 - note_output_loss: 2.0612 - length_output_loss: 2.8748 - val_loss: 4.6527 - val_note_output_loss: 3.0455 - val_length_output_loss: 3.2145\n",
      "Epoch 83/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 3.4873 - note_output_loss: 2.0486 - length_output_loss: 2.8774 - val_loss: 4.6781 - val_note_output_loss: 3.0703 - val_length_output_loss: 3.2156\n",
      "Epoch 84/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 3.4768 - note_output_loss: 2.0418 - length_output_loss: 2.8700 - val_loss: 4.6634 - val_note_output_loss: 3.0563 - val_length_output_loss: 3.2142\n",
      "Epoch 85/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.4751 - note_output_loss: 2.0415 - length_output_loss: 2.8671 - val_loss: 4.6795 - val_note_output_loss: 3.0690 - val_length_output_loss: 3.2211\n",
      "Epoch 86/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 3.4726 - note_output_loss: 2.0394 - length_output_loss: 2.8664 - val_loss: 4.7023 - val_note_output_loss: 3.0899 - val_length_output_loss: 3.2249\n",
      "Epoch 87/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 3.4555 - note_output_loss: 2.0251 - length_output_loss: 2.8609 - val_loss: 4.6646 - val_note_output_loss: 3.0559 - val_length_output_loss: 3.2175\n",
      "Epoch 88/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 3.4451 - note_output_loss: 2.0156 - length_output_loss: 2.8590 - val_loss: 4.6776 - val_note_output_loss: 3.0706 - val_length_output_loss: 3.2139\n",
      "Epoch 89/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 3.4280 - note_output_loss: 1.9984 - length_output_loss: 2.8592 - val_loss: 4.7163 - val_note_output_loss: 3.1027 - val_length_output_loss: 3.2272\n",
      "Epoch 90/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 3.4328 - note_output_loss: 2.0043 - length_output_loss: 2.8570 - val_loss: 4.7262 - val_note_output_loss: 3.1120 - val_length_output_loss: 3.2284\n",
      "Epoch 91/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.4250 - note_output_loss: 1.9985 - length_output_loss: 2.8530 - val_loss: 4.7413 - val_note_output_loss: 3.1227 - val_length_output_loss: 3.2372\n",
      "Epoch 92/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.4132 - note_output_loss: 1.9824 - length_output_loss: 2.8615 - val_loss: 4.6970 - val_note_output_loss: 3.0805 - val_length_output_loss: 3.2330\n",
      "Epoch 93/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 3.4092 - note_output_loss: 1.9839 - length_output_loss: 2.8507 - val_loss: 4.7289 - val_note_output_loss: 3.1133 - val_length_output_loss: 3.2312\n",
      "Epoch 94/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 3.3951 - note_output_loss: 1.9708 - length_output_loss: 2.8488 - val_loss: 4.7699 - val_note_output_loss: 3.1546 - val_length_output_loss: 3.2306\n",
      "Epoch 95/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.3878 - note_output_loss: 1.9637 - length_output_loss: 2.8483 - val_loss: 4.7645 - val_note_output_loss: 3.1462 - val_length_output_loss: 3.2366\n",
      "Epoch 96/1500\n",
      "7089/7089 [==============================] - 5s 637us/step - loss: 3.3732 - note_output_loss: 1.9520 - length_output_loss: 2.8424 - val_loss: 4.7505 - val_note_output_loss: 3.1330 - val_length_output_loss: 3.2350\n",
      "Epoch 97/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.3818 - note_output_loss: 1.9607 - length_output_loss: 2.8422 - val_loss: 4.7957 - val_note_output_loss: 3.1782 - val_length_output_loss: 3.2350\n",
      "Epoch 98/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 3.3773 - note_output_loss: 1.9567 - length_output_loss: 2.8411 - val_loss: 4.7447 - val_note_output_loss: 3.1283 - val_length_output_loss: 3.2328\n",
      "Epoch 99/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 3.3602 - note_output_loss: 1.9425 - length_output_loss: 2.8355 - val_loss: 4.7743 - val_note_output_loss: 3.1556 - val_length_output_loss: 3.2375\n",
      "Epoch 100/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 3.3434 - note_output_loss: 1.9261 - length_output_loss: 2.8347 - val_loss: 4.7834 - val_note_output_loss: 3.1607 - val_length_output_loss: 3.2454\n",
      "Epoch 101/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 3.3433 - note_output_loss: 1.9280 - length_output_loss: 2.8307 - val_loss: 4.7953 - val_note_output_loss: 3.1741 - val_length_output_loss: 3.2423\n",
      "Epoch 102/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 3.3269 - note_output_loss: 1.9129 - length_output_loss: 2.8281 - val_loss: 4.7945 - val_note_output_loss: 3.1729 - val_length_output_loss: 3.2431\n",
      "Epoch 103/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 3.3176 - note_output_loss: 1.9053 - length_output_loss: 2.8246 - val_loss: 4.8357 - val_note_output_loss: 3.2140 - val_length_output_loss: 3.2434\n",
      "Epoch 104/1500\n",
      "7089/7089 [==============================] - 5s 666us/step - loss: 3.3094 - note_output_loss: 1.8982 - length_output_loss: 2.8223 - val_loss: 4.7990 - val_note_output_loss: 3.1796 - val_length_output_loss: 3.2387\n",
      "Epoch 105/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 3.3129 - note_output_loss: 1.9012 - length_output_loss: 2.8235 - val_loss: 4.8534 - val_note_output_loss: 3.2314 - val_length_output_loss: 3.2439\n",
      "Epoch 106/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 3.3048 - note_output_loss: 1.8938 - length_output_loss: 2.8220 - val_loss: 4.8146 - val_note_output_loss: 3.1920 - val_length_output_loss: 3.2451\n",
      "Epoch 107/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.2969 - note_output_loss: 1.8864 - length_output_loss: 2.8210 - val_loss: 4.8494 - val_note_output_loss: 3.2266 - val_length_output_loss: 3.2456\n",
      "Epoch 108/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7089/7089 [==============================] - 5s 644us/step - loss: 3.2992 - note_output_loss: 1.8874 - length_output_loss: 2.8236 - val_loss: 4.8395 - val_note_output_loss: 3.2137 - val_length_output_loss: 3.2518\n",
      "Epoch 109/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 3.2860 - note_output_loss: 1.8747 - length_output_loss: 2.8227 - val_loss: 4.8400 - val_note_output_loss: 3.2122 - val_length_output_loss: 3.2556\n",
      "Epoch 110/1500\n",
      "7089/7089 [==============================] - 5s 637us/step - loss: 3.2762 - note_output_loss: 1.8662 - length_output_loss: 2.8199 - val_loss: 4.8486 - val_note_output_loss: 3.2225 - val_length_output_loss: 3.2522\n",
      "Epoch 111/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 3.2722 - note_output_loss: 1.8643 - length_output_loss: 2.8157 - val_loss: 4.8876 - val_note_output_loss: 3.2630 - val_length_output_loss: 3.2492\n",
      "Epoch 112/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 3.2606 - note_output_loss: 1.8549 - length_output_loss: 2.8112 - val_loss: 4.8758 - val_note_output_loss: 3.2483 - val_length_output_loss: 3.2551\n",
      "Epoch 113/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 3.2568 - note_output_loss: 1.8517 - length_output_loss: 2.8102 - val_loss: 4.8939 - val_note_output_loss: 3.2637 - val_length_output_loss: 3.2604\n",
      "Epoch 114/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 3.2483 - note_output_loss: 1.8444 - length_output_loss: 2.8078 - val_loss: 4.8930 - val_note_output_loss: 3.2632 - val_length_output_loss: 3.2597\n",
      "Epoch 115/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.2441 - note_output_loss: 1.8396 - length_output_loss: 2.8090 - val_loss: 4.8803 - val_note_output_loss: 3.2527 - val_length_output_loss: 3.2551\n",
      "Epoch 116/1500\n",
      "7089/7089 [==============================] - 5s 638us/step - loss: 3.2183 - note_output_loss: 1.8173 - length_output_loss: 2.8021 - val_loss: 4.9354 - val_note_output_loss: 3.3041 - val_length_output_loss: 3.2627\n",
      "Epoch 117/1500\n",
      "7089/7089 [==============================] - 5s 662us/step - loss: 3.2225 - note_output_loss: 1.8248 - length_output_loss: 2.7954 - val_loss: 4.8955 - val_note_output_loss: 3.2579 - val_length_output_loss: 3.2752\n",
      "Epoch 118/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 3.2151 - note_output_loss: 1.8148 - length_output_loss: 2.8006 - val_loss: 4.9372 - val_note_output_loss: 3.2992 - val_length_output_loss: 3.2760\n",
      "Epoch 119/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 3.2158 - note_output_loss: 1.8148 - length_output_loss: 2.8020 - val_loss: 4.9255 - val_note_output_loss: 3.2921 - val_length_output_loss: 3.2667\n",
      "Epoch 120/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 3.1920 - note_output_loss: 1.7937 - length_output_loss: 2.7966 - val_loss: 4.9630 - val_note_output_loss: 3.3241 - val_length_output_loss: 3.2779\n",
      "Epoch 121/1500\n",
      "7089/7089 [==============================] - 5s 729us/step - loss: 3.1859 - note_output_loss: 1.7888 - length_output_loss: 2.7942 - val_loss: 4.9533 - val_note_output_loss: 3.3166 - val_length_output_loss: 3.2734\n",
      "Epoch 122/1500\n",
      "7089/7089 [==============================] - 5s 698us/step - loss: 3.2091 - note_output_loss: 1.8087 - length_output_loss: 2.8008 - val_loss: 4.9697 - val_note_output_loss: 3.3328 - val_length_output_loss: 3.2738\n",
      "Epoch 123/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 3.1850 - note_output_loss: 1.7888 - length_output_loss: 2.7925 - val_loss: 4.9530 - val_note_output_loss: 3.3160 - val_length_output_loss: 3.2741\n",
      "Epoch 124/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 3.1742 - note_output_loss: 1.7788 - length_output_loss: 2.7910 - val_loss: 4.9989 - val_note_output_loss: 3.3598 - val_length_output_loss: 3.2783\n",
      "Epoch 125/1500\n",
      "7089/7089 [==============================] - 5s 732us/step - loss: 3.1862 - note_output_loss: 1.7877 - length_output_loss: 2.7971 - val_loss: 4.9889 - val_note_output_loss: 3.3498 - val_length_output_loss: 3.2782\n",
      "Epoch 126/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 3.1608 - note_output_loss: 1.7680 - length_output_loss: 2.7855 - val_loss: 4.9946 - val_note_output_loss: 3.3516 - val_length_output_loss: 3.2859\n",
      "Epoch 127/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 3.1655 - note_output_loss: 1.7731 - length_output_loss: 2.7848 - val_loss: 5.0068 - val_note_output_loss: 3.3676 - val_length_output_loss: 3.2784\n",
      "Epoch 128/1500\n",
      "7089/7089 [==============================] - 5s 669us/step - loss: 3.1474 - note_output_loss: 1.7573 - length_output_loss: 2.7802 - val_loss: 5.0136 - val_note_output_loss: 3.3718 - val_length_output_loss: 3.2836\n",
      "Epoch 129/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 3.1399 - note_output_loss: 1.7460 - length_output_loss: 2.7877 - val_loss: 5.0253 - val_note_output_loss: 3.3859 - val_length_output_loss: 3.2788\n",
      "Epoch 130/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 3.1433 - note_output_loss: 1.7548 - length_output_loss: 2.7770 - val_loss: 4.9936 - val_note_output_loss: 3.3536 - val_length_output_loss: 3.2801\n",
      "Epoch 131/1500\n",
      "7089/7089 [==============================] - 5s 674us/step - loss: 3.1252 - note_output_loss: 1.7330 - length_output_loss: 2.7844 - val_loss: 5.0097 - val_note_output_loss: 3.3647 - val_length_output_loss: 3.2900\n",
      "Epoch 132/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 3.1291 - note_output_loss: 1.7415 - length_output_loss: 2.7752 - val_loss: 5.0059 - val_note_output_loss: 3.3641 - val_length_output_loss: 3.2834\n",
      "Epoch 133/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 3.1106 - note_output_loss: 1.7216 - length_output_loss: 2.7780 - val_loss: 5.0487 - val_note_output_loss: 3.4032 - val_length_output_loss: 3.2909\n",
      "Epoch 134/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 3.1154 - note_output_loss: 1.7288 - length_output_loss: 2.7731 - val_loss: 5.0567 - val_note_output_loss: 3.4114 - val_length_output_loss: 3.2906\n",
      "Epoch 135/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 3.0929 - note_output_loss: 1.7062 - length_output_loss: 2.7733 - val_loss: 5.0712 - val_note_output_loss: 3.4192 - val_length_output_loss: 3.3041\n",
      "Epoch 136/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.0887 - note_output_loss: 1.7003 - length_output_loss: 2.7768 - val_loss: 5.1093 - val_note_output_loss: 3.4570 - val_length_output_loss: 3.3046\n",
      "Epoch 137/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 3.1041 - note_output_loss: 1.7195 - length_output_loss: 2.7692 - val_loss: 5.0869 - val_note_output_loss: 3.4378 - val_length_output_loss: 3.2983\n",
      "Epoch 138/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.0832 - note_output_loss: 1.7012 - length_output_loss: 2.7640 - val_loss: 5.0836 - val_note_output_loss: 3.4320 - val_length_output_loss: 3.3031\n",
      "Epoch 139/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 3.0792 - note_output_loss: 1.6973 - length_output_loss: 2.7636 - val_loss: 5.0666 - val_note_output_loss: 3.4191 - val_length_output_loss: 3.2949\n",
      "Epoch 140/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 3.0709 - note_output_loss: 1.6909 - length_output_loss: 2.7600 - val_loss: 5.1170 - val_note_output_loss: 3.4663 - val_length_output_loss: 3.3013\n",
      "Epoch 141/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 3.0663 - note_output_loss: 1.6828 - length_output_loss: 2.7671 - val_loss: 5.1370 - val_note_output_loss: 3.4868 - val_length_output_loss: 3.3005\n",
      "Epoch 142/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 3.0583 - note_output_loss: 1.6810 - length_output_loss: 2.7548 - val_loss: 5.1393 - val_note_output_loss: 3.4853 - val_length_output_loss: 3.3080\n",
      "Epoch 143/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 3.0603 - note_output_loss: 1.6802 - length_output_loss: 2.7603 - val_loss: 5.1322 - val_note_output_loss: 3.4761 - val_length_output_loss: 3.3122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 3.0544 - note_output_loss: 1.6758 - length_output_loss: 2.7571 - val_loss: 5.1188 - val_note_output_loss: 3.4655 - val_length_output_loss: 3.3066\n",
      "Epoch 145/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 3.0450 - note_output_loss: 1.6665 - length_output_loss: 2.7570 - val_loss: 5.1707 - val_note_output_loss: 3.5083 - val_length_output_loss: 3.3246\n",
      "Epoch 146/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 3.0391 - note_output_loss: 1.6590 - length_output_loss: 2.7602 - val_loss: 5.1700 - val_note_output_loss: 3.5097 - val_length_output_loss: 3.3206\n",
      "Epoch 147/1500\n",
      "7089/7089 [==============================] - 5s 662us/step - loss: 3.0394 - note_output_loss: 1.6621 - length_output_loss: 2.7546 - val_loss: 5.1505 - val_note_output_loss: 3.4929 - val_length_output_loss: 3.3152\n",
      "Epoch 148/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 3.0191 - note_output_loss: 1.6443 - length_output_loss: 2.7496 - val_loss: 5.1907 - val_note_output_loss: 3.5291 - val_length_output_loss: 3.3232\n",
      "Epoch 149/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 3.0304 - note_output_loss: 1.6555 - length_output_loss: 2.7498 - val_loss: 5.1549 - val_note_output_loss: 3.4984 - val_length_output_loss: 3.3131\n",
      "Epoch 150/1500\n",
      "7089/7089 [==============================] - 5s 662us/step - loss: 3.0230 - note_output_loss: 1.6503 - length_output_loss: 2.7455 - val_loss: 5.2048 - val_note_output_loss: 3.5472 - val_length_output_loss: 3.3152\n",
      "Epoch 151/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 3.0036 - note_output_loss: 1.6282 - length_output_loss: 2.7508 - val_loss: 5.2363 - val_note_output_loss: 3.5747 - val_length_output_loss: 3.3231\n",
      "Epoch 152/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 3.0002 - note_output_loss: 1.6265 - length_output_loss: 2.7475 - val_loss: 5.2189 - val_note_output_loss: 3.5541 - val_length_output_loss: 3.3297\n",
      "Epoch 153/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 2.9842 - note_output_loss: 1.6137 - length_output_loss: 2.7410 - val_loss: 5.2206 - val_note_output_loss: 3.5537 - val_length_output_loss: 3.3339\n",
      "Epoch 154/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.9873 - note_output_loss: 1.6148 - length_output_loss: 2.7450 - val_loss: 5.2096 - val_note_output_loss: 3.5501 - val_length_output_loss: 3.3190\n",
      "Epoch 155/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.9878 - note_output_loss: 1.6176 - length_output_loss: 2.7405 - val_loss: 5.2035 - val_note_output_loss: 3.5419 - val_length_output_loss: 3.3232\n",
      "Epoch 156/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 2.9735 - note_output_loss: 1.6043 - length_output_loss: 2.7385 - val_loss: 5.1995 - val_note_output_loss: 3.5422 - val_length_output_loss: 3.3145\n",
      "Epoch 157/1500\n",
      "7089/7089 [==============================] - 5s 724us/step - loss: 2.9758 - note_output_loss: 1.6073 - length_output_loss: 2.7369 - val_loss: 5.2315 - val_note_output_loss: 3.5707 - val_length_output_loss: 3.3216\n",
      "Epoch 158/1500\n",
      "7089/7089 [==============================] - 5s 679us/step - loss: 2.9632 - note_output_loss: 1.5943 - length_output_loss: 2.7378 - val_loss: 5.2671 - val_note_output_loss: 3.6057 - val_length_output_loss: 3.3228\n",
      "Epoch 159/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 2.9619 - note_output_loss: 1.5937 - length_output_loss: 2.7364 - val_loss: 5.2770 - val_note_output_loss: 3.6106 - val_length_output_loss: 3.3329\n",
      "Epoch 160/1500\n",
      "7089/7089 [==============================] - 5s 669us/step - loss: 2.9390 - note_output_loss: 1.5727 - length_output_loss: 2.7327 - val_loss: 5.2887 - val_note_output_loss: 3.6200 - val_length_output_loss: 3.3374\n",
      "Epoch 161/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.9607 - note_output_loss: 1.5952 - length_output_loss: 2.7309 - val_loss: 5.2584 - val_note_output_loss: 3.5922 - val_length_output_loss: 3.3324\n",
      "Epoch 162/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.9355 - note_output_loss: 1.5715 - length_output_loss: 2.7279 - val_loss: 5.3257 - val_note_output_loss: 3.6519 - val_length_output_loss: 3.3475\n",
      "Epoch 163/1500\n",
      "7089/7089 [==============================] - 5s 662us/step - loss: 2.9387 - note_output_loss: 1.5727 - length_output_loss: 2.7322 - val_loss: 5.2794 - val_note_output_loss: 3.6093 - val_length_output_loss: 3.3402\n",
      "Epoch 164/1500\n",
      "7089/7089 [==============================] - 5s 666us/step - loss: 2.9156 - note_output_loss: 1.5480 - length_output_loss: 2.7352 - val_loss: 5.2985 - val_note_output_loss: 3.6346 - val_length_output_loss: 3.3277\n",
      "Epoch 165/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 2.9332 - note_output_loss: 1.5710 - length_output_loss: 2.7244 - val_loss: 5.3235 - val_note_output_loss: 3.6518 - val_length_output_loss: 3.3433\n",
      "Epoch 166/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 2.9218 - note_output_loss: 1.5599 - length_output_loss: 2.7239 - val_loss: 5.2965 - val_note_output_loss: 3.6256 - val_length_output_loss: 3.3418\n",
      "Epoch 167/1500\n",
      "7089/7089 [==============================] - 5s 667us/step - loss: 2.9154 - note_output_loss: 1.5522 - length_output_loss: 2.7264 - val_loss: 5.3293 - val_note_output_loss: 3.6575 - val_length_output_loss: 3.3435\n",
      "Epoch 168/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 2.9059 - note_output_loss: 1.5464 - length_output_loss: 2.7189 - val_loss: 5.3531 - val_note_output_loss: 3.6831 - val_length_output_loss: 3.3400\n",
      "Epoch 169/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 2.8995 - note_output_loss: 1.5407 - length_output_loss: 2.7175 - val_loss: 5.3785 - val_note_output_loss: 3.7031 - val_length_output_loss: 3.3508\n",
      "Epoch 170/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 2.8977 - note_output_loss: 1.5391 - length_output_loss: 2.7172 - val_loss: 5.3867 - val_note_output_loss: 3.7107 - val_length_output_loss: 3.3519\n",
      "Epoch 171/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.8921 - note_output_loss: 1.5342 - length_output_loss: 2.7159 - val_loss: 5.3791 - val_note_output_loss: 3.7025 - val_length_output_loss: 3.3531\n",
      "Epoch 172/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 2.8758 - note_output_loss: 1.5161 - length_output_loss: 2.7194 - val_loss: 5.4363 - val_note_output_loss: 3.7596 - val_length_output_loss: 3.3533\n",
      "Epoch 173/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.8747 - note_output_loss: 1.5176 - length_output_loss: 2.7143 - val_loss: 5.4094 - val_note_output_loss: 3.7282 - val_length_output_loss: 3.3625\n",
      "Epoch 174/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.8703 - note_output_loss: 1.5099 - length_output_loss: 2.7208 - val_loss: 5.3810 - val_note_output_loss: 3.7039 - val_length_output_loss: 3.3542\n",
      "Epoch 175/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 2.8774 - note_output_loss: 1.5218 - length_output_loss: 2.7112 - val_loss: 5.3966 - val_note_output_loss: 3.7155 - val_length_output_loss: 3.3621\n",
      "Epoch 176/1500\n",
      "7089/7089 [==============================] - 5s 667us/step - loss: 2.8582 - note_output_loss: 1.5039 - length_output_loss: 2.7087 - val_loss: 5.4255 - val_note_output_loss: 3.7449 - val_length_output_loss: 3.3611\n",
      "Epoch 177/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 2.8688 - note_output_loss: 1.5140 - length_output_loss: 2.7097 - val_loss: 5.4318 - val_note_output_loss: 3.7528 - val_length_output_loss: 3.3582\n",
      "Epoch 178/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.8599 - note_output_loss: 1.5070 - length_output_loss: 2.7058 - val_loss: 5.4187 - val_note_output_loss: 3.7378 - val_length_output_loss: 3.3619\n",
      "Epoch 179/1500\n",
      "7089/7089 [==============================] - 5s 638us/step - loss: 2.8353 - note_output_loss: 1.4796 - length_output_loss: 2.7113 - val_loss: 5.4891 - val_note_output_loss: 3.8032 - val_length_output_loss: 3.3719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.8421 - note_output_loss: 1.4908 - length_output_loss: 2.7027 - val_loss: 5.4325 - val_note_output_loss: 3.7477 - val_length_output_loss: 3.3696\n",
      "Epoch 181/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 2.8416 - note_output_loss: 1.4904 - length_output_loss: 2.7023 - val_loss: 5.4525 - val_note_output_loss: 3.7650 - val_length_output_loss: 3.3750\n",
      "Epoch 182/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 2.8249 - note_output_loss: 1.4755 - length_output_loss: 2.6987 - val_loss: 5.4910 - val_note_output_loss: 3.8050 - val_length_output_loss: 3.3719\n",
      "Epoch 183/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.8189 - note_output_loss: 1.4721 - length_output_loss: 2.6936 - val_loss: 5.5026 - val_note_output_loss: 3.8166 - val_length_output_loss: 3.3721\n",
      "Epoch 184/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.8266 - note_output_loss: 1.4760 - length_output_loss: 2.7012 - val_loss: 5.5140 - val_note_output_loss: 3.8219 - val_length_output_loss: 3.3841\n",
      "Epoch 185/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 2.8192 - note_output_loss: 1.4702 - length_output_loss: 2.6980 - val_loss: 5.4782 - val_note_output_loss: 3.7910 - val_length_output_loss: 3.3745\n",
      "Epoch 186/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 2.8128 - note_output_loss: 1.4660 - length_output_loss: 2.6936 - val_loss: 5.5320 - val_note_output_loss: 3.8385 - val_length_output_loss: 3.3870\n",
      "Epoch 187/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 2.8033 - note_output_loss: 1.4527 - length_output_loss: 2.7013 - val_loss: 5.5292 - val_note_output_loss: 3.8383 - val_length_output_loss: 3.3818\n",
      "Epoch 188/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.7982 - note_output_loss: 1.4523 - length_output_loss: 2.6918 - val_loss: 5.5502 - val_note_output_loss: 3.8538 - val_length_output_loss: 3.3928\n",
      "Epoch 189/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.7959 - note_output_loss: 1.4479 - length_output_loss: 2.6960 - val_loss: 5.4871 - val_note_output_loss: 3.7977 - val_length_output_loss: 3.3787\n",
      "Epoch 190/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.7876 - note_output_loss: 1.4411 - length_output_loss: 2.6932 - val_loss: 5.5675 - val_note_output_loss: 3.8709 - val_length_output_loss: 3.3933\n",
      "Epoch 191/1500\n",
      "7089/7089 [==============================] - 5s 694us/step - loss: 2.7940 - note_output_loss: 1.4449 - length_output_loss: 2.6983 - val_loss: 5.5501 - val_note_output_loss: 3.8545 - val_length_output_loss: 3.3911\n",
      "Epoch 192/1500\n",
      "7089/7089 [==============================] - 5s 748us/step - loss: 2.7829 - note_output_loss: 1.4364 - length_output_loss: 2.6930 - val_loss: 5.5979 - val_note_output_loss: 3.9006 - val_length_output_loss: 3.3946\n",
      "Epoch 193/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.7730 - note_output_loss: 1.4281 - length_output_loss: 2.6898 - val_loss: 5.5625 - val_note_output_loss: 3.8666 - val_length_output_loss: 3.3919\n",
      "Epoch 194/1500\n",
      "7089/7089 [==============================] - 5s 710us/step - loss: 2.7657 - note_output_loss: 1.4229 - length_output_loss: 2.6856 - val_loss: 5.6030 - val_note_output_loss: 3.9078 - val_length_output_loss: 3.3904\n",
      "Epoch 195/1500\n",
      "7089/7089 [==============================] - 5s 704us/step - loss: 2.7557 - note_output_loss: 1.4143 - length_output_loss: 2.6830 - val_loss: 5.5667 - val_note_output_loss: 3.8705 - val_length_output_loss: 3.3924\n",
      "Epoch 196/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 2.7698 - note_output_loss: 1.4265 - length_output_loss: 2.6867 - val_loss: 5.5885 - val_note_output_loss: 3.8938 - val_length_output_loss: 3.3893\n",
      "Epoch 197/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 2.7509 - note_output_loss: 1.4105 - length_output_loss: 2.6808 - val_loss: 5.5698 - val_note_output_loss: 3.8741 - val_length_output_loss: 3.3913\n",
      "Epoch 198/1500\n",
      "7089/7089 [==============================] - 5s 745us/step - loss: 2.7539 - note_output_loss: 1.4113 - length_output_loss: 2.6851 - val_loss: 5.6040 - val_note_output_loss: 3.9054 - val_length_output_loss: 3.3973\n",
      "Epoch 199/1500\n",
      "7089/7089 [==============================] - 5s 690us/step - loss: 2.7454 - note_output_loss: 1.4036 - length_output_loss: 2.6836 - val_loss: 5.6294 - val_note_output_loss: 3.9261 - val_length_output_loss: 3.4066\n",
      "Epoch 200/1500\n",
      "7089/7089 [==============================] - 5s 726us/step - loss: 2.7323 - note_output_loss: 1.3901 - length_output_loss: 2.6843 - val_loss: 5.6445 - val_note_output_loss: 3.9461 - val_length_output_loss: 3.3968\n",
      "Epoch 201/1500\n",
      "7089/7089 [==============================] - 7s 1ms/step - loss: 2.7296 - note_output_loss: 1.3887 - length_output_loss: 2.6816 - val_loss: 5.6376 - val_note_output_loss: 3.9427 - val_length_output_loss: 3.3899\n",
      "Epoch 202/1500\n",
      "7089/7089 [==============================] - 8s 1ms/step - loss: 2.7339 - note_output_loss: 1.3946 - length_output_loss: 2.6787 - val_loss: 5.6472 - val_note_output_loss: 3.9447 - val_length_output_loss: 3.4051\n",
      "Epoch 203/1500\n",
      "7089/7089 [==============================] - 8s 1ms/step - loss: 2.7146 - note_output_loss: 1.3799 - length_output_loss: 2.6694 - val_loss: 5.6687 - val_note_output_loss: 3.9666 - val_length_output_loss: 3.4043\n",
      "Epoch 204/1500\n",
      "7089/7089 [==============================] - 7s 1ms/step - loss: 2.7231 - note_output_loss: 1.3848 - length_output_loss: 2.6767 - val_loss: 5.6482 - val_note_output_loss: 3.9457 - val_length_output_loss: 3.4049\n",
      "Epoch 205/1500\n",
      "7089/7089 [==============================] - 7s 1ms/step - loss: 2.7258 - note_output_loss: 1.3861 - length_output_loss: 2.6793 - val_loss: 5.6327 - val_note_output_loss: 3.9350 - val_length_output_loss: 3.3954\n",
      "Epoch 206/1500\n",
      "7089/7089 [==============================] - 8s 1ms/step - loss: 2.7193 - note_output_loss: 1.3838 - length_output_loss: 2.6711 - val_loss: 5.6496 - val_note_output_loss: 3.9436 - val_length_output_loss: 3.4121\n",
      "Epoch 207/1500\n",
      "7089/7089 [==============================] - 7s 993us/step - loss: 2.7048 - note_output_loss: 1.3699 - length_output_loss: 2.6697 - val_loss: 5.6801 - val_note_output_loss: 3.9728 - val_length_output_loss: 3.4146\n",
      "Epoch 208/1500\n",
      "7089/7089 [==============================] - 7s 1ms/step - loss: 2.7092 - note_output_loss: 1.3704 - length_output_loss: 2.6776 - val_loss: 5.6460 - val_note_output_loss: 3.9441 - val_length_output_loss: 3.4037\n",
      "Epoch 209/1500\n",
      "7089/7089 [==============================] - 8s 1ms/step - loss: 2.6990 - note_output_loss: 1.3637 - length_output_loss: 2.6706 - val_loss: 5.6941 - val_note_output_loss: 3.9867 - val_length_output_loss: 3.4148\n",
      "Epoch 210/1500\n",
      "7089/7089 [==============================] - 8s 1ms/step - loss: 2.7018 - note_output_loss: 1.3675 - length_output_loss: 2.6685 - val_loss: 5.6974 - val_note_output_loss: 3.9901 - val_length_output_loss: 3.4146\n",
      "Epoch 211/1500\n",
      "7089/7089 [==============================] - 7s 982us/step - loss: 2.6868 - note_output_loss: 1.3522 - length_output_loss: 2.6694 - val_loss: 5.7056 - val_note_output_loss: 3.9982 - val_length_output_loss: 3.4149\n",
      "Epoch 212/1500\n",
      "7089/7089 [==============================] - 6s 798us/step - loss: 2.7023 - note_output_loss: 1.3700 - length_output_loss: 2.6646 - val_loss: 5.7183 - val_note_output_loss: 4.0098 - val_length_output_loss: 3.4171\n",
      "Epoch 213/1500\n",
      "7089/7089 [==============================] - 6s 854us/step - loss: 2.6791 - note_output_loss: 1.3475 - length_output_loss: 2.6631 - val_loss: 5.6876 - val_note_output_loss: 3.9812 - val_length_output_loss: 3.4127\n",
      "Epoch 214/1500\n",
      "7089/7089 [==============================] - 7s 958us/step - loss: 2.6882 - note_output_loss: 1.3575 - length_output_loss: 2.6614 - val_loss: 5.7271 - val_note_output_loss: 4.0187 - val_length_output_loss: 3.4167\n",
      "Epoch 215/1500\n",
      "7089/7089 [==============================] - 7s 947us/step - loss: 2.6620 - note_output_loss: 1.3334 - length_output_loss: 2.6572 - val_loss: 5.7468 - val_note_output_loss: 4.0324 - val_length_output_loss: 3.4289\n",
      "Epoch 216/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7089/7089 [==============================] - 7s 933us/step - loss: 2.6793 - note_output_loss: 1.3486 - length_output_loss: 2.6615 - val_loss: 5.8039 - val_note_output_loss: 4.0849 - val_length_output_loss: 3.4381\n",
      "Epoch 217/1500\n",
      "7089/7089 [==============================] - 6s 906us/step - loss: 2.6666 - note_output_loss: 1.3338 - length_output_loss: 2.6656 - val_loss: 5.7377 - val_note_output_loss: 4.0277 - val_length_output_loss: 3.4199\n",
      "Epoch 218/1500\n",
      "7089/7089 [==============================] - 7s 932us/step - loss: 2.6518 - note_output_loss: 1.3216 - length_output_loss: 2.6603 - val_loss: 5.7365 - val_note_output_loss: 4.0283 - val_length_output_loss: 3.4165\n",
      "Epoch 219/1500\n",
      "7089/7089 [==============================] - 6s 912us/step - loss: 2.6550 - note_output_loss: 1.3276 - length_output_loss: 2.6548 - val_loss: 5.7763 - val_note_output_loss: 4.0592 - val_length_output_loss: 3.4342\n",
      "Epoch 220/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.6521 - note_output_loss: 1.3209 - length_output_loss: 2.6623 - val_loss: 5.7902 - val_note_output_loss: 4.0760 - val_length_output_loss: 3.4284\n",
      "Epoch 221/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 2.6413 - note_output_loss: 1.3120 - length_output_loss: 2.6587 - val_loss: 5.7868 - val_note_output_loss: 4.0735 - val_length_output_loss: 3.4267\n",
      "Epoch 222/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 2.6412 - note_output_loss: 1.3121 - length_output_loss: 2.6581 - val_loss: 5.7755 - val_note_output_loss: 4.0577 - val_length_output_loss: 3.4356\n",
      "Epoch 223/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 2.6372 - note_output_loss: 1.3138 - length_output_loss: 2.6467 - val_loss: 5.7499 - val_note_output_loss: 4.0326 - val_length_output_loss: 3.4347\n",
      "Epoch 224/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 2.6359 - note_output_loss: 1.3122 - length_output_loss: 2.6474 - val_loss: 5.8017 - val_note_output_loss: 4.0813 - val_length_output_loss: 3.4409\n",
      "Epoch 225/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.6195 - note_output_loss: 1.2986 - length_output_loss: 2.6418 - val_loss: 5.8622 - val_note_output_loss: 4.1396 - val_length_output_loss: 3.4451\n",
      "Epoch 226/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.6081 - note_output_loss: 1.2867 - length_output_loss: 2.6428 - val_loss: 5.8335 - val_note_output_loss: 4.1155 - val_length_output_loss: 3.4361\n",
      "Epoch 227/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.6187 - note_output_loss: 1.2916 - length_output_loss: 2.6544 - val_loss: 5.8125 - val_note_output_loss: 4.0918 - val_length_output_loss: 3.4413\n",
      "Epoch 228/1500\n",
      "7089/7089 [==============================] - 5s 693us/step - loss: 2.6248 - note_output_loss: 1.3019 - length_output_loss: 2.6460 - val_loss: 5.8525 - val_note_output_loss: 4.1255 - val_length_output_loss: 3.4539\n",
      "Epoch 229/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.6177 - note_output_loss: 1.2951 - length_output_loss: 2.6451 - val_loss: 5.8288 - val_note_output_loss: 4.1119 - val_length_output_loss: 3.4337\n",
      "Epoch 230/1500\n",
      "7089/7089 [==============================] - 5s 679us/step - loss: 2.6153 - note_output_loss: 1.2913 - length_output_loss: 2.6481 - val_loss: 5.8615 - val_note_output_loss: 4.1396 - val_length_output_loss: 3.4439\n",
      "Epoch 231/1500\n",
      "7089/7089 [==============================] - 5s 673us/step - loss: 2.5988 - note_output_loss: 1.2778 - length_output_loss: 2.6420 - val_loss: 5.8763 - val_note_output_loss: 4.1568 - val_length_output_loss: 3.4390\n",
      "Epoch 232/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.6098 - note_output_loss: 1.2887 - length_output_loss: 2.6422 - val_loss: 5.8924 - val_note_output_loss: 4.1674 - val_length_output_loss: 3.4501\n",
      "Epoch 233/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 2.6090 - note_output_loss: 1.2843 - length_output_loss: 2.6495 - val_loss: 5.8865 - val_note_output_loss: 4.1643 - val_length_output_loss: 3.4445\n",
      "Epoch 234/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.6032 - note_output_loss: 1.2789 - length_output_loss: 2.6487 - val_loss: 5.8675 - val_note_output_loss: 4.1433 - val_length_output_loss: 3.4483\n",
      "Epoch 235/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.5792 - note_output_loss: 1.2602 - length_output_loss: 2.6379 - val_loss: 5.8952 - val_note_output_loss: 4.1755 - val_length_output_loss: 3.4395\n",
      "Epoch 236/1500\n",
      "7089/7089 [==============================] - 5s 676us/step - loss: 2.5775 - note_output_loss: 1.2589 - length_output_loss: 2.6372 - val_loss: 5.8920 - val_note_output_loss: 4.1650 - val_length_output_loss: 3.4539\n",
      "Epoch 237/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.5926 - note_output_loss: 1.2736 - length_output_loss: 2.6381 - val_loss: 5.8722 - val_note_output_loss: 4.1499 - val_length_output_loss: 3.4447\n",
      "Epoch 238/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 2.5801 - note_output_loss: 1.2629 - length_output_loss: 2.6343 - val_loss: 5.9476 - val_note_output_loss: 4.2197 - val_length_output_loss: 3.4559\n",
      "Epoch 239/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.5859 - note_output_loss: 1.2687 - length_output_loss: 2.6344 - val_loss: 5.9018 - val_note_output_loss: 4.1806 - val_length_output_loss: 3.4423\n",
      "Epoch 240/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.5723 - note_output_loss: 1.2564 - length_output_loss: 2.6317 - val_loss: 5.9537 - val_note_output_loss: 4.2223 - val_length_output_loss: 3.4629\n",
      "Epoch 241/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.5568 - note_output_loss: 1.2391 - length_output_loss: 2.6354 - val_loss: 5.9139 - val_note_output_loss: 4.1881 - val_length_output_loss: 3.4514\n",
      "Epoch 242/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.5595 - note_output_loss: 1.2452 - length_output_loss: 2.6286 - val_loss: 5.9600 - val_note_output_loss: 4.2296 - val_length_output_loss: 3.4608\n",
      "Epoch 243/1500\n",
      "7089/7089 [==============================] - 5s 673us/step - loss: 2.5584 - note_output_loss: 1.2442 - length_output_loss: 2.6285 - val_loss: 5.9279 - val_note_output_loss: 4.1996 - val_length_output_loss: 3.4567\n",
      "Epoch 244/1500\n",
      "7089/7089 [==============================] - 5s 726us/step - loss: 2.5487 - note_output_loss: 1.2338 - length_output_loss: 2.6298 - val_loss: 5.9888 - val_note_output_loss: 4.2578 - val_length_output_loss: 3.4619\n",
      "Epoch 245/1500\n",
      "7089/7089 [==============================] - 5s 683us/step - loss: 2.5589 - note_output_loss: 1.2414 - length_output_loss: 2.6350 - val_loss: 5.9717 - val_note_output_loss: 4.2382 - val_length_output_loss: 3.4670\n",
      "Epoch 246/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.5533 - note_output_loss: 1.2391 - length_output_loss: 2.6284 - val_loss: 5.9382 - val_note_output_loss: 4.2093 - val_length_output_loss: 3.4577\n",
      "Epoch 247/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.5478 - note_output_loss: 1.2334 - length_output_loss: 2.6289 - val_loss: 5.9608 - val_note_output_loss: 4.2300 - val_length_output_loss: 3.4616\n",
      "Epoch 248/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.5412 - note_output_loss: 1.2291 - length_output_loss: 2.6241 - val_loss: 5.9777 - val_note_output_loss: 4.2461 - val_length_output_loss: 3.4632\n",
      "Epoch 249/1500\n",
      "7089/7089 [==============================] - 5s 683us/step - loss: 2.5223 - note_output_loss: 1.2123 - length_output_loss: 2.6200 - val_loss: 6.0103 - val_note_output_loss: 4.2722 - val_length_output_loss: 3.4761\n",
      "Epoch 250/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.5319 - note_output_loss: 1.2209 - length_output_loss: 2.6219 - val_loss: 6.0157 - val_note_output_loss: 4.2757 - val_length_output_loss: 3.4799\n",
      "Epoch 251/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 2.5305 - note_output_loss: 1.2198 - length_output_loss: 2.6214 - val_loss: 6.0238 - val_note_output_loss: 4.2832 - val_length_output_loss: 3.4811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.5271 - note_output_loss: 1.2162 - length_output_loss: 2.6217 - val_loss: 6.0002 - val_note_output_loss: 4.2614 - val_length_output_loss: 3.4776\n",
      "Epoch 253/1500\n",
      "7089/7089 [==============================] - 5s 714us/step - loss: 2.5243 - note_output_loss: 1.2129 - length_output_loss: 2.6229 - val_loss: 6.0437 - val_note_output_loss: 4.3048 - val_length_output_loss: 3.4778\n",
      "Epoch 254/1500\n",
      "7089/7089 [==============================] - 5s 731us/step - loss: 2.5050 - note_output_loss: 1.1964 - length_output_loss: 2.6174 - val_loss: 6.0259 - val_note_output_loss: 4.2902 - val_length_output_loss: 3.4714\n",
      "Epoch 255/1500\n",
      "7089/7089 [==============================] - 5s 768us/step - loss: 2.5025 - note_output_loss: 1.1949 - length_output_loss: 2.6153 - val_loss: 6.0463 - val_note_output_loss: 4.3111 - val_length_output_loss: 3.4705\n",
      "Epoch 256/1500\n",
      "7089/7089 [==============================] - 5s 734us/step - loss: 2.5124 - note_output_loss: 1.2008 - length_output_loss: 2.6231 - val_loss: 6.0437 - val_note_output_loss: 4.3058 - val_length_output_loss: 3.4758\n",
      "Epoch 257/1500\n",
      "7089/7089 [==============================] - 5s 692us/step - loss: 2.5142 - note_output_loss: 1.2030 - length_output_loss: 2.6223 - val_loss: 6.0234 - val_note_output_loss: 4.2874 - val_length_output_loss: 3.4721\n",
      "Epoch 258/1500\n",
      "7089/7089 [==============================] - 5s 696us/step - loss: 2.4941 - note_output_loss: 1.1875 - length_output_loss: 2.6131 - val_loss: 6.0736 - val_note_output_loss: 4.3330 - val_length_output_loss: 3.4812\n",
      "Epoch 259/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.5074 - note_output_loss: 1.1970 - length_output_loss: 2.6208 - val_loss: 6.0706 - val_note_output_loss: 4.3321 - val_length_output_loss: 3.4771\n",
      "Epoch 260/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 2.4876 - note_output_loss: 1.1782 - length_output_loss: 2.6187 - val_loss: 6.0830 - val_note_output_loss: 4.3467 - val_length_output_loss: 3.4727\n",
      "Epoch 261/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 2.4882 - note_output_loss: 1.1826 - length_output_loss: 2.6112 - val_loss: 6.0954 - val_note_output_loss: 4.3518 - val_length_output_loss: 3.4873\n",
      "Epoch 262/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.4896 - note_output_loss: 1.1813 - length_output_loss: 2.6165 - val_loss: 6.0692 - val_note_output_loss: 4.3305 - val_length_output_loss: 3.4773\n",
      "Epoch 263/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.4897 - note_output_loss: 1.1794 - length_output_loss: 2.6207 - val_loss: 6.0973 - val_note_output_loss: 4.3554 - val_length_output_loss: 3.4838\n",
      "Epoch 264/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 2.4827 - note_output_loss: 1.1771 - length_output_loss: 2.6113 - val_loss: 6.1050 - val_note_output_loss: 4.3635 - val_length_output_loss: 3.4831\n",
      "Epoch 265/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 2.4742 - note_output_loss: 1.1717 - length_output_loss: 2.6050 - val_loss: 6.0888 - val_note_output_loss: 4.3458 - val_length_output_loss: 3.4859\n",
      "Epoch 266/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 2.4745 - note_output_loss: 1.1692 - length_output_loss: 2.6105 - val_loss: 6.1430 - val_note_output_loss: 4.3992 - val_length_output_loss: 3.4878\n",
      "Epoch 267/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.4609 - note_output_loss: 1.1574 - length_output_loss: 2.6070 - val_loss: 6.1101 - val_note_output_loss: 4.3665 - val_length_output_loss: 3.4872\n",
      "Epoch 268/1500\n",
      "7089/7089 [==============================] - 5s 677us/step - loss: 2.4630 - note_output_loss: 1.1605 - length_output_loss: 2.6051 - val_loss: 6.1463 - val_note_output_loss: 4.3988 - val_length_output_loss: 3.4951\n",
      "Epoch 269/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.4540 - note_output_loss: 1.1537 - length_output_loss: 2.6006 - val_loss: 6.1800 - val_note_output_loss: 4.4333 - val_length_output_loss: 3.4934\n",
      "Epoch 270/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 2.4597 - note_output_loss: 1.1557 - length_output_loss: 2.6080 - val_loss: 6.1694 - val_note_output_loss: 4.4213 - val_length_output_loss: 3.4962\n",
      "Epoch 271/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.4723 - note_output_loss: 1.1703 - length_output_loss: 2.6039 - val_loss: 6.1547 - val_note_output_loss: 4.4059 - val_length_output_loss: 3.4975\n",
      "Epoch 272/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 2.4432 - note_output_loss: 1.1391 - length_output_loss: 2.6081 - val_loss: 6.2067 - val_note_output_loss: 4.4523 - val_length_output_loss: 3.5089\n",
      "Epoch 273/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.4368 - note_output_loss: 1.1377 - length_output_loss: 2.5982 - val_loss: 6.1991 - val_note_output_loss: 4.4501 - val_length_output_loss: 3.4981\n",
      "Epoch 274/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 2.4292 - note_output_loss: 1.1291 - length_output_loss: 2.6001 - val_loss: 6.1645 - val_note_output_loss: 4.4218 - val_length_output_loss: 3.4852\n",
      "Epoch 275/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.4374 - note_output_loss: 1.1387 - length_output_loss: 2.5974 - val_loss: 6.2008 - val_note_output_loss: 4.4535 - val_length_output_loss: 3.4946\n",
      "Epoch 276/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.4283 - note_output_loss: 1.1294 - length_output_loss: 2.5977 - val_loss: 6.2492 - val_note_output_loss: 4.5000 - val_length_output_loss: 3.4985\n",
      "Epoch 277/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 2.4263 - note_output_loss: 1.1299 - length_output_loss: 2.5927 - val_loss: 6.1929 - val_note_output_loss: 4.4481 - val_length_output_loss: 3.4895\n",
      "Epoch 278/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.4199 - note_output_loss: 1.1198 - length_output_loss: 2.6002 - val_loss: 6.2336 - val_note_output_loss: 4.4817 - val_length_output_loss: 3.5038\n",
      "Epoch 279/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.4356 - note_output_loss: 1.1386 - length_output_loss: 2.5940 - val_loss: 6.2576 - val_note_output_loss: 4.5031 - val_length_output_loss: 3.5090\n",
      "Epoch 280/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 2.4247 - note_output_loss: 1.1244 - length_output_loss: 2.6005 - val_loss: 6.2308 - val_note_output_loss: 4.4836 - val_length_output_loss: 3.4944\n",
      "Epoch 281/1500\n",
      "7089/7089 [==============================] - 5s 676us/step - loss: 2.4182 - note_output_loss: 1.1202 - length_output_loss: 2.5960 - val_loss: 6.2749 - val_note_output_loss: 4.5229 - val_length_output_loss: 3.5041\n",
      "Epoch 282/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.4163 - note_output_loss: 1.1191 - length_output_loss: 2.5945 - val_loss: 6.2587 - val_note_output_loss: 4.5103 - val_length_output_loss: 3.4969\n",
      "Epoch 283/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.4167 - note_output_loss: 1.1216 - length_output_loss: 2.5900 - val_loss: 6.2609 - val_note_output_loss: 4.5085 - val_length_output_loss: 3.5049\n",
      "Epoch 284/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.4158 - note_output_loss: 1.1189 - length_output_loss: 2.5938 - val_loss: 6.2272 - val_note_output_loss: 4.4787 - val_length_output_loss: 3.4969\n",
      "Epoch 285/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.3965 - note_output_loss: 1.0998 - length_output_loss: 2.5934 - val_loss: 6.3157 - val_note_output_loss: 4.5576 - val_length_output_loss: 3.5162\n",
      "Epoch 286/1500\n",
      "7089/7089 [==============================] - 5s 701us/step - loss: 2.4149 - note_output_loss: 1.1173 - length_output_loss: 2.5952 - val_loss: 6.2821 - val_note_output_loss: 4.5297 - val_length_output_loss: 3.5049\n",
      "Epoch 287/1500\n",
      "7089/7089 [==============================] - 5s 761us/step - loss: 2.3837 - note_output_loss: 1.0894 - length_output_loss: 2.5887 - val_loss: 6.2839 - val_note_output_loss: 4.5317 - val_length_output_loss: 3.5044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 2.3922 - note_output_loss: 1.1001 - length_output_loss: 2.5843 - val_loss: 6.2842 - val_note_output_loss: 4.5257 - val_length_output_loss: 3.5171\n",
      "Epoch 289/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.3919 - note_output_loss: 1.0965 - length_output_loss: 2.5908 - val_loss: 6.3156 - val_note_output_loss: 4.5642 - val_length_output_loss: 3.5028\n",
      "Epoch 290/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.3825 - note_output_loss: 1.0902 - length_output_loss: 2.5845 - val_loss: 6.2851 - val_note_output_loss: 4.5327 - val_length_output_loss: 3.5048\n",
      "Epoch 291/1500\n",
      "7089/7089 [==============================] - 5s 681us/step - loss: 2.3832 - note_output_loss: 1.0916 - length_output_loss: 2.5832 - val_loss: 6.3659 - val_note_output_loss: 4.6049 - val_length_output_loss: 3.5218\n",
      "Epoch 292/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.3831 - note_output_loss: 1.0913 - length_output_loss: 2.5835 - val_loss: 6.2913 - val_note_output_loss: 4.5420 - val_length_output_loss: 3.4986\n",
      "Epoch 293/1500\n",
      "7089/7089 [==============================] - 5s 695us/step - loss: 2.3826 - note_output_loss: 1.0914 - length_output_loss: 2.5823 - val_loss: 6.3313 - val_note_output_loss: 4.5804 - val_length_output_loss: 3.5018\n",
      "Epoch 294/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.3825 - note_output_loss: 1.0921 - length_output_loss: 2.5807 - val_loss: 6.3689 - val_note_output_loss: 4.6138 - val_length_output_loss: 3.5102\n",
      "Epoch 295/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.3689 - note_output_loss: 1.0797 - length_output_loss: 2.5786 - val_loss: 6.4038 - val_note_output_loss: 4.6421 - val_length_output_loss: 3.5235\n",
      "Epoch 296/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 2.3621 - note_output_loss: 1.0702 - length_output_loss: 2.5836 - val_loss: 6.3767 - val_note_output_loss: 4.6197 - val_length_output_loss: 3.5141\n",
      "Epoch 297/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 2.3710 - note_output_loss: 1.0782 - length_output_loss: 2.5856 - val_loss: 6.3424 - val_note_output_loss: 4.5849 - val_length_output_loss: 3.5151\n",
      "Epoch 298/1500\n",
      "7089/7089 [==============================] - 5s 662us/step - loss: 2.3496 - note_output_loss: 1.0646 - length_output_loss: 2.5699 - val_loss: 6.3610 - val_note_output_loss: 4.6004 - val_length_output_loss: 3.5212\n",
      "Epoch 299/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.3655 - note_output_loss: 1.0790 - length_output_loss: 2.5730 - val_loss: 6.4466 - val_note_output_loss: 4.6824 - val_length_output_loss: 3.5285\n",
      "Epoch 300/1500\n",
      "7089/7089 [==============================] - 5s 676us/step - loss: 2.3515 - note_output_loss: 1.0630 - length_output_loss: 2.5770 - val_loss: 6.3901 - val_note_output_loss: 4.6250 - val_length_output_loss: 3.5301\n",
      "Epoch 301/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.3551 - note_output_loss: 1.0662 - length_output_loss: 2.5776 - val_loss: 6.4048 - val_note_output_loss: 4.6435 - val_length_output_loss: 3.5226\n",
      "Epoch 302/1500\n",
      "7089/7089 [==============================] - 5s 696us/step - loss: 2.3738 - note_output_loss: 1.0879 - length_output_loss: 2.5718 - val_loss: 6.3871 - val_note_output_loss: 4.6214 - val_length_output_loss: 3.5313\n",
      "Epoch 303/1500\n",
      "7089/7089 [==============================] - 5s 704us/step - loss: 2.3416 - note_output_loss: 1.0552 - length_output_loss: 2.5728 - val_loss: 6.4151 - val_note_output_loss: 4.6561 - val_length_output_loss: 3.5180\n",
      "Epoch 304/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.3420 - note_output_loss: 1.0563 - length_output_loss: 2.5714 - val_loss: 6.4300 - val_note_output_loss: 4.6613 - val_length_output_loss: 3.5374\n",
      "Epoch 305/1500\n",
      "7089/7089 [==============================] - 5s 681us/step - loss: 2.3299 - note_output_loss: 1.0441 - length_output_loss: 2.5716 - val_loss: 6.4097 - val_note_output_loss: 4.6527 - val_length_output_loss: 3.5141\n",
      "Epoch 306/1500\n",
      "7089/7089 [==============================] - 5s 705us/step - loss: 2.3408 - note_output_loss: 1.0527 - length_output_loss: 2.5761 - val_loss: 6.3971 - val_note_output_loss: 4.6355 - val_length_output_loss: 3.5231\n",
      "Epoch 307/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 2.3485 - note_output_loss: 1.0640 - length_output_loss: 2.5689 - val_loss: 6.3672 - val_note_output_loss: 4.6098 - val_length_output_loss: 3.5148\n",
      "Epoch 308/1500\n",
      "7089/7089 [==============================] - 5s 679us/step - loss: 2.3214 - note_output_loss: 1.0406 - length_output_loss: 2.5616 - val_loss: 6.4792 - val_note_output_loss: 4.7067 - val_length_output_loss: 3.5451\n",
      "Epoch 309/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.3287 - note_output_loss: 1.0405 - length_output_loss: 2.5762 - val_loss: 6.4678 - val_note_output_loss: 4.6944 - val_length_output_loss: 3.5467\n",
      "Epoch 310/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.3335 - note_output_loss: 1.0482 - length_output_loss: 2.5705 - val_loss: 6.4965 - val_note_output_loss: 4.7240 - val_length_output_loss: 3.5450\n",
      "Epoch 311/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.3263 - note_output_loss: 1.0385 - length_output_loss: 2.5756 - val_loss: 6.4763 - val_note_output_loss: 4.7056 - val_length_output_loss: 3.5414\n",
      "Epoch 312/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 2.3303 - note_output_loss: 1.0451 - length_output_loss: 2.5705 - val_loss: 6.4722 - val_note_output_loss: 4.7031 - val_length_output_loss: 3.5382\n",
      "Epoch 313/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.3045 - note_output_loss: 1.0223 - length_output_loss: 2.5644 - val_loss: 6.5435 - val_note_output_loss: 4.7746 - val_length_output_loss: 3.5379\n",
      "Epoch 314/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 2.3247 - note_output_loss: 1.0376 - length_output_loss: 2.5741 - val_loss: 6.5218 - val_note_output_loss: 4.7472 - val_length_output_loss: 3.5491\n",
      "Epoch 315/1500\n",
      "7089/7089 [==============================] - 5s 737us/step - loss: 2.3029 - note_output_loss: 1.0218 - length_output_loss: 2.5621 - val_loss: 6.5157 - val_note_output_loss: 4.7461 - val_length_output_loss: 3.5391\n",
      "Epoch 316/1500\n",
      "7089/7089 [==============================] - 5s 681us/step - loss: 2.3232 - note_output_loss: 1.0398 - length_output_loss: 2.5668 - val_loss: 6.4713 - val_note_output_loss: 4.7050 - val_length_output_loss: 3.5326\n",
      "Epoch 317/1500\n",
      "7089/7089 [==============================] - 5s 690us/step - loss: 2.3016 - note_output_loss: 1.0171 - length_output_loss: 2.5691 - val_loss: 6.5160 - val_note_output_loss: 4.7459 - val_length_output_loss: 3.5403\n",
      "Epoch 318/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 2.3075 - note_output_loss: 1.0265 - length_output_loss: 2.5621 - val_loss: 6.5294 - val_note_output_loss: 4.7545 - val_length_output_loss: 3.5499\n",
      "Epoch 319/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.2963 - note_output_loss: 1.0173 - length_output_loss: 2.5581 - val_loss: 6.5389 - val_note_output_loss: 4.7620 - val_length_output_loss: 3.5537\n",
      "Epoch 320/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 2.2927 - note_output_loss: 1.0119 - length_output_loss: 2.5616 - val_loss: 6.4854 - val_note_output_loss: 4.7139 - val_length_output_loss: 3.5429\n",
      "Epoch 321/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 2.2989 - note_output_loss: 1.0198 - length_output_loss: 2.5582 - val_loss: 6.5982 - val_note_output_loss: 4.8208 - val_length_output_loss: 3.5547\n",
      "Epoch 322/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.2855 - note_output_loss: 1.0053 - length_output_loss: 2.5604 - val_loss: 6.5588 - val_note_output_loss: 4.7854 - val_length_output_loss: 3.5468\n",
      "Epoch 323/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 2.2909 - note_output_loss: 1.0078 - length_output_loss: 2.5663 - val_loss: 6.5211 - val_note_output_loss: 4.7492 - val_length_output_loss: 3.5438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.2776 - note_output_loss: 0.9975 - length_output_loss: 2.5603 - val_loss: 6.5750 - val_note_output_loss: 4.8071 - val_length_output_loss: 3.5358\n",
      "Epoch 325/1500\n",
      "7089/7089 [==============================] - 5s 678us/step - loss: 2.2958 - note_output_loss: 1.0166 - length_output_loss: 2.5584 - val_loss: 6.6151 - val_note_output_loss: 4.8445 - val_length_output_loss: 3.5412\n",
      "Epoch 326/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.2816 - note_output_loss: 1.0063 - length_output_loss: 2.5506 - val_loss: 6.5439 - val_note_output_loss: 4.7691 - val_length_output_loss: 3.5495\n",
      "Epoch 327/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 2.2720 - note_output_loss: 0.9974 - length_output_loss: 2.5492 - val_loss: 6.5790 - val_note_output_loss: 4.7986 - val_length_output_loss: 3.5609\n",
      "Epoch 328/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.2866 - note_output_loss: 1.0082 - length_output_loss: 2.5568 - val_loss: 6.5999 - val_note_output_loss: 4.8177 - val_length_output_loss: 3.5644\n",
      "Epoch 329/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 2.2672 - note_output_loss: 0.9906 - length_output_loss: 2.5532 - val_loss: 6.6138 - val_note_output_loss: 4.8325 - val_length_output_loss: 3.5627\n",
      "Epoch 330/1500\n",
      "7089/7089 [==============================] - 5s 723us/step - loss: 2.2530 - note_output_loss: 0.9794 - length_output_loss: 2.5471 - val_loss: 6.6022 - val_note_output_loss: 4.8232 - val_length_output_loss: 3.5581\n",
      "Epoch 331/1500\n",
      "7089/7089 [==============================] - 5s 673us/step - loss: 2.2600 - note_output_loss: 0.9832 - length_output_loss: 2.5536 - val_loss: 6.6035 - val_note_output_loss: 4.8238 - val_length_output_loss: 3.5595\n",
      "Epoch 332/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 2.2692 - note_output_loss: 0.9939 - length_output_loss: 2.5506 - val_loss: 6.6114 - val_note_output_loss: 4.8330 - val_length_output_loss: 3.5568\n",
      "Epoch 333/1500\n",
      "7089/7089 [==============================] - 5s 748us/step - loss: 2.2597 - note_output_loss: 0.9831 - length_output_loss: 2.5531 - val_loss: 6.6022 - val_note_output_loss: 4.8237 - val_length_output_loss: 3.5570\n",
      "Epoch 334/1500\n",
      "7089/7089 [==============================] - 6s 815us/step - loss: 2.2456 - note_output_loss: 0.9721 - length_output_loss: 2.5472 - val_loss: 6.6019 - val_note_output_loss: 4.8210 - val_length_output_loss: 3.5618\n",
      "Epoch 335/1500\n",
      "7089/7089 [==============================] - 6s 809us/step - loss: 2.2522 - note_output_loss: 0.9772 - length_output_loss: 2.5501 - val_loss: 6.6510 - val_note_output_loss: 4.8685 - val_length_output_loss: 3.5650\n",
      "Epoch 336/1500\n",
      "7089/7089 [==============================] - 6s 878us/step - loss: 2.2421 - note_output_loss: 0.9688 - length_output_loss: 2.5466 - val_loss: 6.6283 - val_note_output_loss: 4.8455 - val_length_output_loss: 3.5656\n",
      "Epoch 337/1500\n",
      "7089/7089 [==============================] - 5s 771us/step - loss: 2.2424 - note_output_loss: 0.9660 - length_output_loss: 2.5527 - val_loss: 6.6404 - val_note_output_loss: 4.8548 - val_length_output_loss: 3.5712\n",
      "Epoch 338/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.2451 - note_output_loss: 0.9709 - length_output_loss: 2.5485 - val_loss: 6.6312 - val_note_output_loss: 4.8503 - val_length_output_loss: 3.5619\n",
      "Epoch 339/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 2.2387 - note_output_loss: 0.9686 - length_output_loss: 2.5401 - val_loss: 6.7209 - val_note_output_loss: 4.9355 - val_length_output_loss: 3.5707\n",
      "Epoch 340/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.2478 - note_output_loss: 0.9782 - length_output_loss: 2.5393 - val_loss: 6.7159 - val_note_output_loss: 4.9265 - val_length_output_loss: 3.5787\n",
      "Epoch 341/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.2531 - note_output_loss: 0.9772 - length_output_loss: 2.5519 - val_loss: 6.6975 - val_note_output_loss: 4.9076 - val_length_output_loss: 3.5798\n",
      "Epoch 342/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 2.2350 - note_output_loss: 0.9652 - length_output_loss: 2.5397 - val_loss: 6.6277 - val_note_output_loss: 4.8485 - val_length_output_loss: 3.5585\n",
      "Epoch 343/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 2.2547 - note_output_loss: 0.9810 - length_output_loss: 2.5473 - val_loss: 6.6590 - val_note_output_loss: 4.8731 - val_length_output_loss: 3.5718\n",
      "Epoch 344/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 2.2272 - note_output_loss: 0.9557 - length_output_loss: 2.5431 - val_loss: 6.7080 - val_note_output_loss: 4.9201 - val_length_output_loss: 3.5758\n",
      "Epoch 345/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.2260 - note_output_loss: 0.9503 - length_output_loss: 2.5515 - val_loss: 6.7021 - val_note_output_loss: 4.9188 - val_length_output_loss: 3.5666\n",
      "Epoch 346/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 2.2245 - note_output_loss: 0.9543 - length_output_loss: 2.5403 - val_loss: 6.7400 - val_note_output_loss: 4.9523 - val_length_output_loss: 3.5754\n",
      "Epoch 347/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.2108 - note_output_loss: 0.9414 - length_output_loss: 2.5388 - val_loss: 6.7211 - val_note_output_loss: 4.9323 - val_length_output_loss: 3.5777\n",
      "Epoch 348/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 2.2319 - note_output_loss: 0.9576 - length_output_loss: 2.5487 - val_loss: 6.7311 - val_note_output_loss: 4.9440 - val_length_output_loss: 3.5742\n",
      "Epoch 349/1500\n",
      "7089/7089 [==============================] - 5s 674us/step - loss: 2.2205 - note_output_loss: 0.9512 - length_output_loss: 2.5386 - val_loss: 6.7649 - val_note_output_loss: 4.9767 - val_length_output_loss: 3.5765\n",
      "Epoch 350/1500\n",
      "7089/7089 [==============================] - 5s 689us/step - loss: 2.2171 - note_output_loss: 0.9465 - length_output_loss: 2.5412 - val_loss: 6.7812 - val_note_output_loss: 4.9881 - val_length_output_loss: 3.5863\n",
      "Epoch 351/1500\n",
      "7089/7089 [==============================] - 5s 772us/step - loss: 2.2187 - note_output_loss: 0.9469 - length_output_loss: 2.5436 - val_loss: 6.7715 - val_note_output_loss: 4.9821 - val_length_output_loss: 3.5787\n",
      "Epoch 352/1500\n",
      "7089/7089 [==============================] - 5s 764us/step - loss: 2.2089 - note_output_loss: 0.9393 - length_output_loss: 2.5392 - val_loss: 6.7902 - val_note_output_loss: 5.0002 - val_length_output_loss: 3.5801\n",
      "Epoch 353/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 2.2080 - note_output_loss: 0.9393 - length_output_loss: 2.5372 - val_loss: 6.7585 - val_note_output_loss: 4.9752 - val_length_output_loss: 3.5666\n",
      "Epoch 354/1500\n",
      "7089/7089 [==============================] - 5s 712us/step - loss: 2.2215 - note_output_loss: 0.9500 - length_output_loss: 2.5431 - val_loss: 6.7147 - val_note_output_loss: 4.9236 - val_length_output_loss: 3.5822\n",
      "Epoch 355/1500\n",
      "7089/7089 [==============================] - 5s 715us/step - loss: 2.2126 - note_output_loss: 0.9452 - length_output_loss: 2.5348 - val_loss: 6.7922 - val_note_output_loss: 5.0007 - val_length_output_loss: 3.5830\n",
      "Epoch 356/1500\n",
      "7089/7089 [==============================] - 5s 750us/step - loss: 2.2062 - note_output_loss: 0.9391 - length_output_loss: 2.5340 - val_loss: 6.7735 - val_note_output_loss: 4.9787 - val_length_output_loss: 3.5897\n",
      "Epoch 357/1500\n",
      "7089/7089 [==============================] - 5s 684us/step - loss: 2.2023 - note_output_loss: 0.9328 - length_output_loss: 2.5391 - val_loss: 6.7938 - val_note_output_loss: 5.0021 - val_length_output_loss: 3.5833\n",
      "Epoch 358/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.1947 - note_output_loss: 0.9285 - length_output_loss: 2.5325 - val_loss: 6.8023 - val_note_output_loss: 5.0144 - val_length_output_loss: 3.5757\n",
      "Epoch 359/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.1887 - note_output_loss: 0.9232 - length_output_loss: 2.5310 - val_loss: 6.8108 - val_note_output_loss: 5.0202 - val_length_output_loss: 3.5811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.1889 - note_output_loss: 0.9243 - length_output_loss: 2.5293 - val_loss: 6.7966 - val_note_output_loss: 5.0002 - val_length_output_loss: 3.5930\n",
      "Epoch 361/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.1950 - note_output_loss: 0.9303 - length_output_loss: 2.5295 - val_loss: 6.8026 - val_note_output_loss: 5.0099 - val_length_output_loss: 3.5854\n",
      "Epoch 362/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.1686 - note_output_loss: 0.9051 - length_output_loss: 2.5269 - val_loss: 6.8468 - val_note_output_loss: 5.0477 - val_length_output_loss: 3.5982\n",
      "Epoch 363/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 2.1797 - note_output_loss: 0.9161 - length_output_loss: 2.5272 - val_loss: 6.8398 - val_note_output_loss: 5.0407 - val_length_output_loss: 3.5984\n",
      "Epoch 364/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.1867 - note_output_loss: 0.9226 - length_output_loss: 2.5282 - val_loss: 6.8354 - val_note_output_loss: 5.0349 - val_length_output_loss: 3.6010\n",
      "Epoch 365/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 2.1755 - note_output_loss: 0.9175 - length_output_loss: 2.5159 - val_loss: 6.8161 - val_note_output_loss: 5.0259 - val_length_output_loss: 3.5803\n",
      "Epoch 366/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.1778 - note_output_loss: 0.9129 - length_output_loss: 2.5298 - val_loss: 6.8405 - val_note_output_loss: 5.0463 - val_length_output_loss: 3.5883\n",
      "Epoch 367/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 2.1771 - note_output_loss: 0.9149 - length_output_loss: 2.5243 - val_loss: 6.8304 - val_note_output_loss: 5.0287 - val_length_output_loss: 3.6033\n",
      "Epoch 368/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.1761 - note_output_loss: 0.9143 - length_output_loss: 2.5237 - val_loss: 6.8405 - val_note_output_loss: 5.0404 - val_length_output_loss: 3.6003\n",
      "Epoch 369/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 2.1828 - note_output_loss: 0.9198 - length_output_loss: 2.5260 - val_loss: 6.8392 - val_note_output_loss: 5.0431 - val_length_output_loss: 3.5921\n",
      "Epoch 370/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.1587 - note_output_loss: 0.8982 - length_output_loss: 2.5210 - val_loss: 6.8021 - val_note_output_loss: 5.0059 - val_length_output_loss: 3.5925\n",
      "Epoch 371/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.1459 - note_output_loss: 0.8885 - length_output_loss: 2.5147 - val_loss: 6.8824 - val_note_output_loss: 5.0792 - val_length_output_loss: 3.6065\n",
      "Epoch 372/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.1676 - note_output_loss: 0.9039 - length_output_loss: 2.5274 - val_loss: 6.9058 - val_note_output_loss: 5.1039 - val_length_output_loss: 3.6037\n",
      "Epoch 373/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.1804 - note_output_loss: 0.9143 - length_output_loss: 2.5323 - val_loss: 6.8632 - val_note_output_loss: 5.0676 - val_length_output_loss: 3.5912\n",
      "Epoch 374/1500\n",
      "7089/7089 [==============================] - 5s 684us/step - loss: 2.1664 - note_output_loss: 0.9020 - length_output_loss: 2.5289 - val_loss: 6.9247 - val_note_output_loss: 5.1213 - val_length_output_loss: 3.6069\n",
      "Epoch 375/1500\n",
      "7089/7089 [==============================] - 5s 703us/step - loss: 2.1667 - note_output_loss: 0.9056 - length_output_loss: 2.5223 - val_loss: 6.8371 - val_note_output_loss: 5.0369 - val_length_output_loss: 3.6004\n",
      "Epoch 376/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.1582 - note_output_loss: 0.8994 - length_output_loss: 2.5176 - val_loss: 6.9023 - val_note_output_loss: 5.0981 - val_length_output_loss: 3.6084\n",
      "Epoch 377/1500\n",
      "7089/7089 [==============================] - 5s 667us/step - loss: 2.1476 - note_output_loss: 0.8881 - length_output_loss: 2.5189 - val_loss: 6.9447 - val_note_output_loss: 5.1400 - val_length_output_loss: 3.6094\n",
      "Epoch 378/1500\n",
      "7089/7089 [==============================] - 5s 677us/step - loss: 2.1570 - note_output_loss: 0.8984 - length_output_loss: 2.5171 - val_loss: 6.9052 - val_note_output_loss: 5.1002 - val_length_output_loss: 3.6100\n",
      "Epoch 379/1500\n",
      "7089/7089 [==============================] - 5s 746us/step - loss: 2.1376 - note_output_loss: 0.8796 - length_output_loss: 2.5161 - val_loss: 6.9200 - val_note_output_loss: 5.1128 - val_length_output_loss: 3.6143\n",
      "Epoch 380/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 2.1407 - note_output_loss: 0.8804 - length_output_loss: 2.5207 - val_loss: 6.9266 - val_note_output_loss: 5.1290 - val_length_output_loss: 3.5953\n",
      "Epoch 381/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.1396 - note_output_loss: 0.8824 - length_output_loss: 2.5144 - val_loss: 6.9429 - val_note_output_loss: 5.1388 - val_length_output_loss: 3.6084\n",
      "Epoch 382/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 2.1464 - note_output_loss: 0.8888 - length_output_loss: 2.5153 - val_loss: 6.9822 - val_note_output_loss: 5.1760 - val_length_output_loss: 3.6124\n",
      "Epoch 383/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 2.1277 - note_output_loss: 0.8693 - length_output_loss: 2.5169 - val_loss: 6.9681 - val_note_output_loss: 5.1663 - val_length_output_loss: 3.6037\n",
      "Epoch 384/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.1389 - note_output_loss: 0.8810 - length_output_loss: 2.5158 - val_loss: 6.9578 - val_note_output_loss: 5.1495 - val_length_output_loss: 3.6165\n",
      "Epoch 385/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.1420 - note_output_loss: 0.8849 - length_output_loss: 2.5141 - val_loss: 6.9820 - val_note_output_loss: 5.1746 - val_length_output_loss: 3.6147\n",
      "Epoch 386/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.1344 - note_output_loss: 0.8784 - length_output_loss: 2.5119 - val_loss: 6.9765 - val_note_output_loss: 5.1651 - val_length_output_loss: 3.6228\n",
      "Epoch 387/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.1289 - note_output_loss: 0.8746 - length_output_loss: 2.5086 - val_loss: 6.9645 - val_note_output_loss: 5.1566 - val_length_output_loss: 3.6158\n",
      "Epoch 388/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 2.1284 - note_output_loss: 0.8755 - length_output_loss: 2.5059 - val_loss: 7.0121 - val_note_output_loss: 5.2008 - val_length_output_loss: 3.6226\n",
      "Epoch 389/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 2.1370 - note_output_loss: 0.8823 - length_output_loss: 2.5093 - val_loss: 6.9821 - val_note_output_loss: 5.1707 - val_length_output_loss: 3.6228\n",
      "Epoch 390/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 2.1196 - note_output_loss: 0.8688 - length_output_loss: 2.5015 - val_loss: 6.9904 - val_note_output_loss: 5.1739 - val_length_output_loss: 3.6331\n",
      "Epoch 391/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.1126 - note_output_loss: 0.8599 - length_output_loss: 2.5054 - val_loss: 7.0018 - val_note_output_loss: 5.1890 - val_length_output_loss: 3.6256\n",
      "Epoch 392/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.1219 - note_output_loss: 0.8687 - length_output_loss: 2.5063 - val_loss: 7.0012 - val_note_output_loss: 5.1931 - val_length_output_loss: 3.6162\n",
      "Epoch 393/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.1166 - note_output_loss: 0.8637 - length_output_loss: 2.5059 - val_loss: 6.9983 - val_note_output_loss: 5.1885 - val_length_output_loss: 3.6196\n",
      "Epoch 394/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.1192 - note_output_loss: 0.8691 - length_output_loss: 2.5003 - val_loss: 6.9913 - val_note_output_loss: 5.1795 - val_length_output_loss: 3.6236\n",
      "Epoch 395/1500\n",
      "7089/7089 [==============================] - 5s 700us/step - loss: 2.0974 - note_output_loss: 0.8464 - length_output_loss: 2.5020 - val_loss: 7.0144 - val_note_output_loss: 5.2006 - val_length_output_loss: 3.6276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/1500\n",
      "7089/7089 [==============================] - 5s 718us/step - loss: 2.1243 - note_output_loss: 0.8683 - length_output_loss: 2.5119 - val_loss: 7.0085 - val_note_output_loss: 5.1948 - val_length_output_loss: 3.6273\n",
      "Epoch 397/1500\n",
      "7089/7089 [==============================] - 5s 706us/step - loss: 2.0894 - note_output_loss: 0.8433 - length_output_loss: 2.4920 - val_loss: 7.0316 - val_note_output_loss: 5.2155 - val_length_output_loss: 3.6321\n",
      "Epoch 398/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.1093 - note_output_loss: 0.8577 - length_output_loss: 2.5033 - val_loss: 7.0192 - val_note_output_loss: 5.2131 - val_length_output_loss: 3.6122\n",
      "Epoch 399/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 2.1008 - note_output_loss: 0.8488 - length_output_loss: 2.5040 - val_loss: 7.0173 - val_note_output_loss: 5.2092 - val_length_output_loss: 3.6161\n",
      "Epoch 400/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.0975 - note_output_loss: 0.8442 - length_output_loss: 2.5067 - val_loss: 7.0634 - val_note_output_loss: 5.2486 - val_length_output_loss: 3.6297\n",
      "Epoch 401/1500\n",
      "7089/7089 [==============================] - 5s 678us/step - loss: 2.1147 - note_output_loss: 0.8661 - length_output_loss: 2.4972 - val_loss: 6.9987 - val_note_output_loss: 5.1930 - val_length_output_loss: 3.6115\n",
      "Epoch 402/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 2.0898 - note_output_loss: 0.8426 - length_output_loss: 2.4945 - val_loss: 7.0329 - val_note_output_loss: 5.2204 - val_length_output_loss: 3.6249\n",
      "Epoch 403/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.0936 - note_output_loss: 0.8456 - length_output_loss: 2.4961 - val_loss: 7.0362 - val_note_output_loss: 5.2256 - val_length_output_loss: 3.6213\n",
      "Epoch 404/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.0831 - note_output_loss: 0.8324 - length_output_loss: 2.5014 - val_loss: 7.0358 - val_note_output_loss: 5.2222 - val_length_output_loss: 3.6273\n",
      "Epoch 405/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 2.0778 - note_output_loss: 0.8309 - length_output_loss: 2.4939 - val_loss: 7.0467 - val_note_output_loss: 5.2269 - val_length_output_loss: 3.6396\n",
      "Epoch 406/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.0881 - note_output_loss: 0.8420 - length_output_loss: 2.4923 - val_loss: 7.0582 - val_note_output_loss: 5.2472 - val_length_output_loss: 3.6220\n",
      "Epoch 407/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.0910 - note_output_loss: 0.8414 - length_output_loss: 2.4991 - val_loss: 7.0701 - val_note_output_loss: 5.2534 - val_length_output_loss: 3.6335\n",
      "Epoch 408/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 2.0828 - note_output_loss: 0.8332 - length_output_loss: 2.4992 - val_loss: 7.0876 - val_note_output_loss: 5.2671 - val_length_output_loss: 3.6409\n",
      "Epoch 409/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 2.0822 - note_output_loss: 0.8348 - length_output_loss: 2.4949 - val_loss: 7.0478 - val_note_output_loss: 5.2343 - val_length_output_loss: 3.6269\n",
      "Epoch 410/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.0775 - note_output_loss: 0.8304 - length_output_loss: 2.4943 - val_loss: 7.0888 - val_note_output_loss: 5.2757 - val_length_output_loss: 3.6262\n",
      "Epoch 411/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 2.0728 - note_output_loss: 0.8285 - length_output_loss: 2.4886 - val_loss: 7.0858 - val_note_output_loss: 5.2655 - val_length_output_loss: 3.6406\n",
      "Epoch 412/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 2.0667 - note_output_loss: 0.8202 - length_output_loss: 2.4930 - val_loss: 7.1034 - val_note_output_loss: 5.2875 - val_length_output_loss: 3.6319\n",
      "Epoch 413/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 2.0828 - note_output_loss: 0.8416 - length_output_loss: 2.4826 - val_loss: 7.0830 - val_note_output_loss: 5.2648 - val_length_output_loss: 3.6365\n",
      "Epoch 414/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.0686 - note_output_loss: 0.8251 - length_output_loss: 2.4870 - val_loss: 7.1214 - val_note_output_loss: 5.3056 - val_length_output_loss: 3.6317\n",
      "Epoch 415/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.0767 - note_output_loss: 0.8288 - length_output_loss: 2.4959 - val_loss: 7.1165 - val_note_output_loss: 5.3044 - val_length_output_loss: 3.6242\n",
      "Epoch 416/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.0700 - note_output_loss: 0.8279 - length_output_loss: 2.4841 - val_loss: 7.1022 - val_note_output_loss: 5.2847 - val_length_output_loss: 3.6352\n",
      "Epoch 417/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.0492 - note_output_loss: 0.8073 - length_output_loss: 2.4838 - val_loss: 7.1389 - val_note_output_loss: 5.3203 - val_length_output_loss: 3.6373\n",
      "Epoch 418/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 2.0527 - note_output_loss: 0.8089 - length_output_loss: 2.4876 - val_loss: 7.0746 - val_note_output_loss: 5.2589 - val_length_output_loss: 3.6314\n",
      "Epoch 419/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.0552 - note_output_loss: 0.8095 - length_output_loss: 2.4914 - val_loss: 7.1555 - val_note_output_loss: 5.3313 - val_length_output_loss: 3.6484\n",
      "Epoch 420/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.0737 - note_output_loss: 0.8299 - length_output_loss: 2.4876 - val_loss: 7.1253 - val_note_output_loss: 5.3061 - val_length_output_loss: 3.6384\n",
      "Epoch 421/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 2.0517 - note_output_loss: 0.8104 - length_output_loss: 2.4827 - val_loss: 7.1548 - val_note_output_loss: 5.3316 - val_length_output_loss: 3.6463\n",
      "Epoch 422/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.0560 - note_output_loss: 0.8135 - length_output_loss: 2.4851 - val_loss: 7.1594 - val_note_output_loss: 5.3399 - val_length_output_loss: 3.6389\n",
      "Epoch 423/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.0624 - note_output_loss: 0.8195 - length_output_loss: 2.4858 - val_loss: 7.1435 - val_note_output_loss: 5.3256 - val_length_output_loss: 3.6358\n",
      "Epoch 424/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 2.0522 - note_output_loss: 0.8092 - length_output_loss: 2.4861 - val_loss: 7.1719 - val_note_output_loss: 5.3553 - val_length_output_loss: 3.6333\n",
      "Epoch 425/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.0478 - note_output_loss: 0.8059 - length_output_loss: 2.4838 - val_loss: 7.1629 - val_note_output_loss: 5.3429 - val_length_output_loss: 3.6401\n",
      "Epoch 426/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 2.0445 - note_output_loss: 0.8046 - length_output_loss: 2.4799 - val_loss: 7.1978 - val_note_output_loss: 5.3726 - val_length_output_loss: 3.6505\n",
      "Epoch 427/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.0465 - note_output_loss: 0.8058 - length_output_loss: 2.4813 - val_loss: 7.1648 - val_note_output_loss: 5.3413 - val_length_output_loss: 3.6469\n",
      "Epoch 428/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 2.0427 - note_output_loss: 0.8045 - length_output_loss: 2.4763 - val_loss: 7.1541 - val_note_output_loss: 5.3331 - val_length_output_loss: 3.6418\n",
      "Epoch 429/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.0479 - note_output_loss: 0.8067 - length_output_loss: 2.4823 - val_loss: 7.1632 - val_note_output_loss: 5.3416 - val_length_output_loss: 3.6431\n",
      "Epoch 430/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 2.0343 - note_output_loss: 0.7938 - length_output_loss: 2.4810 - val_loss: 7.1926 - val_note_output_loss: 5.3699 - val_length_output_loss: 3.6454\n",
      "Epoch 431/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.0252 - note_output_loss: 0.7858 - length_output_loss: 2.4787 - val_loss: 7.1957 - val_note_output_loss: 5.3688 - val_length_output_loss: 3.6538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 2.0414 - note_output_loss: 0.8028 - length_output_loss: 2.4772 - val_loss: 7.1946 - val_note_output_loss: 5.3661 - val_length_output_loss: 3.6571\n",
      "Epoch 433/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 2.0395 - note_output_loss: 0.8012 - length_output_loss: 2.4767 - val_loss: 7.1922 - val_note_output_loss: 5.3651 - val_length_output_loss: 3.6541\n",
      "Epoch 434/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 2.0304 - note_output_loss: 0.7889 - length_output_loss: 2.4830 - val_loss: 7.2161 - val_note_output_loss: 5.3905 - val_length_output_loss: 3.6513\n",
      "Epoch 435/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 2.0148 - note_output_loss: 0.7764 - length_output_loss: 2.4770 - val_loss: 7.2164 - val_note_output_loss: 5.3896 - val_length_output_loss: 3.6536\n",
      "Epoch 436/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.0261 - note_output_loss: 0.7922 - length_output_loss: 2.4678 - val_loss: 7.2041 - val_note_output_loss: 5.3721 - val_length_output_loss: 3.6638\n",
      "Epoch 437/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 2.0215 - note_output_loss: 0.7851 - length_output_loss: 2.4728 - val_loss: 7.2103 - val_note_output_loss: 5.3900 - val_length_output_loss: 3.6407\n",
      "Epoch 438/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 2.0112 - note_output_loss: 0.7775 - length_output_loss: 2.4674 - val_loss: 7.2286 - val_note_output_loss: 5.4006 - val_length_output_loss: 3.6561\n",
      "Epoch 439/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 2.0129 - note_output_loss: 0.7750 - length_output_loss: 2.4758 - val_loss: 7.2572 - val_note_output_loss: 5.4313 - val_length_output_loss: 3.6520\n",
      "Epoch 440/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.0159 - note_output_loss: 0.7767 - length_output_loss: 2.4783 - val_loss: 7.2459 - val_note_output_loss: 5.4166 - val_length_output_loss: 3.6586\n",
      "Epoch 441/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.0066 - note_output_loss: 0.7761 - length_output_loss: 2.4610 - val_loss: 7.2008 - val_note_output_loss: 5.3737 - val_length_output_loss: 3.6542\n",
      "Epoch 442/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.0107 - note_output_loss: 0.7720 - length_output_loss: 2.4774 - val_loss: 7.2340 - val_note_output_loss: 5.4033 - val_length_output_loss: 3.6615\n",
      "Epoch 443/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 2.0141 - note_output_loss: 0.7795 - length_output_loss: 2.4692 - val_loss: 7.2754 - val_note_output_loss: 5.4471 - val_length_output_loss: 3.6566\n",
      "Epoch 444/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 2.0075 - note_output_loss: 0.7744 - length_output_loss: 2.4662 - val_loss: 7.2355 - val_note_output_loss: 5.4064 - val_length_output_loss: 3.6581\n",
      "Epoch 445/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 2.0007 - note_output_loss: 0.7658 - length_output_loss: 2.4697 - val_loss: 7.2672 - val_note_output_loss: 5.4332 - val_length_output_loss: 3.6680\n",
      "Epoch 446/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 2.0020 - note_output_loss: 0.7739 - length_output_loss: 2.4561 - val_loss: 7.2364 - val_note_output_loss: 5.4065 - val_length_output_loss: 3.6598\n",
      "Epoch 447/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.0085 - note_output_loss: 0.7744 - length_output_loss: 2.4683 - val_loss: 7.2630 - val_note_output_loss: 5.4315 - val_length_output_loss: 3.6629\n",
      "Epoch 448/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 2.0132 - note_output_loss: 0.7819 - length_output_loss: 2.4626 - val_loss: 7.2498 - val_note_output_loss: 5.4190 - val_length_output_loss: 3.6617\n",
      "Epoch 449/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 2.0027 - note_output_loss: 0.7678 - length_output_loss: 2.4699 - val_loss: 7.2864 - val_note_output_loss: 5.4499 - val_length_output_loss: 3.6730\n",
      "Epoch 450/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 2.0037 - note_output_loss: 0.7714 - length_output_loss: 2.4647 - val_loss: 7.2738 - val_note_output_loss: 5.4426 - val_length_output_loss: 3.6624\n",
      "Epoch 451/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.9915 - note_output_loss: 0.7608 - length_output_loss: 2.4614 - val_loss: 7.2918 - val_note_output_loss: 5.4533 - val_length_output_loss: 3.6770\n",
      "Epoch 452/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.9994 - note_output_loss: 0.7654 - length_output_loss: 2.4679 - val_loss: 7.3270 - val_note_output_loss: 5.4931 - val_length_output_loss: 3.6679\n",
      "Epoch 453/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 2.0005 - note_output_loss: 0.7719 - length_output_loss: 2.4572 - val_loss: 7.3015 - val_note_output_loss: 5.4710 - val_length_output_loss: 3.6612\n",
      "Epoch 454/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 2.0203 - note_output_loss: 0.7869 - length_output_loss: 2.4668 - val_loss: 7.3142 - val_note_output_loss: 5.4817 - val_length_output_loss: 3.6649\n",
      "Epoch 455/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.9898 - note_output_loss: 0.7631 - length_output_loss: 2.4534 - val_loss: 7.3121 - val_note_output_loss: 5.4776 - val_length_output_loss: 3.6689\n",
      "Epoch 456/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.9793 - note_output_loss: 0.7513 - length_output_loss: 2.4560 - val_loss: 7.3069 - val_note_output_loss: 5.4715 - val_length_output_loss: 3.6709\n",
      "Epoch 457/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.9850 - note_output_loss: 0.7539 - length_output_loss: 2.4620 - val_loss: 7.3497 - val_note_output_loss: 5.5129 - val_length_output_loss: 3.6736\n",
      "Epoch 458/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 1.9923 - note_output_loss: 0.7603 - length_output_loss: 2.4640 - val_loss: 7.3383 - val_note_output_loss: 5.5015 - val_length_output_loss: 3.6735\n",
      "Epoch 459/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.9931 - note_output_loss: 0.7632 - length_output_loss: 2.4599 - val_loss: 7.3152 - val_note_output_loss: 5.4853 - val_length_output_loss: 3.6598\n",
      "Epoch 460/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.9982 - note_output_loss: 0.7629 - length_output_loss: 2.4706 - val_loss: 7.3256 - val_note_output_loss: 5.4920 - val_length_output_loss: 3.6672\n",
      "Epoch 461/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.9760 - note_output_loss: 0.7473 - length_output_loss: 2.4574 - val_loss: 7.3782 - val_note_output_loss: 5.5439 - val_length_output_loss: 3.6687\n",
      "Epoch 462/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.9845 - note_output_loss: 0.7580 - length_output_loss: 2.4531 - val_loss: 7.3462 - val_note_output_loss: 5.5098 - val_length_output_loss: 3.6728\n",
      "Epoch 463/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.9745 - note_output_loss: 0.7469 - length_output_loss: 2.4553 - val_loss: 7.3771 - val_note_output_loss: 5.5361 - val_length_output_loss: 3.6819\n",
      "Epoch 464/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.9726 - note_output_loss: 0.7458 - length_output_loss: 2.4536 - val_loss: 7.3430 - val_note_output_loss: 5.5082 - val_length_output_loss: 3.6696\n",
      "Epoch 465/1500\n",
      "7089/7089 [==============================] - 5s 639us/step - loss: 1.9746 - note_output_loss: 0.7463 - length_output_loss: 2.4568 - val_loss: 7.3242 - val_note_output_loss: 5.4945 - val_length_output_loss: 3.6595\n",
      "Epoch 466/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.9693 - note_output_loss: 0.7405 - length_output_loss: 2.4574 - val_loss: 7.3965 - val_note_output_loss: 5.5586 - val_length_output_loss: 3.6758\n",
      "Epoch 467/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.9678 - note_output_loss: 0.7437 - length_output_loss: 2.4483 - val_loss: 7.3571 - val_note_output_loss: 5.5171 - val_length_output_loss: 3.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.9572 - note_output_loss: 0.7317 - length_output_loss: 2.4510 - val_loss: 7.4102 - val_note_output_loss: 5.5745 - val_length_output_loss: 3.6715\n",
      "Epoch 469/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 1.9814 - note_output_loss: 0.7546 - length_output_loss: 2.4536 - val_loss: 7.3651 - val_note_output_loss: 5.5246 - val_length_output_loss: 3.6810\n",
      "Epoch 470/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.9680 - note_output_loss: 0.7417 - length_output_loss: 2.4526 - val_loss: 7.3959 - val_note_output_loss: 5.5537 - val_length_output_loss: 3.6845\n",
      "Epoch 471/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.9591 - note_output_loss: 0.7336 - length_output_loss: 2.4511 - val_loss: 7.4159 - val_note_output_loss: 5.5730 - val_length_output_loss: 3.6857\n",
      "Epoch 472/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.9564 - note_output_loss: 0.7309 - length_output_loss: 2.4511 - val_loss: 7.4400 - val_note_output_loss: 5.5969 - val_length_output_loss: 3.6862\n",
      "Epoch 473/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.9650 - note_output_loss: 0.7411 - length_output_loss: 2.4478 - val_loss: 7.4123 - val_note_output_loss: 5.5697 - val_length_output_loss: 3.6853\n",
      "Epoch 474/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 1.9701 - note_output_loss: 0.7409 - length_output_loss: 2.4584 - val_loss: 7.4243 - val_note_output_loss: 5.5894 - val_length_output_loss: 3.6698\n",
      "Epoch 475/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.9529 - note_output_loss: 0.7276 - length_output_loss: 2.4506 - val_loss: 7.3795 - val_note_output_loss: 5.5408 - val_length_output_loss: 3.6772\n",
      "Epoch 476/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.9443 - note_output_loss: 0.7195 - length_output_loss: 2.4497 - val_loss: 7.3987 - val_note_output_loss: 5.5566 - val_length_output_loss: 3.6841\n",
      "Epoch 477/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.9592 - note_output_loss: 0.7339 - length_output_loss: 2.4506 - val_loss: 7.4477 - val_note_output_loss: 5.6045 - val_length_output_loss: 3.6864\n",
      "Epoch 478/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.9423 - note_output_loss: 0.7204 - length_output_loss: 2.4438 - val_loss: 7.4275 - val_note_output_loss: 5.5875 - val_length_output_loss: 3.6800\n",
      "Epoch 479/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.9566 - note_output_loss: 0.7318 - length_output_loss: 2.4495 - val_loss: 7.4346 - val_note_output_loss: 5.5878 - val_length_output_loss: 3.6936\n",
      "Epoch 480/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.9498 - note_output_loss: 0.7274 - length_output_loss: 2.4447 - val_loss: 7.4707 - val_note_output_loss: 5.6296 - val_length_output_loss: 3.6822\n",
      "Epoch 481/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.9478 - note_output_loss: 0.7260 - length_output_loss: 2.4435 - val_loss: 7.4880 - val_note_output_loss: 5.6433 - val_length_output_loss: 3.6894\n",
      "Epoch 482/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.9392 - note_output_loss: 0.7160 - length_output_loss: 2.4463 - val_loss: 7.4446 - val_note_output_loss: 5.6001 - val_length_output_loss: 3.6891\n",
      "Epoch 483/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.9375 - note_output_loss: 0.7158 - length_output_loss: 2.4433 - val_loss: 7.4594 - val_note_output_loss: 5.6122 - val_length_output_loss: 3.6943\n",
      "Epoch 484/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.9539 - note_output_loss: 0.7322 - length_output_loss: 2.4433 - val_loss: 7.4788 - val_note_output_loss: 5.6320 - val_length_output_loss: 3.6935\n",
      "Epoch 485/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.9358 - note_output_loss: 0.7157 - length_output_loss: 2.4403 - val_loss: 7.4240 - val_note_output_loss: 5.5797 - val_length_output_loss: 3.6884\n",
      "Epoch 486/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.9414 - note_output_loss: 0.7173 - length_output_loss: 2.4482 - val_loss: 7.4615 - val_note_output_loss: 5.6126 - val_length_output_loss: 3.6978\n",
      "Epoch 487/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.9329 - note_output_loss: 0.7134 - length_output_loss: 2.4389 - val_loss: 7.4315 - val_note_output_loss: 5.5911 - val_length_output_loss: 3.6807\n",
      "Epoch 488/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.9403 - note_output_loss: 0.7225 - length_output_loss: 2.4355 - val_loss: 7.4932 - val_note_output_loss: 5.6484 - val_length_output_loss: 3.6897\n",
      "Epoch 489/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.9352 - note_output_loss: 0.7125 - length_output_loss: 2.4454 - val_loss: 7.4735 - val_note_output_loss: 5.6335 - val_length_output_loss: 3.6801\n",
      "Epoch 490/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.9233 - note_output_loss: 0.7071 - length_output_loss: 2.4324 - val_loss: 7.4907 - val_note_output_loss: 5.6449 - val_length_output_loss: 3.6916\n",
      "Epoch 491/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.9318 - note_output_loss: 0.7112 - length_output_loss: 2.4411 - val_loss: 7.4823 - val_note_output_loss: 5.6419 - val_length_output_loss: 3.6808\n",
      "Epoch 492/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.9354 - note_output_loss: 0.7147 - length_output_loss: 2.4413 - val_loss: 7.4662 - val_note_output_loss: 5.6209 - val_length_output_loss: 3.6905\n",
      "Epoch 493/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.9312 - note_output_loss: 0.7137 - length_output_loss: 2.4349 - val_loss: 7.5237 - val_note_output_loss: 5.6762 - val_length_output_loss: 3.6951\n",
      "Epoch 494/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.9155 - note_output_loss: 0.6967 - length_output_loss: 2.4376 - val_loss: 7.5189 - val_note_output_loss: 5.6703 - val_length_output_loss: 3.6972\n",
      "Epoch 495/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.9169 - note_output_loss: 0.6998 - length_output_loss: 2.4343 - val_loss: 7.4766 - val_note_output_loss: 5.6317 - val_length_output_loss: 3.6896\n",
      "Epoch 496/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.9372 - note_output_loss: 0.7181 - length_output_loss: 2.4383 - val_loss: 7.4999 - val_note_output_loss: 5.6503 - val_length_output_loss: 3.6992\n",
      "Epoch 497/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.9274 - note_output_loss: 0.7139 - length_output_loss: 2.4269 - val_loss: 7.5027 - val_note_output_loss: 5.6548 - val_length_output_loss: 3.6958\n",
      "Epoch 498/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.9179 - note_output_loss: 0.7012 - length_output_loss: 2.4335 - val_loss: 7.5194 - val_note_output_loss: 5.6676 - val_length_output_loss: 3.7036\n",
      "Epoch 499/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.9216 - note_output_loss: 0.7048 - length_output_loss: 2.4336 - val_loss: 7.5474 - val_note_output_loss: 5.6935 - val_length_output_loss: 3.7077\n",
      "Epoch 500/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.9306 - note_output_loss: 0.7133 - length_output_loss: 2.4346 - val_loss: 7.5315 - val_note_output_loss: 5.6782 - val_length_output_loss: 3.7066\n",
      "Epoch 501/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.9193 - note_output_loss: 0.6986 - length_output_loss: 2.4412 - val_loss: 7.5434 - val_note_output_loss: 5.6893 - val_length_output_loss: 3.7081\n",
      "Epoch 502/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.9086 - note_output_loss: 0.6895 - length_output_loss: 2.4383 - val_loss: 7.5340 - val_note_output_loss: 5.6875 - val_length_output_loss: 3.6928\n",
      "Epoch 503/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.9093 - note_output_loss: 0.6949 - length_output_loss: 2.4288 - val_loss: 7.5566 - val_note_output_loss: 5.7027 - val_length_output_loss: 3.7079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.9210 - note_output_loss: 0.7094 - length_output_loss: 2.4233 - val_loss: 7.5624 - val_note_output_loss: 5.7119 - val_length_output_loss: 3.7010\n",
      "Epoch 505/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.9168 - note_output_loss: 0.7005 - length_output_loss: 2.4325 - val_loss: 7.5530 - val_note_output_loss: 5.7015 - val_length_output_loss: 3.7031\n",
      "Epoch 506/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.9099 - note_output_loss: 0.6959 - length_output_loss: 2.4279 - val_loss: 7.5318 - val_note_output_loss: 5.6810 - val_length_output_loss: 3.7017\n",
      "Epoch 507/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.8972 - note_output_loss: 0.6860 - length_output_loss: 2.4223 - val_loss: 7.5518 - val_note_output_loss: 5.6970 - val_length_output_loss: 3.7096\n",
      "Epoch 508/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.9115 - note_output_loss: 0.6968 - length_output_loss: 2.4294 - val_loss: 7.5329 - val_note_output_loss: 5.6838 - val_length_output_loss: 3.6983\n",
      "Epoch 509/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.9160 - note_output_loss: 0.7008 - length_output_loss: 2.4303 - val_loss: 7.5775 - val_note_output_loss: 5.7266 - val_length_output_loss: 3.7019\n",
      "Epoch 510/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.9026 - note_output_loss: 0.6892 - length_output_loss: 2.4267 - val_loss: 7.5790 - val_note_output_loss: 5.7219 - val_length_output_loss: 3.7143\n",
      "Epoch 511/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.8887 - note_output_loss: 0.6792 - length_output_loss: 2.4190 - val_loss: 7.5982 - val_note_output_loss: 5.7411 - val_length_output_loss: 3.7142\n",
      "Epoch 512/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.9144 - note_output_loss: 0.7008 - length_output_loss: 2.4272 - val_loss: 7.5993 - val_note_output_loss: 5.7455 - val_length_output_loss: 3.7077\n",
      "Epoch 513/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.9000 - note_output_loss: 0.6885 - length_output_loss: 2.4230 - val_loss: 7.6030 - val_note_output_loss: 5.7466 - val_length_output_loss: 3.7128\n",
      "Epoch 514/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.9079 - note_output_loss: 0.6946 - length_output_loss: 2.4265 - val_loss: 7.6241 - val_note_output_loss: 5.7664 - val_length_output_loss: 3.7154\n",
      "Epoch 515/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.8820 - note_output_loss: 0.6679 - length_output_loss: 2.4281 - val_loss: 7.6563 - val_note_output_loss: 5.7978 - val_length_output_loss: 3.7170\n",
      "Epoch 516/1500\n",
      "7089/7089 [==============================] - 5s 662us/step - loss: 1.9043 - note_output_loss: 0.6945 - length_output_loss: 2.4197 - val_loss: 7.6259 - val_note_output_loss: 5.7686 - val_length_output_loss: 3.7146\n",
      "Epoch 517/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.8870 - note_output_loss: 0.6744 - length_output_loss: 2.4251 - val_loss: 7.6549 - val_note_output_loss: 5.7929 - val_length_output_loss: 3.7240\n",
      "Epoch 518/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.8927 - note_output_loss: 0.6798 - length_output_loss: 2.4257 - val_loss: 7.6482 - val_note_output_loss: 5.7874 - val_length_output_loss: 3.7216\n",
      "Epoch 519/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.8883 - note_output_loss: 0.6747 - length_output_loss: 2.4272 - val_loss: 7.6407 - val_note_output_loss: 5.7814 - val_length_output_loss: 3.7186\n",
      "Epoch 520/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.8960 - note_output_loss: 0.6819 - length_output_loss: 2.4280 - val_loss: 7.6178 - val_note_output_loss: 5.7600 - val_length_output_loss: 3.7156\n",
      "Epoch 521/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8695 - note_output_loss: 0.6598 - length_output_loss: 2.4193 - val_loss: 7.5965 - val_note_output_loss: 5.7395 - val_length_output_loss: 3.7141\n",
      "Epoch 522/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.8812 - note_output_loss: 0.6687 - length_output_loss: 2.4251 - val_loss: 7.6293 - val_note_output_loss: 5.7700 - val_length_output_loss: 3.7186\n",
      "Epoch 523/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.8870 - note_output_loss: 0.6749 - length_output_loss: 2.4242 - val_loss: 7.6306 - val_note_output_loss: 5.7705 - val_length_output_loss: 3.7202\n",
      "Epoch 524/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8815 - note_output_loss: 0.6717 - length_output_loss: 2.4196 - val_loss: 7.6638 - val_note_output_loss: 5.8070 - val_length_output_loss: 3.7136\n",
      "Epoch 525/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.9009 - note_output_loss: 0.6932 - length_output_loss: 2.4154 - val_loss: 7.6249 - val_note_output_loss: 5.7693 - val_length_output_loss: 3.7113\n",
      "Epoch 526/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8794 - note_output_loss: 0.6680 - length_output_loss: 2.4228 - val_loss: 7.6310 - val_note_output_loss: 5.7693 - val_length_output_loss: 3.7234\n",
      "Epoch 527/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.8749 - note_output_loss: 0.6678 - length_output_loss: 2.4141 - val_loss: 7.6606 - val_note_output_loss: 5.7994 - val_length_output_loss: 3.7224\n",
      "Epoch 528/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.8762 - note_output_loss: 0.6713 - length_output_loss: 2.4098 - val_loss: 7.6730 - val_note_output_loss: 5.8101 - val_length_output_loss: 3.7258\n",
      "Epoch 529/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.8686 - note_output_loss: 0.6589 - length_output_loss: 2.4195 - val_loss: 7.6688 - val_note_output_loss: 5.8058 - val_length_output_loss: 3.7260\n",
      "Epoch 530/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.8701 - note_output_loss: 0.6603 - length_output_loss: 2.4195 - val_loss: 7.6737 - val_note_output_loss: 5.8081 - val_length_output_loss: 3.7312\n",
      "Epoch 531/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.8735 - note_output_loss: 0.6613 - length_output_loss: 2.4243 - val_loss: 7.6783 - val_note_output_loss: 5.8160 - val_length_output_loss: 3.7246\n",
      "Epoch 532/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.8684 - note_output_loss: 0.6603 - length_output_loss: 2.4163 - val_loss: 7.6851 - val_note_output_loss: 5.8227 - val_length_output_loss: 3.7249\n",
      "Epoch 533/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.8650 - note_output_loss: 0.6570 - length_output_loss: 2.4161 - val_loss: 7.7421 - val_note_output_loss: 5.8737 - val_length_output_loss: 3.7370\n",
      "Epoch 534/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8615 - note_output_loss: 0.6523 - length_output_loss: 2.4183 - val_loss: 7.7035 - val_note_output_loss: 5.8422 - val_length_output_loss: 3.7226\n",
      "Epoch 535/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8632 - note_output_loss: 0.6550 - length_output_loss: 2.4163 - val_loss: 7.6850 - val_note_output_loss: 5.8223 - val_length_output_loss: 3.7255\n",
      "Epoch 536/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.8536 - note_output_loss: 0.6489 - length_output_loss: 2.4093 - val_loss: 7.6819 - val_note_output_loss: 5.8162 - val_length_output_loss: 3.7314\n",
      "Epoch 537/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.8580 - note_output_loss: 0.6545 - length_output_loss: 2.4071 - val_loss: 7.7272 - val_note_output_loss: 5.8628 - val_length_output_loss: 3.7289\n",
      "Epoch 538/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8654 - note_output_loss: 0.6540 - length_output_loss: 2.4228 - val_loss: 7.6942 - val_note_output_loss: 5.8272 - val_length_output_loss: 3.7339\n",
      "Epoch 539/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8619 - note_output_loss: 0.6563 - length_output_loss: 2.4111 - val_loss: 7.7405 - val_note_output_loss: 5.8743 - val_length_output_loss: 3.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.8560 - note_output_loss: 0.6533 - length_output_loss: 2.4054 - val_loss: 7.7707 - val_note_output_loss: 5.9036 - val_length_output_loss: 3.7342\n",
      "Epoch 541/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.8687 - note_output_loss: 0.6635 - length_output_loss: 2.4103 - val_loss: 7.7488 - val_note_output_loss: 5.8795 - val_length_output_loss: 3.7386\n",
      "Epoch 542/1500\n",
      "7089/7089 [==============================] - 5s 707us/step - loss: 1.8511 - note_output_loss: 0.6506 - length_output_loss: 2.4009 - val_loss: 7.7341 - val_note_output_loss: 5.8702 - val_length_output_loss: 3.7278\n",
      "Epoch 543/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.8477 - note_output_loss: 0.6462 - length_output_loss: 2.4029 - val_loss: 7.7457 - val_note_output_loss: 5.8780 - val_length_output_loss: 3.7355\n",
      "Epoch 544/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.8483 - note_output_loss: 0.6510 - length_output_loss: 2.3946 - val_loss: 7.7703 - val_note_output_loss: 5.9007 - val_length_output_loss: 3.7392\n",
      "Epoch 545/1500\n",
      "7089/7089 [==============================] - 5s 716us/step - loss: 1.8510 - note_output_loss: 0.6468 - length_output_loss: 2.4083 - val_loss: 7.7432 - val_note_output_loss: 5.8746 - val_length_output_loss: 3.7372\n",
      "Epoch 546/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8459 - note_output_loss: 0.6462 - length_output_loss: 2.3994 - val_loss: 7.7398 - val_note_output_loss: 5.8739 - val_length_output_loss: 3.7317\n",
      "Epoch 547/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8352 - note_output_loss: 0.6337 - length_output_loss: 2.4028 - val_loss: 7.7686 - val_note_output_loss: 5.8970 - val_length_output_loss: 3.7432\n",
      "Epoch 548/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8493 - note_output_loss: 0.6473 - length_output_loss: 2.4039 - val_loss: 7.7537 - val_note_output_loss: 5.8874 - val_length_output_loss: 3.7325\n",
      "Epoch 549/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.8402 - note_output_loss: 0.6425 - length_output_loss: 2.3956 - val_loss: 7.8077 - val_note_output_loss: 5.9366 - val_length_output_loss: 3.7421\n",
      "Epoch 550/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.8369 - note_output_loss: 0.6359 - length_output_loss: 2.4020 - val_loss: 7.7969 - val_note_output_loss: 5.9250 - val_length_output_loss: 3.7440\n",
      "Epoch 551/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.8327 - note_output_loss: 0.6340 - length_output_loss: 2.3974 - val_loss: 7.8081 - val_note_output_loss: 5.9382 - val_length_output_loss: 3.7398\n",
      "Epoch 552/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.8362 - note_output_loss: 0.6396 - length_output_loss: 2.3932 - val_loss: 7.7776 - val_note_output_loss: 5.9073 - val_length_output_loss: 3.7406\n",
      "Epoch 553/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8487 - note_output_loss: 0.6476 - length_output_loss: 2.4022 - val_loss: 7.7866 - val_note_output_loss: 5.9191 - val_length_output_loss: 3.7351\n",
      "Epoch 554/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8459 - note_output_loss: 0.6464 - length_output_loss: 2.3989 - val_loss: 7.7968 - val_note_output_loss: 5.9261 - val_length_output_loss: 3.7413\n",
      "Epoch 555/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.8274 - note_output_loss: 0.6291 - length_output_loss: 2.3967 - val_loss: 7.7941 - val_note_output_loss: 5.9168 - val_length_output_loss: 3.7548\n",
      "Epoch 556/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.8245 - note_output_loss: 0.6293 - length_output_loss: 2.3906 - val_loss: 7.8126 - val_note_output_loss: 5.9383 - val_length_output_loss: 3.7486\n",
      "Epoch 557/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.8392 - note_output_loss: 0.6390 - length_output_loss: 2.4003 - val_loss: 7.8080 - val_note_output_loss: 5.9371 - val_length_output_loss: 3.7418\n",
      "Epoch 558/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8299 - note_output_loss: 0.6341 - length_output_loss: 2.3916 - val_loss: 7.8319 - val_note_output_loss: 5.9633 - val_length_output_loss: 3.7373\n",
      "Epoch 559/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.8365 - note_output_loss: 0.6336 - length_output_loss: 2.4057 - val_loss: 7.8116 - val_note_output_loss: 5.9447 - val_length_output_loss: 3.7338\n",
      "Epoch 560/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.8319 - note_output_loss: 0.6340 - length_output_loss: 2.3958 - val_loss: 7.7866 - val_note_output_loss: 5.9149 - val_length_output_loss: 3.7434\n",
      "Epoch 561/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.8185 - note_output_loss: 0.6225 - length_output_loss: 2.3921 - val_loss: 7.8164 - val_note_output_loss: 5.9424 - val_length_output_loss: 3.7480\n",
      "Epoch 562/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8446 - note_output_loss: 0.6444 - length_output_loss: 2.4003 - val_loss: 7.8185 - val_note_output_loss: 5.9498 - val_length_output_loss: 3.7374\n",
      "Epoch 563/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.8317 - note_output_loss: 0.6331 - length_output_loss: 2.3974 - val_loss: 7.8112 - val_note_output_loss: 5.9353 - val_length_output_loss: 3.7517\n",
      "Epoch 564/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.8227 - note_output_loss: 0.6262 - length_output_loss: 2.3929 - val_loss: 7.8402 - val_note_output_loss: 5.9586 - val_length_output_loss: 3.7631\n",
      "Epoch 565/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8167 - note_output_loss: 0.6214 - length_output_loss: 2.3905 - val_loss: 7.8631 - val_note_output_loss: 5.9857 - val_length_output_loss: 3.7548\n",
      "Epoch 566/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8100 - note_output_loss: 0.6107 - length_output_loss: 2.3986 - val_loss: 7.8317 - val_note_output_loss: 5.9551 - val_length_output_loss: 3.7532\n",
      "Epoch 567/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.8181 - note_output_loss: 0.6229 - length_output_loss: 2.3904 - val_loss: 7.8302 - val_note_output_loss: 5.9566 - val_length_output_loss: 3.7472\n",
      "Epoch 568/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.8156 - note_output_loss: 0.6193 - length_output_loss: 2.3925 - val_loss: 7.8473 - val_note_output_loss: 5.9718 - val_length_output_loss: 3.7510\n",
      "Epoch 569/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.8342 - note_output_loss: 0.6387 - length_output_loss: 2.3911 - val_loss: 7.8327 - val_note_output_loss: 5.9561 - val_length_output_loss: 3.7533\n",
      "Epoch 570/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.8241 - note_output_loss: 0.6288 - length_output_loss: 2.3906 - val_loss: 7.8263 - val_note_output_loss: 5.9542 - val_length_output_loss: 3.7443\n",
      "Epoch 571/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8207 - note_output_loss: 0.6242 - length_output_loss: 2.3929 - val_loss: 7.8935 - val_note_output_loss: 6.0139 - val_length_output_loss: 3.7592\n",
      "Epoch 572/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.8232 - note_output_loss: 0.6285 - length_output_loss: 2.3894 - val_loss: 7.8774 - val_note_output_loss: 6.0002 - val_length_output_loss: 3.7544\n",
      "Epoch 573/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8052 - note_output_loss: 0.6134 - length_output_loss: 2.3835 - val_loss: 7.8475 - val_note_output_loss: 5.9730 - val_length_output_loss: 3.7490\n",
      "Epoch 574/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 1.8153 - note_output_loss: 0.6222 - length_output_loss: 2.3864 - val_loss: 7.9195 - val_note_output_loss: 6.0411 - val_length_output_loss: 3.7569\n",
      "Epoch 575/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.8145 - note_output_loss: 0.6169 - length_output_loss: 2.3952 - val_loss: 7.8617 - val_note_output_loss: 5.9867 - val_length_output_loss: 3.7499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.8160 - note_output_loss: 0.6197 - length_output_loss: 2.3927 - val_loss: 7.8548 - val_note_output_loss: 5.9805 - val_length_output_loss: 3.7486\n",
      "Epoch 577/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.8182 - note_output_loss: 0.6211 - length_output_loss: 2.3941 - val_loss: 7.8457 - val_note_output_loss: 5.9743 - val_length_output_loss: 3.7428\n",
      "Epoch 578/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.8099 - note_output_loss: 0.6192 - length_output_loss: 2.3814 - val_loss: 7.8820 - val_note_output_loss: 6.0024 - val_length_output_loss: 3.7592\n",
      "Epoch 579/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.8098 - note_output_loss: 0.6159 - length_output_loss: 2.3879 - val_loss: 7.9113 - val_note_output_loss: 6.0336 - val_length_output_loss: 3.7556\n",
      "Epoch 580/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.7865 - note_output_loss: 0.5985 - length_output_loss: 2.3759 - val_loss: 7.8919 - val_note_output_loss: 6.0162 - val_length_output_loss: 3.7514\n",
      "Epoch 581/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.7989 - note_output_loss: 0.6061 - length_output_loss: 2.3855 - val_loss: 7.9074 - val_note_output_loss: 6.0254 - val_length_output_loss: 3.7640\n",
      "Epoch 582/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.8011 - note_output_loss: 0.6099 - length_output_loss: 2.3825 - val_loss: 7.9180 - val_note_output_loss: 6.0383 - val_length_output_loss: 3.7593\n",
      "Epoch 583/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.8056 - note_output_loss: 0.6162 - length_output_loss: 2.3787 - val_loss: 7.9027 - val_note_output_loss: 6.0219 - val_length_output_loss: 3.7618\n",
      "Epoch 584/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8098 - note_output_loss: 0.6202 - length_output_loss: 2.3792 - val_loss: 7.9242 - val_note_output_loss: 6.0410 - val_length_output_loss: 3.7663\n",
      "Epoch 585/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.7922 - note_output_loss: 0.6023 - length_output_loss: 2.3799 - val_loss: 7.9436 - val_note_output_loss: 6.0592 - val_length_output_loss: 3.7688\n",
      "Epoch 586/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.7959 - note_output_loss: 0.6031 - length_output_loss: 2.3857 - val_loss: 7.9173 - val_note_output_loss: 6.0372 - val_length_output_loss: 3.7603\n",
      "Epoch 587/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.8011 - note_output_loss: 0.6097 - length_output_loss: 2.3826 - val_loss: 7.9225 - val_note_output_loss: 6.0428 - val_length_output_loss: 3.7595\n",
      "Epoch 588/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.8007 - note_output_loss: 0.6096 - length_output_loss: 2.3822 - val_loss: 7.9053 - val_note_output_loss: 6.0302 - val_length_output_loss: 3.7502\n",
      "Epoch 589/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.7839 - note_output_loss: 0.5949 - length_output_loss: 2.3779 - val_loss: 7.9065 - val_note_output_loss: 6.0215 - val_length_output_loss: 3.7699\n",
      "Epoch 590/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.8024 - note_output_loss: 0.6129 - length_output_loss: 2.3790 - val_loss: 7.8919 - val_note_output_loss: 6.0118 - val_length_output_loss: 3.7603\n",
      "Epoch 591/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.7846 - note_output_loss: 0.5953 - length_output_loss: 2.3785 - val_loss: 7.9590 - val_note_output_loss: 6.0736 - val_length_output_loss: 3.7708\n",
      "Epoch 592/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.7860 - note_output_loss: 0.5959 - length_output_loss: 2.3801 - val_loss: 7.9443 - val_note_output_loss: 6.0571 - val_length_output_loss: 3.7746\n",
      "Epoch 593/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.7881 - note_output_loss: 0.5989 - length_output_loss: 2.3783 - val_loss: 7.9600 - val_note_output_loss: 6.0748 - val_length_output_loss: 3.7706\n",
      "Epoch 594/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.7946 - note_output_loss: 0.6064 - length_output_loss: 2.3764 - val_loss: 7.9621 - val_note_output_loss: 6.0774 - val_length_output_loss: 3.7695\n",
      "Epoch 595/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.7879 - note_output_loss: 0.5982 - length_output_loss: 2.3794 - val_loss: 7.9192 - val_note_output_loss: 6.0397 - val_length_output_loss: 3.7590\n",
      "Epoch 596/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.7873 - note_output_loss: 0.6027 - length_output_loss: 2.3692 - val_loss: 7.9645 - val_note_output_loss: 6.0787 - val_length_output_loss: 3.7715\n",
      "Epoch 597/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.7709 - note_output_loss: 0.5877 - length_output_loss: 2.3663 - val_loss: 7.9325 - val_note_output_loss: 6.0465 - val_length_output_loss: 3.7722\n",
      "Epoch 598/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.7887 - note_output_loss: 0.6014 - length_output_loss: 2.3746 - val_loss: 7.9788 - val_note_output_loss: 6.0910 - val_length_output_loss: 3.7755\n",
      "Epoch 599/1500\n",
      "7089/7089 [==============================] - 5s 640us/step - loss: 1.7790 - note_output_loss: 0.5932 - length_output_loss: 2.3717 - val_loss: 7.9815 - val_note_output_loss: 6.0925 - val_length_output_loss: 3.7779\n",
      "Epoch 600/1500\n",
      "7089/7089 [==============================] - 5s 740us/step - loss: 1.7924 - note_output_loss: 0.6033 - length_output_loss: 2.3782 - val_loss: 7.9605 - val_note_output_loss: 6.0731 - val_length_output_loss: 3.7749\n",
      "Epoch 601/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 1.7861 - note_output_loss: 0.5992 - length_output_loss: 2.3737 - val_loss: 7.9275 - val_note_output_loss: 6.0438 - val_length_output_loss: 3.7674\n",
      "Epoch 602/1500\n",
      "7089/7089 [==============================] - 5s 707us/step - loss: 1.7815 - note_output_loss: 0.5955 - length_output_loss: 2.3720 - val_loss: 8.0229 - val_note_output_loss: 6.1283 - val_length_output_loss: 3.7891\n",
      "Epoch 603/1500\n",
      "7089/7089 [==============================] - 6s 815us/step - loss: 1.7826 - note_output_loss: 0.5969 - length_output_loss: 2.3715 - val_loss: 8.0078 - val_note_output_loss: 6.1190 - val_length_output_loss: 3.7776\n",
      "Epoch 604/1500\n",
      "7089/7089 [==============================] - 5s 681us/step - loss: 1.7771 - note_output_loss: 0.5931 - length_output_loss: 2.3682 - val_loss: 7.9965 - val_note_output_loss: 6.1104 - val_length_output_loss: 3.7723\n",
      "Epoch 605/1500\n",
      "7089/7089 [==============================] - 5s 728us/step - loss: 1.7721 - note_output_loss: 0.5860 - length_output_loss: 2.3720 - val_loss: 8.0188 - val_note_output_loss: 6.1291 - val_length_output_loss: 3.7794\n",
      "Epoch 606/1500\n",
      "7089/7089 [==============================] - 5s 697us/step - loss: 1.7687 - note_output_loss: 0.5849 - length_output_loss: 2.3676 - val_loss: 7.9928 - val_note_output_loss: 6.1050 - val_length_output_loss: 3.7757\n",
      "Epoch 607/1500\n",
      "7089/7089 [==============================] - 5s 763us/step - loss: 1.7630 - note_output_loss: 0.5786 - length_output_loss: 2.3688 - val_loss: 7.9869 - val_note_output_loss: 6.0979 - val_length_output_loss: 3.7780\n",
      "Epoch 608/1500\n",
      "7089/7089 [==============================] - 6s 810us/step - loss: 1.7749 - note_output_loss: 0.5914 - length_output_loss: 2.3671 - val_loss: 8.0375 - val_note_output_loss: 6.1494 - val_length_output_loss: 3.7762\n",
      "Epoch 609/1500\n",
      "7089/7089 [==============================] - 5s 742us/step - loss: 1.7740 - note_output_loss: 0.5870 - length_output_loss: 2.3739 - val_loss: 7.9812 - val_note_output_loss: 6.0933 - val_length_output_loss: 3.7758\n",
      "Epoch 610/1500\n",
      "7089/7089 [==============================] - 6s 786us/step - loss: 1.7737 - note_output_loss: 0.5886 - length_output_loss: 2.3702 - val_loss: 7.9853 - val_note_output_loss: 6.0977 - val_length_output_loss: 3.7753\n",
      "Epoch 611/1500\n",
      "7089/7089 [==============================] - 5s 726us/step - loss: 1.7768 - note_output_loss: 0.5876 - length_output_loss: 2.3782 - val_loss: 7.9615 - val_note_output_loss: 6.0741 - val_length_output_loss: 3.7748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1500\n",
      "7089/7089 [==============================] - 5s 714us/step - loss: 1.7578 - note_output_loss: 0.5753 - length_output_loss: 2.3650 - val_loss: 8.0286 - val_note_output_loss: 6.1382 - val_length_output_loss: 3.7809\n",
      "Epoch 613/1500\n",
      "7089/7089 [==============================] - 5s 740us/step - loss: 1.7586 - note_output_loss: 0.5802 - length_output_loss: 2.3568 - val_loss: 8.0291 - val_note_output_loss: 6.1405 - val_length_output_loss: 3.7772\n",
      "Epoch 614/1500\n",
      "7089/7089 [==============================] - 5s 750us/step - loss: 1.7712 - note_output_loss: 0.5891 - length_output_loss: 2.3643 - val_loss: 8.0057 - val_note_output_loss: 6.1203 - val_length_output_loss: 3.7707\n",
      "Epoch 615/1500\n",
      "7089/7089 [==============================] - 6s 874us/step - loss: 1.7726 - note_output_loss: 0.5862 - length_output_loss: 2.3728 - val_loss: 8.0462 - val_note_output_loss: 6.1527 - val_length_output_loss: 3.7872\n",
      "Epoch 616/1500\n",
      "7089/7089 [==============================] - 5s 766us/step - loss: 1.7638 - note_output_loss: 0.5862 - length_output_loss: 2.3553 - val_loss: 8.0050 - val_note_output_loss: 6.1162 - val_length_output_loss: 3.7775\n",
      "Epoch 617/1500\n",
      "7089/7089 [==============================] - 5s 708us/step - loss: 1.7652 - note_output_loss: 0.5819 - length_output_loss: 2.3667 - val_loss: 7.9907 - val_note_output_loss: 6.1043 - val_length_output_loss: 3.7727\n",
      "Epoch 618/1500\n",
      "7089/7089 [==============================] - 5s 711us/step - loss: 1.7620 - note_output_loss: 0.5813 - length_output_loss: 2.3614 - val_loss: 8.0354 - val_note_output_loss: 6.1420 - val_length_output_loss: 3.7868\n",
      "Epoch 619/1500\n",
      "7089/7089 [==============================] - 5s 769us/step - loss: 1.7444 - note_output_loss: 0.5639 - length_output_loss: 2.3609 - val_loss: 8.0554 - val_note_output_loss: 6.1624 - val_length_output_loss: 3.7861\n",
      "Epoch 620/1500\n",
      "7089/7089 [==============================] - 5s 738us/step - loss: 1.7581 - note_output_loss: 0.5771 - length_output_loss: 2.3621 - val_loss: 8.0816 - val_note_output_loss: 6.1854 - val_length_output_loss: 3.7924\n",
      "Epoch 621/1500\n",
      "7089/7089 [==============================] - 5s 743us/step - loss: 1.7572 - note_output_loss: 0.5769 - length_output_loss: 2.3606 - val_loss: 8.0689 - val_note_output_loss: 6.1753 - val_length_output_loss: 3.7871\n",
      "Epoch 622/1500\n",
      "7089/7089 [==============================] - 5s 706us/step - loss: 1.7662 - note_output_loss: 0.5873 - length_output_loss: 2.3579 - val_loss: 8.0469 - val_note_output_loss: 6.1544 - val_length_output_loss: 3.7849\n",
      "Epoch 623/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.7427 - note_output_loss: 0.5610 - length_output_loss: 2.3635 - val_loss: 8.0131 - val_note_output_loss: 6.1219 - val_length_output_loss: 3.7825\n",
      "Epoch 624/1500\n",
      "7089/7089 [==============================] - 5s 686us/step - loss: 1.7526 - note_output_loss: 0.5733 - length_output_loss: 2.3584 - val_loss: 8.1267 - val_note_output_loss: 6.2276 - val_length_output_loss: 3.7981\n",
      "Epoch 625/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 1.7561 - note_output_loss: 0.5809 - length_output_loss: 2.3505 - val_loss: 8.0874 - val_note_output_loss: 6.1927 - val_length_output_loss: 3.7894\n",
      "Epoch 626/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 1.7546 - note_output_loss: 0.5794 - length_output_loss: 2.3503 - val_loss: 8.1045 - val_note_output_loss: 6.2050 - val_length_output_loss: 3.7988\n",
      "Epoch 627/1500\n",
      "7089/7089 [==============================] - 5s 694us/step - loss: 1.7382 - note_output_loss: 0.5654 - length_output_loss: 2.3456 - val_loss: 8.0558 - val_note_output_loss: 6.1588 - val_length_output_loss: 3.7941\n",
      "Epoch 628/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 1.7568 - note_output_loss: 0.5797 - length_output_loss: 2.3542 - val_loss: 8.1219 - val_note_output_loss: 6.2235 - val_length_output_loss: 3.7967\n",
      "Epoch 629/1500\n",
      "7089/7089 [==============================] - 5s 715us/step - loss: 1.7558 - note_output_loss: 0.5733 - length_output_loss: 2.3650 - val_loss: 8.0651 - val_note_output_loss: 6.1687 - val_length_output_loss: 3.7929\n",
      "Epoch 630/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 1.7389 - note_output_loss: 0.5608 - length_output_loss: 2.3563 - val_loss: 8.0686 - val_note_output_loss: 6.1680 - val_length_output_loss: 3.8012\n",
      "Epoch 631/1500\n",
      "7089/7089 [==============================] - 5s 716us/step - loss: 1.7374 - note_output_loss: 0.5628 - length_output_loss: 2.3492 - val_loss: 8.0622 - val_note_output_loss: 6.1636 - val_length_output_loss: 3.7970\n",
      "Epoch 632/1500\n",
      "7089/7089 [==============================] - 5s 735us/step - loss: 1.7379 - note_output_loss: 0.5600 - length_output_loss: 2.3559 - val_loss: 8.0999 - val_note_output_loss: 6.2033 - val_length_output_loss: 3.7931\n",
      "Epoch 633/1500\n",
      "7089/7089 [==============================] - 5s 730us/step - loss: 1.7318 - note_output_loss: 0.5511 - length_output_loss: 2.3613 - val_loss: 8.0976 - val_note_output_loss: 6.2000 - val_length_output_loss: 3.7952\n",
      "Epoch 634/1500\n",
      "7089/7089 [==============================] - 5s 750us/step - loss: 1.7503 - note_output_loss: 0.5739 - length_output_loss: 2.3527 - val_loss: 8.1078 - val_note_output_loss: 6.2087 - val_length_output_loss: 3.7983\n",
      "Epoch 635/1500\n",
      "7089/7089 [==============================] - 5s 766us/step - loss: 1.7410 - note_output_loss: 0.5615 - length_output_loss: 2.3590 - val_loss: 8.0968 - val_note_output_loss: 6.1958 - val_length_output_loss: 3.8019\n",
      "Epoch 636/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.7418 - note_output_loss: 0.5670 - length_output_loss: 2.3496 - val_loss: 8.0296 - val_note_output_loss: 6.1321 - val_length_output_loss: 3.7948\n",
      "Epoch 637/1500\n",
      "7089/7089 [==============================] - 5s 699us/step - loss: 1.7408 - note_output_loss: 0.5636 - length_output_loss: 2.3544 - val_loss: 8.0740 - val_note_output_loss: 6.1717 - val_length_output_loss: 3.8046\n",
      "Epoch 638/1500\n",
      "7089/7089 [==============================] - 5s 745us/step - loss: 1.7403 - note_output_loss: 0.5647 - length_output_loss: 2.3512 - val_loss: 8.0823 - val_note_output_loss: 6.1836 - val_length_output_loss: 3.7974\n",
      "Epoch 639/1500\n",
      "7089/7089 [==============================] - 5s 757us/step - loss: 1.7313 - note_output_loss: 0.5552 - length_output_loss: 2.3521 - val_loss: 8.0888 - val_note_output_loss: 6.1855 - val_length_output_loss: 3.8065\n",
      "Epoch 640/1500\n",
      "7089/7089 [==============================] - 5s 731us/step - loss: 1.7379 - note_output_loss: 0.5670 - length_output_loss: 2.3418 - val_loss: 8.0940 - val_note_output_loss: 6.1914 - val_length_output_loss: 3.8052\n",
      "Epoch 641/1500\n",
      "7089/7089 [==============================] - 5s 727us/step - loss: 1.7436 - note_output_loss: 0.5650 - length_output_loss: 2.3571 - val_loss: 8.1223 - val_note_output_loss: 6.2128 - val_length_output_loss: 3.8190\n",
      "Epoch 642/1500\n",
      "7089/7089 [==============================] - 6s 789us/step - loss: 1.7244 - note_output_loss: 0.5577 - length_output_loss: 2.3335 - val_loss: 8.1449 - val_note_output_loss: 6.2419 - val_length_output_loss: 3.8060\n",
      "Epoch 643/1500\n",
      "7089/7089 [==============================] - 5s 688us/step - loss: 1.7188 - note_output_loss: 0.5428 - length_output_loss: 2.3520 - val_loss: 8.0598 - val_note_output_loss: 6.1620 - val_length_output_loss: 3.7957\n",
      "Epoch 644/1500\n",
      "7089/7089 [==============================] - 5s 700us/step - loss: 1.7391 - note_output_loss: 0.5638 - length_output_loss: 2.3504 - val_loss: 8.1270 - val_note_output_loss: 6.2224 - val_length_output_loss: 3.8093\n",
      "Epoch 645/1500\n",
      "7089/7089 [==============================] - 5s 709us/step - loss: 1.7277 - note_output_loss: 0.5540 - length_output_loss: 2.3473 - val_loss: 8.1442 - val_note_output_loss: 6.2360 - val_length_output_loss: 3.8165\n",
      "Epoch 646/1500\n",
      "7089/7089 [==============================] - 5s 705us/step - loss: 1.7270 - note_output_loss: 0.5539 - length_output_loss: 2.3461 - val_loss: 8.1234 - val_note_output_loss: 6.2207 - val_length_output_loss: 3.8054\n",
      "Epoch 647/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 1.7164 - note_output_loss: 0.5438 - length_output_loss: 2.3452 - val_loss: 8.1228 - val_note_output_loss: 6.2172 - val_length_output_loss: 3.8111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 648/1500\n",
      "7089/7089 [==============================] - 5s 692us/step - loss: 1.7155 - note_output_loss: 0.5479 - length_output_loss: 2.3351 - val_loss: 8.1210 - val_note_output_loss: 6.2149 - val_length_output_loss: 3.8123\n",
      "Epoch 649/1500\n",
      "7089/7089 [==============================] - 5s 748us/step - loss: 1.7250 - note_output_loss: 0.5527 - length_output_loss: 2.3447 - val_loss: 8.1690 - val_note_output_loss: 6.2613 - val_length_output_loss: 3.8153\n",
      "Epoch 650/1500\n",
      "7089/7089 [==============================] - 5s 754us/step - loss: 1.7188 - note_output_loss: 0.5509 - length_output_loss: 2.3358 - val_loss: 8.1773 - val_note_output_loss: 6.2685 - val_length_output_loss: 3.8176\n",
      "Epoch 651/1500\n",
      "7089/7089 [==============================] - 6s 787us/step - loss: 1.7315 - note_output_loss: 0.5581 - length_output_loss: 2.3468 - val_loss: 8.1454 - val_note_output_loss: 6.2417 - val_length_output_loss: 3.8075\n",
      "Epoch 652/1500\n",
      "7089/7089 [==============================] - 5s 743us/step - loss: 1.7272 - note_output_loss: 0.5538 - length_output_loss: 2.3467 - val_loss: 8.1437 - val_note_output_loss: 6.2417 - val_length_output_loss: 3.8040\n",
      "Epoch 653/1500\n",
      "7089/7089 [==============================] - 6s 805us/step - loss: 1.7253 - note_output_loss: 0.5557 - length_output_loss: 2.3391 - val_loss: 8.1678 - val_note_output_loss: 6.2633 - val_length_output_loss: 3.8088\n",
      "Epoch 654/1500\n",
      "7089/7089 [==============================] - 5s 765us/step - loss: 1.7212 - note_output_loss: 0.5500 - length_output_loss: 2.3423 - val_loss: 8.1857 - val_note_output_loss: 6.2782 - val_length_output_loss: 3.8149\n",
      "Epoch 655/1500\n",
      "7089/7089 [==============================] - 6s 778us/step - loss: 1.7213 - note_output_loss: 0.5478 - length_output_loss: 2.3472 - val_loss: 8.1567 - val_note_output_loss: 6.2517 - val_length_output_loss: 3.8101\n",
      "Epoch 656/1500\n",
      "7089/7089 [==============================] - 6s 839us/step - loss: 1.7123 - note_output_loss: 0.5421 - length_output_loss: 2.3404 - val_loss: 8.1625 - val_note_output_loss: 6.2561 - val_length_output_loss: 3.8128\n",
      "Epoch 657/1500\n",
      "7089/7089 [==============================] - 5s 752us/step - loss: 1.7199 - note_output_loss: 0.5512 - length_output_loss: 2.3374 - val_loss: 8.1734 - val_note_output_loss: 6.2720 - val_length_output_loss: 3.8027\n",
      "Epoch 658/1500\n",
      "7089/7089 [==============================] - 5s 721us/step - loss: 1.7165 - note_output_loss: 0.5437 - length_output_loss: 2.3456 - val_loss: 8.1838 - val_note_output_loss: 6.2770 - val_length_output_loss: 3.8137\n",
      "Epoch 659/1500\n",
      "7089/7089 [==============================] - 5s 709us/step - loss: 1.7189 - note_output_loss: 0.5470 - length_output_loss: 2.3439 - val_loss: 8.2271 - val_note_output_loss: 6.3187 - val_length_output_loss: 3.8168\n",
      "Epoch 660/1500\n",
      "7089/7089 [==============================] - 5s 700us/step - loss: 1.7076 - note_output_loss: 0.5361 - length_output_loss: 2.3430 - val_loss: 8.1423 - val_note_output_loss: 6.2377 - val_length_output_loss: 3.8093\n",
      "Epoch 661/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 1.7012 - note_output_loss: 0.5333 - length_output_loss: 2.3358 - val_loss: 8.2169 - val_note_output_loss: 6.3032 - val_length_output_loss: 3.8274\n",
      "Epoch 662/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 1.7020 - note_output_loss: 0.5278 - length_output_loss: 2.3484 - val_loss: 8.1989 - val_note_output_loss: 6.2856 - val_length_output_loss: 3.8267\n",
      "Epoch 663/1500\n",
      "7089/7089 [==============================] - 5s 667us/step - loss: 1.7092 - note_output_loss: 0.5419 - length_output_loss: 2.3346 - val_loss: 8.1915 - val_note_output_loss: 6.2817 - val_length_output_loss: 3.8197\n",
      "Epoch 664/1500\n",
      "7089/7089 [==============================] - 5s 689us/step - loss: 1.7036 - note_output_loss: 0.5364 - length_output_loss: 2.3345 - val_loss: 8.1845 - val_note_output_loss: 6.2765 - val_length_output_loss: 3.8160\n",
      "Epoch 665/1500\n",
      "7089/7089 [==============================] - 5s 732us/step - loss: 1.7040 - note_output_loss: 0.5370 - length_output_loss: 2.3339 - val_loss: 8.2103 - val_note_output_loss: 6.2972 - val_length_output_loss: 3.8263\n",
      "Epoch 666/1500\n",
      "7089/7089 [==============================] - 5s 728us/step - loss: 1.6945 - note_output_loss: 0.5303 - length_output_loss: 2.3284 - val_loss: 8.2206 - val_note_output_loss: 6.3101 - val_length_output_loss: 3.8211\n",
      "Epoch 667/1500\n",
      "7089/7089 [==============================] - 5s 731us/step - loss: 1.7222 - note_output_loss: 0.5584 - length_output_loss: 2.3276 - val_loss: 8.2396 - val_note_output_loss: 6.3292 - val_length_output_loss: 3.8209\n",
      "Epoch 668/1500\n",
      "7089/7089 [==============================] - 6s 787us/step - loss: 1.6997 - note_output_loss: 0.5340 - length_output_loss: 2.3314 - val_loss: 8.2389 - val_note_output_loss: 6.3249 - val_length_output_loss: 3.8281\n",
      "Epoch 669/1500\n",
      "7089/7089 [==============================] - 5s 708us/step - loss: 1.7071 - note_output_loss: 0.5383 - length_output_loss: 2.3376 - val_loss: 8.2531 - val_note_output_loss: 6.3378 - val_length_output_loss: 3.8306\n",
      "Epoch 670/1500\n",
      "7089/7089 [==============================] - 5s 684us/step - loss: 1.6929 - note_output_loss: 0.5271 - length_output_loss: 2.3316 - val_loss: 8.2454 - val_note_output_loss: 6.3332 - val_length_output_loss: 3.8244\n",
      "Epoch 671/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.6885 - note_output_loss: 0.5228 - length_output_loss: 2.3313 - val_loss: 8.2300 - val_note_output_loss: 6.3207 - val_length_output_loss: 3.8186\n",
      "Epoch 672/1500\n",
      "7089/7089 [==============================] - 5s 699us/step - loss: 1.6948 - note_output_loss: 0.5290 - length_output_loss: 2.3316 - val_loss: 8.2213 - val_note_output_loss: 6.3135 - val_length_output_loss: 3.8157\n",
      "Epoch 673/1500\n",
      "7089/7089 [==============================] - 5s 757us/step - loss: 1.6905 - note_output_loss: 0.5296 - length_output_loss: 2.3218 - val_loss: 8.2411 - val_note_output_loss: 6.3297 - val_length_output_loss: 3.8229\n",
      "Epoch 674/1500\n",
      "7089/7089 [==============================] - 5s 733us/step - loss: 1.6966 - note_output_loss: 0.5315 - length_output_loss: 2.3304 - val_loss: 8.2499 - val_note_output_loss: 6.3344 - val_length_output_loss: 3.8310\n",
      "Epoch 675/1500\n",
      "7089/7089 [==============================] - 5s 754us/step - loss: 1.6936 - note_output_loss: 0.5329 - length_output_loss: 2.3213 - val_loss: 8.2493 - val_note_output_loss: 6.3344 - val_length_output_loss: 3.8299\n",
      "Epoch 676/1500\n",
      "7089/7089 [==============================] - 5s 741us/step - loss: 1.7024 - note_output_loss: 0.5374 - length_output_loss: 2.3301 - val_loss: 8.2573 - val_note_output_loss: 6.3400 - val_length_output_loss: 3.8344\n",
      "Epoch 677/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 1.6909 - note_output_loss: 0.5258 - length_output_loss: 2.3302 - val_loss: 8.3580 - val_note_output_loss: 6.4383 - val_length_output_loss: 3.8395\n",
      "Epoch 678/1500\n",
      "7089/7089 [==============================] - 5s 767us/step - loss: 1.7053 - note_output_loss: 0.5407 - length_output_loss: 2.3293 - val_loss: 8.3119 - val_note_output_loss: 6.3922 - val_length_output_loss: 3.8395\n",
      "Epoch 679/1500\n",
      "7089/7089 [==============================] - 5s 687us/step - loss: 1.6975 - note_output_loss: 0.5351 - length_output_loss: 2.3248 - val_loss: 8.2654 - val_note_output_loss: 6.3524 - val_length_output_loss: 3.8260\n",
      "Epoch 680/1500\n",
      "7089/7089 [==============================] - 5s 736us/step - loss: 1.6802 - note_output_loss: 0.5171 - length_output_loss: 2.3261 - val_loss: 8.2798 - val_note_output_loss: 6.3636 - val_length_output_loss: 3.8325\n",
      "Epoch 681/1500\n",
      "7089/7089 [==============================] - 5s 733us/step - loss: 1.6883 - note_output_loss: 0.5234 - length_output_loss: 2.3297 - val_loss: 8.2454 - val_note_output_loss: 6.3332 - val_length_output_loss: 3.8245\n",
      "Epoch 682/1500\n",
      "7089/7089 [==============================] - 5s 691us/step - loss: 1.6768 - note_output_loss: 0.5107 - length_output_loss: 2.3323 - val_loss: 8.2728 - val_note_output_loss: 6.3534 - val_length_output_loss: 3.8387\n",
      "Epoch 683/1500\n",
      "7089/7089 [==============================] - 5s 726us/step - loss: 1.6830 - note_output_loss: 0.5195 - length_output_loss: 2.3270 - val_loss: 8.2907 - val_note_output_loss: 6.3730 - val_length_output_loss: 3.8355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1500\n",
      "7089/7089 [==============================] - 5s 693us/step - loss: 1.6843 - note_output_loss: 0.5235 - length_output_loss: 2.3216 - val_loss: 8.2669 - val_note_output_loss: 6.3517 - val_length_output_loss: 3.8305\n",
      "Epoch 685/1500\n",
      "7089/7089 [==============================] - 5s 681us/step - loss: 1.6894 - note_output_loss: 0.5266 - length_output_loss: 2.3257 - val_loss: 8.2459 - val_note_output_loss: 6.3273 - val_length_output_loss: 3.8373\n",
      "Epoch 686/1500\n",
      "7089/7089 [==============================] - 5s 737us/step - loss: 1.6886 - note_output_loss: 0.5241 - length_output_loss: 2.3290 - val_loss: 8.2693 - val_note_output_loss: 6.3565 - val_length_output_loss: 3.8256\n",
      "Epoch 687/1500\n",
      "7089/7089 [==============================] - 5s 722us/step - loss: 1.6795 - note_output_loss: 0.5188 - length_output_loss: 2.3214 - val_loss: 8.2707 - val_note_output_loss: 6.3566 - val_length_output_loss: 3.8283\n",
      "Epoch 688/1500\n",
      "7089/7089 [==============================] - 6s 783us/step - loss: 1.7043 - note_output_loss: 0.5449 - length_output_loss: 2.3186 - val_loss: 8.2900 - val_note_output_loss: 6.3758 - val_length_output_loss: 3.8284\n",
      "Epoch 689/1500\n",
      "7089/7089 [==============================] - 5s 755us/step - loss: 1.6875 - note_output_loss: 0.5261 - length_output_loss: 2.3228 - val_loss: 8.2471 - val_note_output_loss: 6.3285 - val_length_output_loss: 3.8372\n",
      "Epoch 690/1500\n",
      "7089/7089 [==============================] - 5s 674us/step - loss: 1.6876 - note_output_loss: 0.5268 - length_output_loss: 2.3217 - val_loss: 8.2860 - val_note_output_loss: 6.3640 - val_length_output_loss: 3.8440\n",
      "Epoch 691/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.6835 - note_output_loss: 0.5249 - length_output_loss: 2.3173 - val_loss: 8.2823 - val_note_output_loss: 6.3617 - val_length_output_loss: 3.8411\n",
      "Epoch 692/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.6972 - note_output_loss: 0.5346 - length_output_loss: 2.3252 - val_loss: 8.2878 - val_note_output_loss: 6.3645 - val_length_output_loss: 3.8467\n",
      "Epoch 693/1500\n",
      "7089/7089 [==============================] - 5s 710us/step - loss: 1.6863 - note_output_loss: 0.5253 - length_output_loss: 2.3219 - val_loss: 8.3449 - val_note_output_loss: 6.4212 - val_length_output_loss: 3.8474\n",
      "Epoch 694/1500\n",
      "7089/7089 [==============================] - 5s 740us/step - loss: 1.6777 - note_output_loss: 0.5170 - length_output_loss: 2.3212 - val_loss: 8.2521 - val_note_output_loss: 6.3339 - val_length_output_loss: 3.8365\n",
      "Epoch 695/1500\n",
      "7089/7089 [==============================] - 5s 743us/step - loss: 1.6727 - note_output_loss: 0.5162 - length_output_loss: 2.3129 - val_loss: 8.2587 - val_note_output_loss: 6.3404 - val_length_output_loss: 3.8367\n",
      "Epoch 696/1500\n",
      "7089/7089 [==============================] - 5s 700us/step - loss: 1.6836 - note_output_loss: 0.5211 - length_output_loss: 2.3250 - val_loss: 8.3159 - val_note_output_loss: 6.3957 - val_length_output_loss: 3.8406\n",
      "Epoch 697/1500\n",
      "7089/7089 [==============================] - 5s 685us/step - loss: 1.6782 - note_output_loss: 0.5185 - length_output_loss: 2.3193 - val_loss: 8.2551 - val_note_output_loss: 6.3356 - val_length_output_loss: 3.8392\n",
      "Epoch 698/1500\n",
      "7089/7089 [==============================] - 5s 674us/step - loss: 1.6815 - note_output_loss: 0.5293 - length_output_loss: 2.3044 - val_loss: 8.2644 - val_note_output_loss: 6.3482 - val_length_output_loss: 3.8324\n",
      "Epoch 699/1500\n",
      "7089/7089 [==============================] - 5s 761us/step - loss: 1.6833 - note_output_loss: 0.5231 - length_output_loss: 2.3203 - val_loss: 8.2768 - val_note_output_loss: 6.3556 - val_length_output_loss: 3.8424\n",
      "Epoch 700/1500\n",
      "7089/7089 [==============================] - 5s 685us/step - loss: 1.6711 - note_output_loss: 0.5170 - length_output_loss: 2.3081 - val_loss: 8.3308 - val_note_output_loss: 6.4060 - val_length_output_loss: 3.8495\n",
      "Epoch 701/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.6640 - note_output_loss: 0.5064 - length_output_loss: 2.3153 - val_loss: 8.2918 - val_note_output_loss: 6.3703 - val_length_output_loss: 3.8431\n",
      "Epoch 702/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 1.6745 - note_output_loss: 0.5129 - length_output_loss: 2.3232 - val_loss: 8.3230 - val_note_output_loss: 6.3969 - val_length_output_loss: 3.8520\n",
      "Epoch 703/1500\n",
      "7089/7089 [==============================] - 5s 689us/step - loss: 1.6595 - note_output_loss: 0.5056 - length_output_loss: 2.3076 - val_loss: 8.3162 - val_note_output_loss: 6.3975 - val_length_output_loss: 3.8375\n",
      "Epoch 704/1500\n",
      "7089/7089 [==============================] - 5s 708us/step - loss: 1.6699 - note_output_loss: 0.5141 - length_output_loss: 2.3117 - val_loss: 8.3231 - val_note_output_loss: 6.3970 - val_length_output_loss: 3.8523\n",
      "Epoch 705/1500\n",
      "7089/7089 [==============================] - 5s 712us/step - loss: 1.6846 - note_output_loss: 0.5257 - length_output_loss: 2.3179 - val_loss: 8.3184 - val_note_output_loss: 6.3906 - val_length_output_loss: 3.8556\n",
      "Epoch 706/1500\n",
      "7089/7089 [==============================] - 5s 691us/step - loss: 1.6856 - note_output_loss: 0.5281 - length_output_loss: 2.3151 - val_loss: 8.3319 - val_note_output_loss: 6.4074 - val_length_output_loss: 3.8491\n",
      "Epoch 707/1500\n",
      "7089/7089 [==============================] - 5s 696us/step - loss: 1.6768 - note_output_loss: 0.5201 - length_output_loss: 2.3133 - val_loss: 8.3664 - val_note_output_loss: 6.4443 - val_length_output_loss: 3.8442\n",
      "Epoch 708/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 1.6601 - note_output_loss: 0.5019 - length_output_loss: 2.3165 - val_loss: 8.3651 - val_note_output_loss: 6.4468 - val_length_output_loss: 3.8366\n",
      "Epoch 709/1500\n",
      "7089/7089 [==============================] - 5s 759us/step - loss: 1.6733 - note_output_loss: 0.5151 - length_output_loss: 2.3163 - val_loss: 8.3759 - val_note_output_loss: 6.4520 - val_length_output_loss: 3.8478\n",
      "Epoch 710/1500\n",
      "7089/7089 [==============================] - 5s 745us/step - loss: 1.6758 - note_output_loss: 0.5172 - length_output_loss: 2.3171 - val_loss: 8.3560 - val_note_output_loss: 6.4272 - val_length_output_loss: 3.8576\n",
      "Epoch 711/1500\n",
      "7089/7089 [==============================] - 5s 666us/step - loss: 1.6615 - note_output_loss: 0.5031 - length_output_loss: 2.3168 - val_loss: 8.3987 - val_note_output_loss: 6.4743 - val_length_output_loss: 3.8488\n",
      "Epoch 712/1500\n",
      "7089/7089 [==============================] - 5s 694us/step - loss: 1.6663 - note_output_loss: 0.5096 - length_output_loss: 2.3135 - val_loss: 8.3543 - val_note_output_loss: 6.4276 - val_length_output_loss: 3.8532\n",
      "Epoch 713/1500\n",
      "7089/7089 [==============================] - 5s 706us/step - loss: 1.6533 - note_output_loss: 0.5006 - length_output_loss: 2.3054 - val_loss: 8.3996 - val_note_output_loss: 6.4717 - val_length_output_loss: 3.8558\n",
      "Epoch 714/1500\n",
      "7089/7089 [==============================] - 5s 685us/step - loss: 1.6719 - note_output_loss: 0.5176 - length_output_loss: 2.3085 - val_loss: 8.4007 - val_note_output_loss: 6.4733 - val_length_output_loss: 3.8547\n",
      "Epoch 715/1500\n",
      "7089/7089 [==============================] - 5s 746us/step - loss: 1.6668 - note_output_loss: 0.5096 - length_output_loss: 2.3145 - val_loss: 8.3156 - val_note_output_loss: 6.3899 - val_length_output_loss: 3.8513\n",
      "Epoch 716/1500\n",
      "7089/7089 [==============================] - 5s 695us/step - loss: 1.6476 - note_output_loss: 0.4979 - length_output_loss: 2.2994 - val_loss: 8.3811 - val_note_output_loss: 6.4518 - val_length_output_loss: 3.8587\n",
      "Epoch 717/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 1.6862 - note_output_loss: 0.5291 - length_output_loss: 2.3141 - val_loss: 8.3808 - val_note_output_loss: 6.4476 - val_length_output_loss: 3.8664\n",
      "Epoch 718/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 1.6589 - note_output_loss: 0.5073 - length_output_loss: 2.3032 - val_loss: 8.3525 - val_note_output_loss: 6.4240 - val_length_output_loss: 3.8570\n",
      "Epoch 719/1500\n",
      "7089/7089 [==============================] - 5s 690us/step - loss: 1.6445 - note_output_loss: 0.4887 - length_output_loss: 2.3117 - val_loss: 8.3786 - val_note_output_loss: 6.4520 - val_length_output_loss: 3.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/1500\n",
      "7089/7089 [==============================] - 5s 739us/step - loss: 1.6626 - note_output_loss: 0.5066 - length_output_loss: 2.3120 - val_loss: 8.4145 - val_note_output_loss: 6.4819 - val_length_output_loss: 3.8652\n",
      "Epoch 721/1500\n",
      "7089/7089 [==============================] - 5s 733us/step - loss: 1.6524 - note_output_loss: 0.4994 - length_output_loss: 2.3060 - val_loss: 8.4146 - val_note_output_loss: 6.4823 - val_length_output_loss: 3.8647\n",
      "Epoch 722/1500\n",
      "7089/7089 [==============================] - 5s 741us/step - loss: 1.6498 - note_output_loss: 0.4950 - length_output_loss: 2.3097 - val_loss: 8.3906 - val_note_output_loss: 6.4589 - val_length_output_loss: 3.8634\n",
      "Epoch 723/1500\n",
      "7089/7089 [==============================] - 5s 763us/step - loss: 1.6607 - note_output_loss: 0.5051 - length_output_loss: 2.3112 - val_loss: 8.3623 - val_note_output_loss: 6.4279 - val_length_output_loss: 3.8688\n",
      "Epoch 724/1500\n",
      "7089/7089 [==============================] - 5s 755us/step - loss: 1.6484 - note_output_loss: 0.4989 - length_output_loss: 2.2990 - val_loss: 8.3557 - val_note_output_loss: 6.4336 - val_length_output_loss: 3.8442\n",
      "Epoch 725/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.6450 - note_output_loss: 0.4951 - length_output_loss: 2.2998 - val_loss: 8.3787 - val_note_output_loss: 6.4468 - val_length_output_loss: 3.8636\n",
      "Epoch 726/1500\n",
      "7089/7089 [==============================] - 6s 821us/step - loss: 1.6723 - note_output_loss: 0.5213 - length_output_loss: 2.3020 - val_loss: 8.4222 - val_note_output_loss: 6.4935 - val_length_output_loss: 3.8573\n",
      "Epoch 727/1500\n",
      "7089/7089 [==============================] - 5s 749us/step - loss: 1.6448 - note_output_loss: 0.4925 - length_output_loss: 2.3046 - val_loss: 8.3812 - val_note_output_loss: 6.4494 - val_length_output_loss: 3.8634\n",
      "Epoch 728/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.6538 - note_output_loss: 0.4994 - length_output_loss: 2.3087 - val_loss: 8.4434 - val_note_output_loss: 6.5091 - val_length_output_loss: 3.8686\n",
      "Epoch 729/1500\n",
      "7089/7089 [==============================] - 5s 716us/step - loss: 1.6521 - note_output_loss: 0.4976 - length_output_loss: 2.3089 - val_loss: 8.3885 - val_note_output_loss: 6.4527 - val_length_output_loss: 3.8716\n",
      "Epoch 730/1500\n",
      "7089/7089 [==============================] - 6s 788us/step - loss: 1.6514 - note_output_loss: 0.5013 - length_output_loss: 2.3002 - val_loss: 8.4398 - val_note_output_loss: 6.5017 - val_length_output_loss: 3.8761\n",
      "Epoch 731/1500\n",
      "7089/7089 [==============================] - 5s 743us/step - loss: 1.6330 - note_output_loss: 0.4850 - length_output_loss: 2.2959 - val_loss: 8.3893 - val_note_output_loss: 6.4535 - val_length_output_loss: 3.8715\n",
      "Epoch 732/1500\n",
      "7089/7089 [==============================] - 5s 678us/step - loss: 1.6459 - note_output_loss: 0.4950 - length_output_loss: 2.3017 - val_loss: 8.4244 - val_note_output_loss: 6.4912 - val_length_output_loss: 3.8665\n",
      "Epoch 733/1500\n",
      "7089/7089 [==============================] - 5s 729us/step - loss: 1.6374 - note_output_loss: 0.4860 - length_output_loss: 2.3029 - val_loss: 8.4746 - val_note_output_loss: 6.5404 - val_length_output_loss: 3.8683\n",
      "Epoch 734/1500\n",
      "7089/7089 [==============================] - 5s 719us/step - loss: 1.6558 - note_output_loss: 0.5067 - length_output_loss: 2.2981 - val_loss: 8.4344 - val_note_output_loss: 6.4998 - val_length_output_loss: 3.8693\n",
      "Epoch 735/1500\n",
      "7089/7089 [==============================] - 5s 687us/step - loss: 1.6256 - note_output_loss: 0.4751 - length_output_loss: 2.3008 - val_loss: 8.4394 - val_note_output_loss: 6.5056 - val_length_output_loss: 3.8677\n",
      "Epoch 736/1500\n",
      "7089/7089 [==============================] - 5s 693us/step - loss: 1.6216 - note_output_loss: 0.4773 - length_output_loss: 2.2887 - val_loss: 8.4414 - val_note_output_loss: 6.5035 - val_length_output_loss: 3.8758\n",
      "Epoch 737/1500\n",
      "7089/7089 [==============================] - 5s 755us/step - loss: 1.6451 - note_output_loss: 0.5018 - length_output_loss: 2.2866 - val_loss: 8.4351 - val_note_output_loss: 6.4956 - val_length_output_loss: 3.8791\n",
      "Epoch 738/1500\n",
      "7089/7089 [==============================] - 6s 829us/step - loss: 1.6295 - note_output_loss: 0.4799 - length_output_loss: 2.2992 - val_loss: 8.4156 - val_note_output_loss: 6.4794 - val_length_output_loss: 3.8725\n",
      "Epoch 739/1500\n",
      "7089/7089 [==============================] - 6s 797us/step - loss: 1.6369 - note_output_loss: 0.4918 - length_output_loss: 2.2901 - val_loss: 8.4760 - val_note_output_loss: 6.5388 - val_length_output_loss: 3.8744\n",
      "Epoch 740/1500\n",
      "7089/7089 [==============================] - 5s 692us/step - loss: 1.6320 - note_output_loss: 0.4794 - length_output_loss: 2.3053 - val_loss: 8.4342 - val_note_output_loss: 6.4957 - val_length_output_loss: 3.8771\n",
      "Epoch 741/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 1.6424 - note_output_loss: 0.4971 - length_output_loss: 2.2905 - val_loss: 8.4473 - val_note_output_loss: 6.5081 - val_length_output_loss: 3.8784\n",
      "Epoch 742/1500\n",
      "7089/7089 [==============================] - 5s 725us/step - loss: 1.6348 - note_output_loss: 0.4892 - length_output_loss: 2.2911 - val_loss: 8.4484 - val_note_output_loss: 6.5116 - val_length_output_loss: 3.8735\n",
      "Epoch 743/1500\n",
      "7089/7089 [==============================] - 5s 760us/step - loss: 1.6414 - note_output_loss: 0.4946 - length_output_loss: 2.2936 - val_loss: 8.4539 - val_note_output_loss: 6.5203 - val_length_output_loss: 3.8671\n",
      "Epoch 744/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.6312 - note_output_loss: 0.4885 - length_output_loss: 2.2854 - val_loss: 8.4154 - val_note_output_loss: 6.4770 - val_length_output_loss: 3.8769\n",
      "Epoch 745/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.6314 - note_output_loss: 0.4852 - length_output_loss: 2.2924 - val_loss: 8.4863 - val_note_output_loss: 6.5509 - val_length_output_loss: 3.8708\n",
      "Epoch 746/1500\n",
      "7089/7089 [==============================] - 5s 683us/step - loss: 1.6301 - note_output_loss: 0.4867 - length_output_loss: 2.2868 - val_loss: 8.4565 - val_note_output_loss: 6.5197 - val_length_output_loss: 3.8737\n",
      "Epoch 747/1500\n",
      "7089/7089 [==============================] - 5s 757us/step - loss: 1.6322 - note_output_loss: 0.4844 - length_output_loss: 2.2955 - val_loss: 8.4277 - val_note_output_loss: 6.4926 - val_length_output_loss: 3.8701\n",
      "Epoch 748/1500\n",
      "7089/7089 [==============================] - 6s 781us/step - loss: 1.6266 - note_output_loss: 0.4814 - length_output_loss: 2.2905 - val_loss: 8.4496 - val_note_output_loss: 6.5122 - val_length_output_loss: 3.8748\n",
      "Epoch 749/1500\n",
      "7089/7089 [==============================] - 5s 766us/step - loss: 1.6282 - note_output_loss: 0.4850 - length_output_loss: 2.2865 - val_loss: 8.4565 - val_note_output_loss: 6.5186 - val_length_output_loss: 3.8756\n",
      "Epoch 750/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.6210 - note_output_loss: 0.4761 - length_output_loss: 2.2897 - val_loss: 8.5182 - val_note_output_loss: 6.5740 - val_length_output_loss: 3.8884\n",
      "Epoch 751/1500\n",
      "7089/7089 [==============================] - 6s 805us/step - loss: 1.6406 - note_output_loss: 0.4980 - length_output_loss: 2.2852 - val_loss: 8.4665 - val_note_output_loss: 6.5298 - val_length_output_loss: 3.8735\n",
      "Epoch 752/1500\n",
      "7089/7089 [==============================] - 5s 748us/step - loss: 1.6272 - note_output_loss: 0.4817 - length_output_loss: 2.2909 - val_loss: 8.4618 - val_note_output_loss: 6.5210 - val_length_output_loss: 3.8817\n",
      "Epoch 753/1500\n",
      "7089/7089 [==============================] - 5s 710us/step - loss: 1.6252 - note_output_loss: 0.4813 - length_output_loss: 2.2877 - val_loss: 8.4697 - val_note_output_loss: 6.5359 - val_length_output_loss: 3.8675\n",
      "Epoch 754/1500\n",
      "7089/7089 [==============================] - 5s 725us/step - loss: 1.6322 - note_output_loss: 0.4865 - length_output_loss: 2.2916 - val_loss: 8.4993 - val_note_output_loss: 6.5625 - val_length_output_loss: 3.8737\n",
      "Epoch 755/1500\n",
      "7089/7089 [==============================] - 6s 779us/step - loss: 1.6211 - note_output_loss: 0.4771 - length_output_loss: 2.2880 - val_loss: 8.5286 - val_note_output_loss: 6.5864 - val_length_output_loss: 3.8844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 756/1500\n",
      "7089/7089 [==============================] - 5s 707us/step - loss: 1.6177 - note_output_loss: 0.4732 - length_output_loss: 2.2890 - val_loss: 8.5339 - val_note_output_loss: 6.5922 - val_length_output_loss: 3.8835\n",
      "Epoch 757/1500\n",
      "7089/7089 [==============================] - 5s 742us/step - loss: 1.6302 - note_output_loss: 0.4845 - length_output_loss: 2.2915 - val_loss: 8.4803 - val_note_output_loss: 6.5420 - val_length_output_loss: 3.8766\n",
      "Epoch 758/1500\n",
      "7089/7089 [==============================] - 5s 676us/step - loss: 1.6333 - note_output_loss: 0.4887 - length_output_loss: 2.2892 - val_loss: 8.4879 - val_note_output_loss: 6.5438 - val_length_output_loss: 3.8882\n",
      "Epoch 759/1500\n",
      "7089/7089 [==============================] - 5s 755us/step - loss: 1.6238 - note_output_loss: 0.4787 - length_output_loss: 2.2903 - val_loss: 8.4960 - val_note_output_loss: 6.5524 - val_length_output_loss: 3.8871\n",
      "Epoch 760/1500\n",
      "7089/7089 [==============================] - 6s 798us/step - loss: 1.6286 - note_output_loss: 0.4853 - length_output_loss: 2.2866 - val_loss: 8.4850 - val_note_output_loss: 6.5404 - val_length_output_loss: 3.8892\n",
      "Epoch 761/1500\n",
      "7089/7089 [==============================] - 6s 815us/step - loss: 1.6205 - note_output_loss: 0.4805 - length_output_loss: 2.2801 - val_loss: 8.5245 - val_note_output_loss: 6.5783 - val_length_output_loss: 3.8924\n",
      "Epoch 762/1500\n",
      "7089/7089 [==============================] - 5s 701us/step - loss: 1.6184 - note_output_loss: 0.4767 - length_output_loss: 2.2835 - val_loss: 8.4835 - val_note_output_loss: 6.5438 - val_length_output_loss: 3.8794\n",
      "Epoch 763/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 1.6123 - note_output_loss: 0.4691 - length_output_loss: 2.2863 - val_loss: 8.5232 - val_note_output_loss: 6.5804 - val_length_output_loss: 3.8856\n",
      "Epoch 764/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.6153 - note_output_loss: 0.4777 - length_output_loss: 2.2751 - val_loss: 8.5214 - val_note_output_loss: 6.5738 - val_length_output_loss: 3.8951\n",
      "Epoch 765/1500\n",
      "7089/7089 [==============================] - 5s 728us/step - loss: 1.6366 - note_output_loss: 0.4927 - length_output_loss: 2.2878 - val_loss: 8.5280 - val_note_output_loss: 6.5851 - val_length_output_loss: 3.8858\n",
      "Epoch 766/1500\n",
      "7089/7089 [==============================] - 5s 684us/step - loss: 1.6080 - note_output_loss: 0.4706 - length_output_loss: 2.2747 - val_loss: 8.4969 - val_note_output_loss: 6.5547 - val_length_output_loss: 3.8845\n",
      "Epoch 767/1500\n",
      "7089/7089 [==============================] - 5s 666us/step - loss: 1.6222 - note_output_loss: 0.4795 - length_output_loss: 2.2855 - val_loss: 8.5439 - val_note_output_loss: 6.6024 - val_length_output_loss: 3.8829\n",
      "Epoch 768/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.6106 - note_output_loss: 0.4678 - length_output_loss: 2.2856 - val_loss: 8.5162 - val_note_output_loss: 6.5726 - val_length_output_loss: 3.8873\n",
      "Epoch 769/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.6135 - note_output_loss: 0.4763 - length_output_loss: 2.2743 - val_loss: 8.5183 - val_note_output_loss: 6.5700 - val_length_output_loss: 3.8967\n",
      "Epoch 770/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 1.6063 - note_output_loss: 0.4642 - length_output_loss: 2.2843 - val_loss: 8.5131 - val_note_output_loss: 6.5618 - val_length_output_loss: 3.9025\n",
      "Epoch 771/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.6049 - note_output_loss: 0.4631 - length_output_loss: 2.2836 - val_loss: 8.5534 - val_note_output_loss: 6.6074 - val_length_output_loss: 3.8919\n",
      "Epoch 772/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.6106 - note_output_loss: 0.4722 - length_output_loss: 2.2768 - val_loss: 8.5270 - val_note_output_loss: 6.5770 - val_length_output_loss: 3.8999\n",
      "Epoch 773/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 1.6049 - note_output_loss: 0.4666 - length_output_loss: 2.2764 - val_loss: 8.5488 - val_note_output_loss: 6.6014 - val_length_output_loss: 3.8948\n",
      "Epoch 774/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.6180 - note_output_loss: 0.4758 - length_output_loss: 2.2844 - val_loss: 8.5433 - val_note_output_loss: 6.5957 - val_length_output_loss: 3.8952\n",
      "Epoch 775/1500\n",
      "7089/7089 [==============================] - 5s 679us/step - loss: 1.6015 - note_output_loss: 0.4639 - length_output_loss: 2.2751 - val_loss: 8.5271 - val_note_output_loss: 6.5774 - val_length_output_loss: 3.8996\n",
      "Epoch 776/1500\n",
      "7089/7089 [==============================] - 5s 691us/step - loss: 1.6055 - note_output_loss: 0.4682 - length_output_loss: 2.2746 - val_loss: 8.5857 - val_note_output_loss: 6.6368 - val_length_output_loss: 3.8978\n",
      "Epoch 777/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 1.5990 - note_output_loss: 0.4604 - length_output_loss: 2.2772 - val_loss: 8.5379 - val_note_output_loss: 6.5898 - val_length_output_loss: 3.8962\n",
      "Epoch 778/1500\n",
      "7089/7089 [==============================] - 5s 712us/step - loss: 1.6062 - note_output_loss: 0.4686 - length_output_loss: 2.2751 - val_loss: 8.5189 - val_note_output_loss: 6.5722 - val_length_output_loss: 3.8933\n",
      "Epoch 779/1500\n",
      "7089/7089 [==============================] - 5s 703us/step - loss: 1.6050 - note_output_loss: 0.4695 - length_output_loss: 2.2709 - val_loss: 8.5731 - val_note_output_loss: 6.6192 - val_length_output_loss: 3.9078\n",
      "Epoch 780/1500\n",
      "7089/7089 [==============================] - 5s 712us/step - loss: 1.5983 - note_output_loss: 0.4662 - length_output_loss: 2.2641 - val_loss: 8.5646 - val_note_output_loss: 6.6139 - val_length_output_loss: 3.9015\n",
      "Epoch 781/1500\n",
      "7089/7089 [==============================] - 6s 798us/step - loss: 1.6101 - note_output_loss: 0.4698 - length_output_loss: 2.2805 - val_loss: 8.5373 - val_note_output_loss: 6.5828 - val_length_output_loss: 3.9089\n",
      "Epoch 782/1500\n",
      "7089/7089 [==============================] - 7s 969us/step - loss: 1.5984 - note_output_loss: 0.4632 - length_output_loss: 2.2704 - val_loss: 8.5817 - val_note_output_loss: 6.6310 - val_length_output_loss: 3.9014\n",
      "Epoch 783/1500\n",
      "7089/7089 [==============================] - 6s 880us/step - loss: 1.6070 - note_output_loss: 0.4695 - length_output_loss: 2.2750 - val_loss: 8.5431 - val_note_output_loss: 6.5899 - val_length_output_loss: 3.9063\n",
      "Epoch 784/1500\n",
      "7089/7089 [==============================] - 6s 877us/step - loss: 1.6190 - note_output_loss: 0.4819 - length_output_loss: 2.2740 - val_loss: 8.5633 - val_note_output_loss: 6.6135 - val_length_output_loss: 3.8996\n",
      "Epoch 785/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 1.6029 - note_output_loss: 0.4684 - length_output_loss: 2.2688 - val_loss: 8.5664 - val_note_output_loss: 6.6178 - val_length_output_loss: 3.8972\n",
      "Epoch 786/1500\n",
      "7089/7089 [==============================] - 5s 768us/step - loss: 1.5874 - note_output_loss: 0.4572 - length_output_loss: 2.2605 - val_loss: 8.5672 - val_note_output_loss: 6.6182 - val_length_output_loss: 3.8981\n",
      "Epoch 787/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 1.5907 - note_output_loss: 0.4552 - length_output_loss: 2.2711 - val_loss: 8.5888 - val_note_output_loss: 6.6412 - val_length_output_loss: 3.8951\n",
      "Epoch 788/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.5868 - note_output_loss: 0.4517 - length_output_loss: 2.2701 - val_loss: 8.5655 - val_note_output_loss: 6.6178 - val_length_output_loss: 3.8954\n",
      "Epoch 789/1500\n",
      "7089/7089 [==============================] - 5s 693us/step - loss: 1.5889 - note_output_loss: 0.4576 - length_output_loss: 2.2626 - val_loss: 8.6176 - val_note_output_loss: 6.6621 - val_length_output_loss: 3.9108\n",
      "Epoch 790/1500\n",
      "7089/7089 [==============================] - 5s 721us/step - loss: 1.6011 - note_output_loss: 0.4610 - length_output_loss: 2.2801 - val_loss: 8.6226 - val_note_output_loss: 6.6711 - val_length_output_loss: 3.9032\n",
      "Epoch 791/1500\n",
      "7089/7089 [==============================] - 5s 687us/step - loss: 1.5979 - note_output_loss: 0.4629 - length_output_loss: 2.2700 - val_loss: 8.5679 - val_note_output_loss: 6.6148 - val_length_output_loss: 3.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1500\n",
      "7089/7089 [==============================] - 5s 699us/step - loss: 1.5962 - note_output_loss: 0.4608 - length_output_loss: 2.2707 - val_loss: 8.5957 - val_note_output_loss: 6.6461 - val_length_output_loss: 3.8992\n",
      "Epoch 793/1500\n",
      "7089/7089 [==============================] - 5s 772us/step - loss: 1.5883 - note_output_loss: 0.4555 - length_output_loss: 2.2655 - val_loss: 8.5924 - val_note_output_loss: 6.6406 - val_length_output_loss: 3.9037\n",
      "Epoch 794/1500\n",
      "7089/7089 [==============================] - 5s 766us/step - loss: 1.5913 - note_output_loss: 0.4572 - length_output_loss: 2.2681 - val_loss: 8.5803 - val_note_output_loss: 6.6297 - val_length_output_loss: 3.9013\n",
      "Epoch 795/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.5977 - note_output_loss: 0.4620 - length_output_loss: 2.2713 - val_loss: 8.5823 - val_note_output_loss: 6.6288 - val_length_output_loss: 3.9070\n",
      "Epoch 796/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 1.5864 - note_output_loss: 0.4500 - length_output_loss: 2.2727 - val_loss: 8.5984 - val_note_output_loss: 6.6473 - val_length_output_loss: 3.9022\n",
      "Epoch 797/1500\n",
      "7089/7089 [==============================] - 5s 733us/step - loss: 1.5964 - note_output_loss: 0.4650 - length_output_loss: 2.2627 - val_loss: 8.6412 - val_note_output_loss: 6.6862 - val_length_output_loss: 3.9099\n",
      "Epoch 798/1500\n",
      "7089/7089 [==============================] - 5s 726us/step - loss: 1.5920 - note_output_loss: 0.4570 - length_output_loss: 2.2700 - val_loss: 8.5858 - val_note_output_loss: 6.6292 - val_length_output_loss: 3.9133\n",
      "Epoch 799/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 1.5851 - note_output_loss: 0.4508 - length_output_loss: 2.2685 - val_loss: 8.6068 - val_note_output_loss: 6.6531 - val_length_output_loss: 3.9075\n",
      "Epoch 800/1500\n",
      "7089/7089 [==============================] - 5s 771us/step - loss: 1.5924 - note_output_loss: 0.4604 - length_output_loss: 2.2640 - val_loss: 8.6295 - val_note_output_loss: 6.6727 - val_length_output_loss: 3.9138\n",
      "Epoch 801/1500\n",
      "7089/7089 [==============================] - 6s 793us/step - loss: 1.5750 - note_output_loss: 0.4477 - length_output_loss: 2.2544 - val_loss: 8.6028 - val_note_output_loss: 6.6474 - val_length_output_loss: 3.9107\n",
      "Epoch 802/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.5903 - note_output_loss: 0.4593 - length_output_loss: 2.2620 - val_loss: 8.6325 - val_note_output_loss: 6.6787 - val_length_output_loss: 3.9077\n",
      "Epoch 803/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 1.5821 - note_output_loss: 0.4479 - length_output_loss: 2.2684 - val_loss: 8.6294 - val_note_output_loss: 6.6752 - val_length_output_loss: 3.9085\n",
      "Epoch 804/1500\n",
      "7089/7089 [==============================] - 5s 734us/step - loss: 1.5745 - note_output_loss: 0.4441 - length_output_loss: 2.2607 - val_loss: 8.6290 - val_note_output_loss: 6.6758 - val_length_output_loss: 3.9064\n",
      "Epoch 805/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.5778 - note_output_loss: 0.4522 - length_output_loss: 2.2511 - val_loss: 8.6194 - val_note_output_loss: 6.6644 - val_length_output_loss: 3.9100\n",
      "Epoch 806/1500\n",
      "7089/7089 [==============================] - 5s 639us/step - loss: 1.5768 - note_output_loss: 0.4475 - length_output_loss: 2.2586 - val_loss: 8.6394 - val_note_output_loss: 6.6827 - val_length_output_loss: 3.9133\n",
      "Epoch 807/1500\n",
      "7089/7089 [==============================] - 5s 689us/step - loss: 1.5814 - note_output_loss: 0.4533 - length_output_loss: 2.2563 - val_loss: 8.6018 - val_note_output_loss: 6.6474 - val_length_output_loss: 3.9089\n",
      "Epoch 808/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 1.5749 - note_output_loss: 0.4456 - length_output_loss: 2.2585 - val_loss: 8.6369 - val_note_output_loss: 6.6733 - val_length_output_loss: 3.9272\n",
      "Epoch 809/1500\n",
      "7089/7089 [==============================] - 5s 673us/step - loss: 1.5839 - note_output_loss: 0.4549 - length_output_loss: 2.2579 - val_loss: 8.6588 - val_note_output_loss: 6.7004 - val_length_output_loss: 3.9167\n",
      "Epoch 810/1500\n",
      "7089/7089 [==============================] - 5s 684us/step - loss: 1.5784 - note_output_loss: 0.4471 - length_output_loss: 2.2626 - val_loss: 8.6315 - val_note_output_loss: 6.6775 - val_length_output_loss: 3.9080\n",
      "Epoch 811/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.5824 - note_output_loss: 0.4513 - length_output_loss: 2.2621 - val_loss: 8.6754 - val_note_output_loss: 6.7144 - val_length_output_loss: 3.9221\n",
      "Epoch 812/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 1.5911 - note_output_loss: 0.4624 - length_output_loss: 2.2575 - val_loss: 8.6457 - val_note_output_loss: 6.6830 - val_length_output_loss: 3.9254\n",
      "Epoch 813/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.5831 - note_output_loss: 0.4516 - length_output_loss: 2.2630 - val_loss: 8.6625 - val_note_output_loss: 6.7021 - val_length_output_loss: 3.9209\n",
      "Epoch 814/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.5858 - note_output_loss: 0.4580 - length_output_loss: 2.2556 - val_loss: 8.6716 - val_note_output_loss: 6.7140 - val_length_output_loss: 3.9151\n",
      "Epoch 815/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.5778 - note_output_loss: 0.4516 - length_output_loss: 2.2525 - val_loss: 8.6709 - val_note_output_loss: 6.7130 - val_length_output_loss: 3.9157\n",
      "Epoch 816/1500\n",
      "7089/7089 [==============================] - 5s 685us/step - loss: 1.5876 - note_output_loss: 0.4554 - length_output_loss: 2.2644 - val_loss: 8.6647 - val_note_output_loss: 6.7038 - val_length_output_loss: 3.9219\n",
      "Epoch 817/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.5674 - note_output_loss: 0.4403 - length_output_loss: 2.2542 - val_loss: 8.6849 - val_note_output_loss: 6.7267 - val_length_output_loss: 3.9165\n",
      "Epoch 818/1500\n",
      "7089/7089 [==============================] - 6s 852us/step - loss: 1.5630 - note_output_loss: 0.4350 - length_output_loss: 2.2560 - val_loss: 8.6516 - val_note_output_loss: 6.6926 - val_length_output_loss: 3.9180\n",
      "Epoch 819/1500\n",
      "7089/7089 [==============================] - 5s 760us/step - loss: 1.5563 - note_output_loss: 0.4322 - length_output_loss: 2.2482 - val_loss: 8.6440 - val_note_output_loss: 6.6843 - val_length_output_loss: 3.9193\n",
      "Epoch 820/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 1.5820 - note_output_loss: 0.4550 - length_output_loss: 2.2541 - val_loss: 8.6607 - val_note_output_loss: 6.6981 - val_length_output_loss: 3.9251\n",
      "Epoch 821/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.5652 - note_output_loss: 0.4385 - length_output_loss: 2.2535 - val_loss: 8.6526 - val_note_output_loss: 6.6914 - val_length_output_loss: 3.9225\n",
      "Epoch 822/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.5718 - note_output_loss: 0.4435 - length_output_loss: 2.2567 - val_loss: 8.6744 - val_note_output_loss: 6.7114 - val_length_output_loss: 3.9260\n",
      "Epoch 823/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.5763 - note_output_loss: 0.4508 - length_output_loss: 2.2510 - val_loss: 8.6524 - val_note_output_loss: 6.6902 - val_length_output_loss: 3.9243\n",
      "Epoch 824/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.5735 - note_output_loss: 0.4464 - length_output_loss: 2.2541 - val_loss: 8.7113 - val_note_output_loss: 6.7481 - val_length_output_loss: 3.9264\n",
      "Epoch 825/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.5720 - note_output_loss: 0.4456 - length_output_loss: 2.2528 - val_loss: 8.6643 - val_note_output_loss: 6.7024 - val_length_output_loss: 3.9238\n",
      "Epoch 826/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.5748 - note_output_loss: 0.4452 - length_output_loss: 2.2594 - val_loss: 8.6960 - val_note_output_loss: 6.7318 - val_length_output_loss: 3.9285\n",
      "Epoch 827/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 1.5564 - note_output_loss: 0.4339 - length_output_loss: 2.2450 - val_loss: 8.6785 - val_note_output_loss: 6.7189 - val_length_output_loss: 3.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.5828 - note_output_loss: 0.4553 - length_output_loss: 2.2551 - val_loss: 8.6650 - val_note_output_loss: 6.7045 - val_length_output_loss: 3.9211\n",
      "Epoch 829/1500\n",
      "7089/7089 [==============================] - 5s 688us/step - loss: 1.5623 - note_output_loss: 0.4402 - length_output_loss: 2.2443 - val_loss: 8.6932 - val_note_output_loss: 6.7239 - val_length_output_loss: 3.9386\n",
      "Epoch 830/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 1.5593 - note_output_loss: 0.4356 - length_output_loss: 2.2474 - val_loss: 8.7077 - val_note_output_loss: 6.7399 - val_length_output_loss: 3.9355\n",
      "Epoch 831/1500\n",
      "7089/7089 [==============================] - 5s 753us/step - loss: 1.5753 - note_output_loss: 0.4489 - length_output_loss: 2.2528 - val_loss: 8.6924 - val_note_output_loss: 6.7269 - val_length_output_loss: 3.9309\n",
      "Epoch 832/1500\n",
      "7089/7089 [==============================] - 5s 692us/step - loss: 1.5638 - note_output_loss: 0.4420 - length_output_loss: 2.2436 - val_loss: 8.6854 - val_note_output_loss: 6.7255 - val_length_output_loss: 3.9198\n",
      "Epoch 833/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.5734 - note_output_loss: 0.4476 - length_output_loss: 2.2516 - val_loss: 8.6836 - val_note_output_loss: 6.7139 - val_length_output_loss: 3.9394\n",
      "Epoch 834/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.5575 - note_output_loss: 0.4355 - length_output_loss: 2.2438 - val_loss: 8.6871 - val_note_output_loss: 6.7210 - val_length_output_loss: 3.9323\n",
      "Epoch 835/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.5710 - note_output_loss: 0.4446 - length_output_loss: 2.2527 - val_loss: 8.7362 - val_note_output_loss: 6.7690 - val_length_output_loss: 3.9346\n",
      "Epoch 836/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 1.5753 - note_output_loss: 0.4500 - length_output_loss: 2.2506 - val_loss: 8.7220 - val_note_output_loss: 6.7511 - val_length_output_loss: 3.9419\n",
      "Epoch 837/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.5504 - note_output_loss: 0.4279 - length_output_loss: 2.2451 - val_loss: 8.6936 - val_note_output_loss: 6.7273 - val_length_output_loss: 3.9326\n",
      "Epoch 838/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.5706 - note_output_loss: 0.4521 - length_output_loss: 2.2370 - val_loss: 8.7161 - val_note_output_loss: 6.7491 - val_length_output_loss: 3.9339\n",
      "Epoch 839/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.5568 - note_output_loss: 0.4363 - length_output_loss: 2.2411 - val_loss: 8.7260 - val_note_output_loss: 6.7524 - val_length_output_loss: 3.9471\n",
      "Epoch 840/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.5626 - note_output_loss: 0.4374 - length_output_loss: 2.2502 - val_loss: 8.6950 - val_note_output_loss: 6.7275 - val_length_output_loss: 3.9351\n",
      "Epoch 841/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 1.5602 - note_output_loss: 0.4364 - length_output_loss: 2.2475 - val_loss: 8.7838 - val_note_output_loss: 6.8170 - val_length_output_loss: 3.9337\n",
      "Epoch 842/1500\n",
      "7089/7089 [==============================] - 5s 676us/step - loss: 1.5554 - note_output_loss: 0.4327 - length_output_loss: 2.2454 - val_loss: 8.7396 - val_note_output_loss: 6.7746 - val_length_output_loss: 3.9301\n",
      "Epoch 843/1500\n",
      "7089/7089 [==============================] - 5s 667us/step - loss: 1.5641 - note_output_loss: 0.4475 - length_output_loss: 2.2332 - val_loss: 8.6966 - val_note_output_loss: 6.7291 - val_length_output_loss: 3.9350\n",
      "Epoch 844/1500\n",
      "7089/7089 [==============================] - 5s 691us/step - loss: 1.5684 - note_output_loss: 0.4480 - length_output_loss: 2.2407 - val_loss: 8.7402 - val_note_output_loss: 6.7692 - val_length_output_loss: 3.9421\n",
      "Epoch 845/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.5453 - note_output_loss: 0.4331 - length_output_loss: 2.2245 - val_loss: 8.7451 - val_note_output_loss: 6.7684 - val_length_output_loss: 3.9535\n",
      "Epoch 846/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.5570 - note_output_loss: 0.4341 - length_output_loss: 2.2459 - val_loss: 8.7521 - val_note_output_loss: 6.7776 - val_length_output_loss: 3.9490\n",
      "Epoch 847/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 1.5356 - note_output_loss: 0.4221 - length_output_loss: 2.2270 - val_loss: 8.7558 - val_note_output_loss: 6.7831 - val_length_output_loss: 3.9455\n",
      "Epoch 848/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 1.5779 - note_output_loss: 0.4556 - length_output_loss: 2.2448 - val_loss: 8.7577 - val_note_output_loss: 6.7869 - val_length_output_loss: 3.9415\n",
      "Epoch 849/1500\n",
      "7089/7089 [==============================] - 5s 684us/step - loss: 1.5524 - note_output_loss: 0.4349 - length_output_loss: 2.2350 - val_loss: 8.7514 - val_note_output_loss: 6.7822 - val_length_output_loss: 3.9385\n",
      "Epoch 850/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.5714 - note_output_loss: 0.4486 - length_output_loss: 2.2455 - val_loss: 8.8013 - val_note_output_loss: 6.8312 - val_length_output_loss: 3.9401\n",
      "Epoch 851/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.5640 - note_output_loss: 0.4440 - length_output_loss: 2.2400 - val_loss: 8.8016 - val_note_output_loss: 6.8220 - val_length_output_loss: 3.9591\n",
      "Epoch 852/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.5549 - note_output_loss: 0.4327 - length_output_loss: 2.2443 - val_loss: 8.7404 - val_note_output_loss: 6.7667 - val_length_output_loss: 3.9474\n",
      "Epoch 853/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.5446 - note_output_loss: 0.4250 - length_output_loss: 2.2392 - val_loss: 8.8066 - val_note_output_loss: 6.8303 - val_length_output_loss: 3.9526\n",
      "Epoch 854/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.5491 - note_output_loss: 0.4279 - length_output_loss: 2.2425 - val_loss: 8.7767 - val_note_output_loss: 6.8034 - val_length_output_loss: 3.9466\n",
      "Epoch 855/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.5562 - note_output_loss: 0.4343 - length_output_loss: 2.2438 - val_loss: 8.7601 - val_note_output_loss: 6.7846 - val_length_output_loss: 3.9510\n",
      "Epoch 856/1500\n",
      "7089/7089 [==============================] - 5s 739us/step - loss: 1.5398 - note_output_loss: 0.4208 - length_output_loss: 2.2379 - val_loss: 8.8154 - val_note_output_loss: 6.8343 - val_length_output_loss: 3.9621\n",
      "Epoch 857/1500\n",
      "7089/7089 [==============================] - 5s 683us/step - loss: 1.5388 - note_output_loss: 0.4196 - length_output_loss: 2.2384 - val_loss: 8.7617 - val_note_output_loss: 6.7859 - val_length_output_loss: 3.9516\n",
      "Epoch 858/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.5585 - note_output_loss: 0.4345 - length_output_loss: 2.2480 - val_loss: 8.7908 - val_note_output_loss: 6.8131 - val_length_output_loss: 3.9555\n",
      "Epoch 859/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.5494 - note_output_loss: 0.4330 - length_output_loss: 2.2327 - val_loss: 8.7531 - val_note_output_loss: 6.7744 - val_length_output_loss: 3.9574\n",
      "Epoch 860/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.5515 - note_output_loss: 0.4325 - length_output_loss: 2.2380 - val_loss: 8.7835 - val_note_output_loss: 6.8046 - val_length_output_loss: 3.9577\n",
      "Epoch 861/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.5443 - note_output_loss: 0.4285 - length_output_loss: 2.2316 - val_loss: 8.7797 - val_note_output_loss: 6.8007 - val_length_output_loss: 3.9579\n",
      "Epoch 862/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.5487 - note_output_loss: 0.4336 - length_output_loss: 2.2303 - val_loss: 8.7566 - val_note_output_loss: 6.7776 - val_length_output_loss: 3.9580\n",
      "Epoch 863/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.5452 - note_output_loss: 0.4331 - length_output_loss: 2.2241 - val_loss: 8.7802 - val_note_output_loss: 6.7998 - val_length_output_loss: 3.9608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 864/1500\n",
      "7089/7089 [==============================] - 5s 639us/step - loss: 1.5538 - note_output_loss: 0.4385 - length_output_loss: 2.2306 - val_loss: 8.7863 - val_note_output_loss: 6.8040 - val_length_output_loss: 3.9647\n",
      "Epoch 865/1500\n",
      "7089/7089 [==============================] - 5s 714us/step - loss: 1.5404 - note_output_loss: 0.4239 - length_output_loss: 2.2330 - val_loss: 8.7926 - val_note_output_loss: 6.8144 - val_length_output_loss: 3.9566\n",
      "Epoch 866/1500\n",
      "7089/7089 [==============================] - 5s 666us/step - loss: 1.5428 - note_output_loss: 0.4305 - length_output_loss: 2.2247 - val_loss: 8.8175 - val_note_output_loss: 6.8352 - val_length_output_loss: 3.9646\n",
      "Epoch 867/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 1.5324 - note_output_loss: 0.4133 - length_output_loss: 2.2382 - val_loss: 8.8050 - val_note_output_loss: 6.8236 - val_length_output_loss: 3.9629\n",
      "Epoch 868/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.5501 - note_output_loss: 0.4340 - length_output_loss: 2.2321 - val_loss: 8.7776 - val_note_output_loss: 6.8004 - val_length_output_loss: 3.9543\n",
      "Epoch 869/1500\n",
      "7089/7089 [==============================] - 5s 718us/step - loss: 1.5379 - note_output_loss: 0.4240 - length_output_loss: 2.2278 - val_loss: 8.8111 - val_note_output_loss: 6.8285 - val_length_output_loss: 3.9653\n",
      "Epoch 870/1500\n",
      "7089/7089 [==============================] - 6s 802us/step - loss: 1.5279 - note_output_loss: 0.4147 - length_output_loss: 2.2265 - val_loss: 8.8061 - val_note_output_loss: 6.8269 - val_length_output_loss: 3.9585\n",
      "Epoch 871/1500\n",
      "7089/7089 [==============================] - 5s 749us/step - loss: 1.5290 - note_output_loss: 0.4151 - length_output_loss: 2.2278 - val_loss: 8.8693 - val_note_output_loss: 6.8914 - val_length_output_loss: 3.9558\n",
      "Epoch 872/1500\n",
      "7089/7089 [==============================] - 5s 736us/step - loss: 1.5359 - note_output_loss: 0.4193 - length_output_loss: 2.2331 - val_loss: 8.8284 - val_note_output_loss: 6.8461 - val_length_output_loss: 3.9646\n",
      "Epoch 873/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.5388 - note_output_loss: 0.4252 - length_output_loss: 2.2272 - val_loss: 8.8401 - val_note_output_loss: 6.8586 - val_length_output_loss: 3.9630\n",
      "Epoch 874/1500\n",
      "7089/7089 [==============================] - 5s 669us/step - loss: 1.5447 - note_output_loss: 0.4272 - length_output_loss: 2.2350 - val_loss: 8.8292 - val_note_output_loss: 6.8465 - val_length_output_loss: 3.9653\n",
      "Epoch 875/1500\n",
      "7089/7089 [==============================] - 5s 720us/step - loss: 1.5355 - note_output_loss: 0.4226 - length_output_loss: 2.2258 - val_loss: 8.8089 - val_note_output_loss: 6.8270 - val_length_output_loss: 3.9638\n",
      "Epoch 876/1500\n",
      "7089/7089 [==============================] - 5s 705us/step - loss: 1.5384 - note_output_loss: 0.4261 - length_output_loss: 2.2246 - val_loss: 8.8533 - val_note_output_loss: 6.8655 - val_length_output_loss: 3.9757\n",
      "Epoch 877/1500\n",
      "7089/7089 [==============================] - 5s 686us/step - loss: 1.5322 - note_output_loss: 0.4240 - length_output_loss: 2.2165 - val_loss: 8.8885 - val_note_output_loss: 6.9042 - val_length_output_loss: 3.9685\n",
      "Epoch 878/1500\n",
      "7089/7089 [==============================] - 5s 742us/step - loss: 1.5576 - note_output_loss: 0.4411 - length_output_loss: 2.2329 - val_loss: 8.8766 - val_note_output_loss: 6.8922 - val_length_output_loss: 3.9690\n",
      "Epoch 879/1500\n",
      "7089/7089 [==============================] - 5s 733us/step - loss: 1.5320 - note_output_loss: 0.4210 - length_output_loss: 2.2220 - val_loss: 8.8347 - val_note_output_loss: 6.8469 - val_length_output_loss: 3.9756\n",
      "Epoch 880/1500\n",
      "7089/7089 [==============================] - 6s 779us/step - loss: 1.5383 - note_output_loss: 0.4260 - length_output_loss: 2.2247 - val_loss: 8.8791 - val_note_output_loss: 6.8950 - val_length_output_loss: 3.9682\n",
      "Epoch 881/1500\n",
      "7089/7089 [==============================] - 5s 769us/step - loss: 1.5352 - note_output_loss: 0.4229 - length_output_loss: 2.2245 - val_loss: 8.8424 - val_note_output_loss: 6.8606 - val_length_output_loss: 3.9635\n",
      "Epoch 882/1500\n",
      "7089/7089 [==============================] - 6s 800us/step - loss: 1.5222 - note_output_loss: 0.4175 - length_output_loss: 2.2095 - val_loss: 8.8598 - val_note_output_loss: 6.8741 - val_length_output_loss: 3.9714\n",
      "Epoch 883/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.5365 - note_output_loss: 0.4228 - length_output_loss: 2.2273 - val_loss: 8.8730 - val_note_output_loss: 6.8888 - val_length_output_loss: 3.9684\n",
      "Epoch 884/1500\n",
      "7089/7089 [==============================] - 5s 735us/step - loss: 1.5311 - note_output_loss: 0.4212 - length_output_loss: 2.2199 - val_loss: 8.8987 - val_note_output_loss: 6.9115 - val_length_output_loss: 3.9744\n",
      "Epoch 885/1500\n",
      "7089/7089 [==============================] - 5s 738us/step - loss: 1.5174 - note_output_loss: 0.4081 - length_output_loss: 2.2185 - val_loss: 8.8922 - val_note_output_loss: 6.9054 - val_length_output_loss: 3.9736\n",
      "Epoch 886/1500\n",
      "7089/7089 [==============================] - 5s 758us/step - loss: 1.5392 - note_output_loss: 0.4282 - length_output_loss: 2.2219 - val_loss: 8.8512 - val_note_output_loss: 6.8648 - val_length_output_loss: 3.9727\n",
      "Epoch 887/1500\n",
      "7089/7089 [==============================] - 5s 737us/step - loss: 1.5339 - note_output_loss: 0.4238 - length_output_loss: 2.2203 - val_loss: 8.8440 - val_note_output_loss: 6.8576 - val_length_output_loss: 3.9728\n",
      "Epoch 888/1500\n",
      "7089/7089 [==============================] - 5s 696us/step - loss: 1.5293 - note_output_loss: 0.4209 - length_output_loss: 2.2167 - val_loss: 8.8776 - val_note_output_loss: 6.8869 - val_length_output_loss: 3.9816\n",
      "Epoch 889/1500\n",
      "7089/7089 [==============================] - 6s 803us/step - loss: 1.5314 - note_output_loss: 0.4213 - length_output_loss: 2.2200 - val_loss: 8.8826 - val_note_output_loss: 6.8911 - val_length_output_loss: 3.9830\n",
      "Epoch 890/1500\n",
      "7089/7089 [==============================] - 6s 780us/step - loss: 1.5320 - note_output_loss: 0.4236 - length_output_loss: 2.2167 - val_loss: 8.8481 - val_note_output_loss: 6.8577 - val_length_output_loss: 3.9808\n",
      "Epoch 891/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.5361 - note_output_loss: 0.4268 - length_output_loss: 2.2187 - val_loss: 8.8583 - val_note_output_loss: 6.8730 - val_length_output_loss: 3.9708\n",
      "Epoch 892/1500\n",
      "7089/7089 [==============================] - 6s 781us/step - loss: 1.5326 - note_output_loss: 0.4197 - length_output_loss: 2.2258 - val_loss: 8.8894 - val_note_output_loss: 6.8998 - val_length_output_loss: 3.9792\n",
      "Epoch 893/1500\n",
      "7089/7089 [==============================] - 5s 765us/step - loss: 1.5340 - note_output_loss: 0.4218 - length_output_loss: 2.2245 - val_loss: 8.9144 - val_note_output_loss: 6.9306 - val_length_output_loss: 3.9677\n",
      "Epoch 894/1500\n",
      "7089/7089 [==============================] - 6s 810us/step - loss: 1.5245 - note_output_loss: 0.4187 - length_output_loss: 2.2115 - val_loss: 8.8691 - val_note_output_loss: 6.8827 - val_length_output_loss: 3.9727\n",
      "Epoch 895/1500\n",
      "7089/7089 [==============================] - 5s 732us/step - loss: 1.5301 - note_output_loss: 0.4250 - length_output_loss: 2.2102 - val_loss: 8.8635 - val_note_output_loss: 6.8745 - val_length_output_loss: 3.9781\n",
      "Epoch 896/1500\n",
      "7089/7089 [==============================] - 5s 746us/step - loss: 1.5088 - note_output_loss: 0.4053 - length_output_loss: 2.2070 - val_loss: 8.8832 - val_note_output_loss: 6.8924 - val_length_output_loss: 3.9816\n",
      "Epoch 897/1500\n",
      "7089/7089 [==============================] - 5s 775us/step - loss: 1.5207 - note_output_loss: 0.4121 - length_output_loss: 2.2171 - val_loss: 8.8820 - val_note_output_loss: 6.8922 - val_length_output_loss: 3.9798\n",
      "Epoch 898/1500\n",
      "7089/7089 [==============================] - 5s 753us/step - loss: 1.5232 - note_output_loss: 0.4211 - length_output_loss: 2.2041 - val_loss: 8.9255 - val_note_output_loss: 6.9355 - val_length_output_loss: 3.9801\n",
      "Epoch 899/1500\n",
      "7089/7089 [==============================] - 5s 768us/step - loss: 1.5239 - note_output_loss: 0.4216 - length_output_loss: 2.2047 - val_loss: 8.9045 - val_note_output_loss: 6.9098 - val_length_output_loss: 3.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1500\n",
      "7089/7089 [==============================] - 5s 719us/step - loss: 1.5213 - note_output_loss: 0.4121 - length_output_loss: 2.2186 - val_loss: 8.8943 - val_note_output_loss: 6.9041 - val_length_output_loss: 3.9804\n",
      "Epoch 901/1500\n",
      "7089/7089 [==============================] - 5s 730us/step - loss: 1.5231 - note_output_loss: 0.4184 - length_output_loss: 2.2093 - val_loss: 8.9120 - val_note_output_loss: 6.9209 - val_length_output_loss: 3.9823\n",
      "Epoch 902/1500\n",
      "7089/7089 [==============================] - 5s 751us/step - loss: 1.5190 - note_output_loss: 0.4144 - length_output_loss: 2.2092 - val_loss: 8.9432 - val_note_output_loss: 6.9507 - val_length_output_loss: 3.9850\n",
      "Epoch 903/1500\n",
      "7089/7089 [==============================] - 5s 762us/step - loss: 1.5248 - note_output_loss: 0.4140 - length_output_loss: 2.2217 - val_loss: 8.9177 - val_note_output_loss: 6.9235 - val_length_output_loss: 3.9884\n",
      "Epoch 904/1500\n",
      "7089/7089 [==============================] - 6s 792us/step - loss: 1.5322 - note_output_loss: 0.4201 - length_output_loss: 2.2243 - val_loss: 8.9120 - val_note_output_loss: 6.9186 - val_length_output_loss: 3.9868\n",
      "Epoch 905/1500\n",
      "7089/7089 [==============================] - 6s 783us/step - loss: 1.5285 - note_output_loss: 0.4185 - length_output_loss: 2.2201 - val_loss: 8.8833 - val_note_output_loss: 6.8926 - val_length_output_loss: 3.9813\n",
      "Epoch 906/1500\n",
      "7089/7089 [==============================] - 5s 725us/step - loss: 1.5257 - note_output_loss: 0.4186 - length_output_loss: 2.2140 - val_loss: 8.9231 - val_note_output_loss: 6.9273 - val_length_output_loss: 3.9916\n",
      "Epoch 907/1500\n",
      "7089/7089 [==============================] - 5s 695us/step - loss: 1.5201 - note_output_loss: 0.4132 - length_output_loss: 2.2139 - val_loss: 8.9217 - val_note_output_loss: 6.9255 - val_length_output_loss: 3.9924\n",
      "Epoch 908/1500\n",
      "7089/7089 [==============================] - 5s 762us/step - loss: 1.4966 - note_output_loss: 0.3949 - length_output_loss: 2.2033 - val_loss: 8.8912 - val_note_output_loss: 6.9022 - val_length_output_loss: 3.9779\n",
      "Epoch 909/1500\n",
      "7089/7089 [==============================] - 5s 773us/step - loss: 1.5136 - note_output_loss: 0.4057 - length_output_loss: 2.2157 - val_loss: 8.9070 - val_note_output_loss: 6.9134 - val_length_output_loss: 3.9873\n",
      "Epoch 910/1500\n",
      "7089/7089 [==============================] - 5s 733us/step - loss: 1.5075 - note_output_loss: 0.4024 - length_output_loss: 2.2102 - val_loss: 8.9014 - val_note_output_loss: 6.9076 - val_length_output_loss: 3.9876\n",
      "Epoch 911/1500\n",
      "7089/7089 [==============================] - 5s 749us/step - loss: 1.5091 - note_output_loss: 0.4014 - length_output_loss: 2.2155 - val_loss: 8.9230 - val_note_output_loss: 6.9299 - val_length_output_loss: 3.9862\n",
      "Epoch 912/1500\n",
      "7089/7089 [==============================] - 5s 723us/step - loss: 1.5109 - note_output_loss: 0.4059 - length_output_loss: 2.2101 - val_loss: 8.9245 - val_note_output_loss: 6.9284 - val_length_output_loss: 3.9922\n",
      "Epoch 913/1500\n",
      "7089/7089 [==============================] - 5s 714us/step - loss: 1.5176 - note_output_loss: 0.4144 - length_output_loss: 2.2063 - val_loss: 8.9499 - val_note_output_loss: 6.9519 - val_length_output_loss: 3.9960\n",
      "Epoch 914/1500\n",
      "7089/7089 [==============================] - 5s 735us/step - loss: 1.5013 - note_output_loss: 0.3976 - length_output_loss: 2.2074 - val_loss: 8.9401 - val_note_output_loss: 6.9507 - val_length_output_loss: 3.9788\n",
      "Epoch 915/1500\n",
      "7089/7089 [==============================] - 5s 730us/step - loss: 1.5013 - note_output_loss: 0.4002 - length_output_loss: 2.2021 - val_loss: 8.9702 - val_note_output_loss: 6.9755 - val_length_output_loss: 3.9893\n",
      "Epoch 916/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 1.5131 - note_output_loss: 0.4111 - length_output_loss: 2.2041 - val_loss: 8.9357 - val_note_output_loss: 6.9412 - val_length_output_loss: 3.9890\n",
      "Epoch 917/1500\n",
      "7089/7089 [==============================] - 5s 721us/step - loss: 1.4969 - note_output_loss: 0.3984 - length_output_loss: 2.1970 - val_loss: 8.9461 - val_note_output_loss: 6.9536 - val_length_output_loss: 3.9850\n",
      "Epoch 918/1500\n",
      "7089/7089 [==============================] - 5s 679us/step - loss: 1.5060 - note_output_loss: 0.4079 - length_output_loss: 2.1963 - val_loss: 8.9716 - val_note_output_loss: 6.9724 - val_length_output_loss: 3.9985\n",
      "Epoch 919/1500\n",
      "7089/7089 [==============================] - 5s 759us/step - loss: 1.5145 - note_output_loss: 0.4135 - length_output_loss: 2.2021 - val_loss: 8.9170 - val_note_output_loss: 6.9178 - val_length_output_loss: 3.9983\n",
      "Epoch 920/1500\n",
      "7089/7089 [==============================] - 6s 788us/step - loss: 1.5052 - note_output_loss: 0.4037 - length_output_loss: 2.2030 - val_loss: 8.9470 - val_note_output_loss: 6.9501 - val_length_output_loss: 3.9939\n",
      "Epoch 921/1500\n",
      "7089/7089 [==============================] - 5s 695us/step - loss: 1.5151 - note_output_loss: 0.4162 - length_output_loss: 2.1980 - val_loss: 8.9745 - val_note_output_loss: 6.9743 - val_length_output_loss: 4.0004\n",
      "Epoch 922/1500\n",
      "7089/7089 [==============================] - 5s 687us/step - loss: 1.5131 - note_output_loss: 0.4092 - length_output_loss: 2.2077 - val_loss: 8.9212 - val_note_output_loss: 6.9182 - val_length_output_loss: 4.0060\n",
      "Epoch 923/1500\n",
      "7089/7089 [==============================] - 6s 790us/step - loss: 1.5049 - note_output_loss: 0.4064 - length_output_loss: 2.1970 - val_loss: 8.9882 - val_note_output_loss: 6.9856 - val_length_output_loss: 4.0051\n",
      "Epoch 924/1500\n",
      "7089/7089 [==============================] - 6s 790us/step - loss: 1.5008 - note_output_loss: 0.3992 - length_output_loss: 2.2033 - val_loss: 9.0155 - val_note_output_loss: 7.0086 - val_length_output_loss: 4.0138\n",
      "Epoch 925/1500\n",
      "7089/7089 [==============================] - 6s 798us/step - loss: 1.5006 - note_output_loss: 0.3939 - length_output_loss: 2.2134 - val_loss: 8.9570 - val_note_output_loss: 6.9544 - val_length_output_loss: 4.0052\n",
      "Epoch 926/1500\n",
      "7089/7089 [==============================] - 5s 767us/step - loss: 1.5056 - note_output_loss: 0.4059 - length_output_loss: 2.1994 - val_loss: 8.9551 - val_note_output_loss: 6.9513 - val_length_output_loss: 4.0076\n",
      "Epoch 927/1500\n",
      "7089/7089 [==============================] - 5s 715us/step - loss: 1.5053 - note_output_loss: 0.4048 - length_output_loss: 2.2011 - val_loss: 8.9450 - val_note_output_loss: 6.9441 - val_length_output_loss: 4.0018\n",
      "Epoch 928/1500\n",
      "7089/7089 [==============================] - 5s 726us/step - loss: 1.4976 - note_output_loss: 0.3959 - length_output_loss: 2.2033 - val_loss: 8.9811 - val_note_output_loss: 6.9759 - val_length_output_loss: 4.0104\n",
      "Epoch 929/1500\n",
      "7089/7089 [==============================] - 5s 687us/step - loss: 1.5080 - note_output_loss: 0.4084 - length_output_loss: 2.1992 - val_loss: 8.9852 - val_note_output_loss: 6.9812 - val_length_output_loss: 4.0078\n",
      "Epoch 930/1500\n",
      "7089/7089 [==============================] - 5s 685us/step - loss: 1.5072 - note_output_loss: 0.4055 - length_output_loss: 2.2035 - val_loss: 8.9804 - val_note_output_loss: 6.9772 - val_length_output_loss: 4.0064\n",
      "Epoch 931/1500\n",
      "7089/7089 [==============================] - 5s 710us/step - loss: 1.5033 - note_output_loss: 0.4063 - length_output_loss: 2.1941 - val_loss: 8.9614 - val_note_output_loss: 6.9599 - val_length_output_loss: 4.0029\n",
      "Epoch 932/1500\n",
      "7089/7089 [==============================] - 5s 690us/step - loss: 1.5006 - note_output_loss: 0.3961 - length_output_loss: 2.2089 - val_loss: 8.9677 - val_note_output_loss: 6.9664 - val_length_output_loss: 4.0027\n",
      "Epoch 933/1500\n",
      "7089/7089 [==============================] - 5s 772us/step - loss: 1.5060 - note_output_loss: 0.4067 - length_output_loss: 2.1988 - val_loss: 8.9995 - val_note_output_loss: 6.9997 - val_length_output_loss: 3.9997\n",
      "Epoch 934/1500\n",
      "7089/7089 [==============================] - 5s 703us/step - loss: 1.4868 - note_output_loss: 0.3903 - length_output_loss: 2.1931 - val_loss: 8.9850 - val_note_output_loss: 6.9807 - val_length_output_loss: 4.0087\n",
      "Epoch 935/1500\n",
      "7089/7089 [==============================] - 5s 702us/step - loss: 1.5022 - note_output_loss: 0.4003 - length_output_loss: 2.2038 - val_loss: 8.9886 - val_note_output_loss: 6.9796 - val_length_output_loss: 4.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/1500\n",
      "7089/7089 [==============================] - 5s 736us/step - loss: 1.4986 - note_output_loss: 0.4008 - length_output_loss: 2.1957 - val_loss: 9.0247 - val_note_output_loss: 7.0169 - val_length_output_loss: 4.0155\n",
      "Epoch 937/1500\n",
      "7089/7089 [==============================] - 5s 749us/step - loss: 1.4957 - note_output_loss: 0.4003 - length_output_loss: 2.1908 - val_loss: 9.0144 - val_note_output_loss: 7.0123 - val_length_output_loss: 4.0041\n",
      "Epoch 938/1500\n",
      "7089/7089 [==============================] - 5s 703us/step - loss: 1.5010 - note_output_loss: 0.4041 - length_output_loss: 2.1938 - val_loss: 9.0233 - val_note_output_loss: 7.0188 - val_length_output_loss: 4.0089\n",
      "Epoch 939/1500\n",
      "7089/7089 [==============================] - 5s 745us/step - loss: 1.4961 - note_output_loss: 0.3962 - length_output_loss: 2.1998 - val_loss: 9.0693 - val_note_output_loss: 7.0552 - val_length_output_loss: 4.0282\n",
      "Epoch 940/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.5021 - note_output_loss: 0.4066 - length_output_loss: 2.1909 - val_loss: 9.0032 - val_note_output_loss: 6.9973 - val_length_output_loss: 4.0120\n",
      "Epoch 941/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.5042 - note_output_loss: 0.4060 - length_output_loss: 2.1964 - val_loss: 9.0145 - val_note_output_loss: 7.0067 - val_length_output_loss: 4.0156\n",
      "Epoch 942/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.5167 - note_output_loss: 0.4223 - length_output_loss: 2.1889 - val_loss: 8.9952 - val_note_output_loss: 6.9916 - val_length_output_loss: 4.0072\n",
      "Epoch 943/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 1.4903 - note_output_loss: 0.3944 - length_output_loss: 2.1916 - val_loss: 8.9851 - val_note_output_loss: 6.9778 - val_length_output_loss: 4.0147\n",
      "Epoch 944/1500\n",
      "7089/7089 [==============================] - 5s 704us/step - loss: 1.4862 - note_output_loss: 0.3918 - length_output_loss: 2.1888 - val_loss: 8.9833 - val_note_output_loss: 6.9758 - val_length_output_loss: 4.0149\n",
      "Epoch 945/1500\n",
      "7089/7089 [==============================] - 5s 733us/step - loss: 1.4923 - note_output_loss: 0.3942 - length_output_loss: 2.1962 - val_loss: 9.0229 - val_note_output_loss: 7.0114 - val_length_output_loss: 4.0228\n",
      "Epoch 946/1500\n",
      "7089/7089 [==============================] - 5s 739us/step - loss: 1.5013 - note_output_loss: 0.4012 - length_output_loss: 2.2003 - val_loss: 8.9996 - val_note_output_loss: 6.9970 - val_length_output_loss: 4.0053\n",
      "Epoch 947/1500\n",
      "7089/7089 [==============================] - 5s 738us/step - loss: 1.4869 - note_output_loss: 0.3870 - length_output_loss: 2.1997 - val_loss: 8.9613 - val_note_output_loss: 6.9598 - val_length_output_loss: 4.0031\n",
      "Epoch 948/1500\n",
      "7089/7089 [==============================] - 6s 778us/step - loss: 1.4936 - note_output_loss: 0.3942 - length_output_loss: 2.1987 - val_loss: 9.0220 - val_note_output_loss: 7.0128 - val_length_output_loss: 4.0185\n",
      "Epoch 949/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 1.4847 - note_output_loss: 0.3882 - length_output_loss: 2.1931 - val_loss: 9.0005 - val_note_output_loss: 6.9908 - val_length_output_loss: 4.0194\n",
      "Epoch 950/1500\n",
      "7089/7089 [==============================] - 5s 773us/step - loss: 1.4906 - note_output_loss: 0.3968 - length_output_loss: 2.1875 - val_loss: 9.0442 - val_note_output_loss: 7.0423 - val_length_output_loss: 4.0039\n",
      "Epoch 951/1500\n",
      "7089/7089 [==============================] - 5s 752us/step - loss: 1.4841 - note_output_loss: 0.3892 - length_output_loss: 2.1898 - val_loss: 9.0068 - val_note_output_loss: 6.9960 - val_length_output_loss: 4.0216\n",
      "Epoch 952/1500\n",
      "7089/7089 [==============================] - 5s 683us/step - loss: 1.4737 - note_output_loss: 0.3771 - length_output_loss: 2.1932 - val_loss: 9.0284 - val_note_output_loss: 7.0189 - val_length_output_loss: 4.0189\n",
      "Epoch 953/1500\n",
      "7089/7089 [==============================] - 5s 697us/step - loss: 1.4832 - note_output_loss: 0.3898 - length_output_loss: 2.1868 - val_loss: 9.0508 - val_note_output_loss: 7.0408 - val_length_output_loss: 4.0200\n",
      "Epoch 954/1500\n",
      "7089/7089 [==============================] - 5s 708us/step - loss: 1.4803 - note_output_loss: 0.3881 - length_output_loss: 2.1844 - val_loss: 9.0843 - val_note_output_loss: 7.0717 - val_length_output_loss: 4.0252\n",
      "Epoch 955/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.4920 - note_output_loss: 0.3988 - length_output_loss: 2.1865 - val_loss: 9.0617 - val_note_output_loss: 7.0464 - val_length_output_loss: 4.0307\n",
      "Epoch 956/1500\n",
      "7089/7089 [==============================] - 5s 671us/step - loss: 1.4905 - note_output_loss: 0.3958 - length_output_loss: 2.1894 - val_loss: 9.0385 - val_note_output_loss: 7.0309 - val_length_output_loss: 4.0153\n",
      "Epoch 957/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.4853 - note_output_loss: 0.3919 - length_output_loss: 2.1868 - val_loss: 9.0197 - val_note_output_loss: 7.0084 - val_length_output_loss: 4.0227\n",
      "Epoch 958/1500\n",
      "7089/7089 [==============================] - 5s 679us/step - loss: 1.4876 - note_output_loss: 0.3926 - length_output_loss: 2.1899 - val_loss: 9.0617 - val_note_output_loss: 7.0445 - val_length_output_loss: 4.0344\n",
      "Epoch 959/1500\n",
      "7089/7089 [==============================] - 5s 678us/step - loss: 1.4892 - note_output_loss: 0.3935 - length_output_loss: 2.1915 - val_loss: 9.0673 - val_note_output_loss: 7.0559 - val_length_output_loss: 4.0227\n",
      "Epoch 960/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 1.4738 - note_output_loss: 0.3789 - length_output_loss: 2.1899 - val_loss: 9.0259 - val_note_output_loss: 7.0116 - val_length_output_loss: 4.0286\n",
      "Epoch 961/1500\n",
      "7089/7089 [==============================] - 5s 672us/step - loss: 1.4715 - note_output_loss: 0.3824 - length_output_loss: 2.1782 - val_loss: 9.0702 - val_note_output_loss: 7.0565 - val_length_output_loss: 4.0274\n",
      "Epoch 962/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 1.4816 - note_output_loss: 0.3850 - length_output_loss: 2.1933 - val_loss: 9.0647 - val_note_output_loss: 7.0509 - val_length_output_loss: 4.0277\n",
      "Epoch 963/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.4812 - note_output_loss: 0.3909 - length_output_loss: 2.1805 - val_loss: 9.0624 - val_note_output_loss: 7.0492 - val_length_output_loss: 4.0264\n",
      "Epoch 964/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.4765 - note_output_loss: 0.3811 - length_output_loss: 2.1907 - val_loss: 9.0620 - val_note_output_loss: 7.0517 - val_length_output_loss: 4.0206\n",
      "Epoch 965/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 1.4932 - note_output_loss: 0.3999 - length_output_loss: 2.1866 - val_loss: 9.0696 - val_note_output_loss: 7.0556 - val_length_output_loss: 4.0280\n",
      "Epoch 966/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.4722 - note_output_loss: 0.3850 - length_output_loss: 2.1745 - val_loss: 9.0518 - val_note_output_loss: 7.0377 - val_length_output_loss: 4.0281\n",
      "Epoch 967/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 1.4779 - note_output_loss: 0.3859 - length_output_loss: 2.1839 - val_loss: 9.0524 - val_note_output_loss: 7.0438 - val_length_output_loss: 4.0171\n",
      "Epoch 968/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.4780 - note_output_loss: 0.3924 - length_output_loss: 2.1712 - val_loss: 9.0707 - val_note_output_loss: 7.0582 - val_length_output_loss: 4.0250\n",
      "Epoch 969/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.4818 - note_output_loss: 0.3929 - length_output_loss: 2.1779 - val_loss: 9.1054 - val_note_output_loss: 7.0906 - val_length_output_loss: 4.0296\n",
      "Epoch 970/1500\n",
      "7089/7089 [==============================] - 5s 663us/step - loss: 1.4787 - note_output_loss: 0.3853 - length_output_loss: 2.1869 - val_loss: 9.0414 - val_note_output_loss: 7.0210 - val_length_output_loss: 4.0408\n",
      "Epoch 971/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.4860 - note_output_loss: 0.3928 - length_output_loss: 2.1863 - val_loss: 9.1066 - val_note_output_loss: 7.0937 - val_length_output_loss: 4.0257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 1.4849 - note_output_loss: 0.3908 - length_output_loss: 2.1882 - val_loss: 9.0909 - val_note_output_loss: 7.0742 - val_length_output_loss: 4.0334\n",
      "Epoch 973/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.4641 - note_output_loss: 0.3752 - length_output_loss: 2.1779 - val_loss: 9.0611 - val_note_output_loss: 7.0457 - val_length_output_loss: 4.0309\n",
      "Epoch 974/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.4860 - note_output_loss: 0.3960 - length_output_loss: 2.1800 - val_loss: 9.0762 - val_note_output_loss: 7.0670 - val_length_output_loss: 4.0185\n",
      "Epoch 975/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.4728 - note_output_loss: 0.3824 - length_output_loss: 2.1807 - val_loss: 9.1251 - val_note_output_loss: 7.1064 - val_length_output_loss: 4.0373\n",
      "Epoch 976/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.4809 - note_output_loss: 0.3879 - length_output_loss: 2.1861 - val_loss: 9.0813 - val_note_output_loss: 7.0677 - val_length_output_loss: 4.0273\n",
      "Epoch 977/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.4715 - note_output_loss: 0.3812 - length_output_loss: 2.1805 - val_loss: 9.1122 - val_note_output_loss: 7.0935 - val_length_output_loss: 4.0374\n",
      "Epoch 978/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 1.4739 - note_output_loss: 0.3838 - length_output_loss: 2.1801 - val_loss: 9.1380 - val_note_output_loss: 7.1192 - val_length_output_loss: 4.0375\n",
      "Epoch 979/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.4876 - note_output_loss: 0.3983 - length_output_loss: 2.1787 - val_loss: 9.1064 - val_note_output_loss: 7.0929 - val_length_output_loss: 4.0271\n",
      "Epoch 980/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.4806 - note_output_loss: 0.3890 - length_output_loss: 2.1832 - val_loss: 9.1162 - val_note_output_loss: 7.1000 - val_length_output_loss: 4.0324\n",
      "Epoch 981/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.4807 - note_output_loss: 0.3876 - length_output_loss: 2.1861 - val_loss: 9.1179 - val_note_output_loss: 7.0985 - val_length_output_loss: 4.0388\n",
      "Epoch 982/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.4593 - note_output_loss: 0.3770 - length_output_loss: 2.1646 - val_loss: 9.1097 - val_note_output_loss: 7.0932 - val_length_output_loss: 4.0330\n",
      "Epoch 983/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.4646 - note_output_loss: 0.3738 - length_output_loss: 2.1815 - val_loss: 9.1405 - val_note_output_loss: 7.1172 - val_length_output_loss: 4.0467\n",
      "Epoch 984/1500\n",
      "7089/7089 [==============================] - 5s 647us/step - loss: 1.4675 - note_output_loss: 0.3782 - length_output_loss: 2.1785 - val_loss: 9.1107 - val_note_output_loss: 7.0909 - val_length_output_loss: 4.0395\n",
      "Epoch 985/1500\n",
      "7089/7089 [==============================] - 5s 662us/step - loss: 1.4702 - note_output_loss: 0.3810 - length_output_loss: 2.1785 - val_loss: 9.1152 - val_note_output_loss: 7.0914 - val_length_output_loss: 4.0476\n",
      "Epoch 986/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.4709 - note_output_loss: 0.3826 - length_output_loss: 2.1766 - val_loss: 9.1003 - val_note_output_loss: 7.0826 - val_length_output_loss: 4.0353\n",
      "Epoch 987/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.4723 - note_output_loss: 0.3861 - length_output_loss: 2.1724 - val_loss: 9.1218 - val_note_output_loss: 7.0996 - val_length_output_loss: 4.0444\n",
      "Epoch 988/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.4673 - note_output_loss: 0.3805 - length_output_loss: 2.1735 - val_loss: 9.1543 - val_note_output_loss: 7.1263 - val_length_output_loss: 4.0561\n",
      "Epoch 989/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.4662 - note_output_loss: 0.3818 - length_output_loss: 2.1690 - val_loss: 9.1483 - val_note_output_loss: 7.1244 - val_length_output_loss: 4.0478\n",
      "Epoch 990/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.4636 - note_output_loss: 0.3753 - length_output_loss: 2.1764 - val_loss: 9.0862 - val_note_output_loss: 7.0672 - val_length_output_loss: 4.0381\n",
      "Epoch 991/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.4555 - note_output_loss: 0.3739 - length_output_loss: 2.1632 - val_loss: 9.1154 - val_note_output_loss: 7.0943 - val_length_output_loss: 4.0423\n",
      "Epoch 992/1500\n",
      "7089/7089 [==============================] - 5s 660us/step - loss: 1.4679 - note_output_loss: 0.3772 - length_output_loss: 2.1814 - val_loss: 9.1659 - val_note_output_loss: 7.1369 - val_length_output_loss: 4.0582\n",
      "Epoch 993/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 1.4630 - note_output_loss: 0.3772 - length_output_loss: 2.1715 - val_loss: 9.1395 - val_note_output_loss: 7.1146 - val_length_output_loss: 4.0498\n",
      "Epoch 994/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.4622 - note_output_loss: 0.3766 - length_output_loss: 2.1711 - val_loss: 9.1547 - val_note_output_loss: 7.1284 - val_length_output_loss: 4.0526\n",
      "Epoch 995/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.4654 - note_output_loss: 0.3818 - length_output_loss: 2.1673 - val_loss: 9.0934 - val_note_output_loss: 7.0752 - val_length_output_loss: 4.0364\n",
      "Epoch 996/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.4664 - note_output_loss: 0.3798 - length_output_loss: 2.1732 - val_loss: 9.1540 - val_note_output_loss: 7.1308 - val_length_output_loss: 4.0463\n",
      "Epoch 997/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.4604 - note_output_loss: 0.3751 - length_output_loss: 2.1707 - val_loss: 9.1251 - val_note_output_loss: 7.0988 - val_length_output_loss: 4.0527\n",
      "Epoch 998/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 1.4690 - note_output_loss: 0.3795 - length_output_loss: 2.1788 - val_loss: 9.1645 - val_note_output_loss: 7.1383 - val_length_output_loss: 4.0525\n",
      "Epoch 999/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.4534 - note_output_loss: 0.3751 - length_output_loss: 2.1566 - val_loss: 9.1456 - val_note_output_loss: 7.1215 - val_length_output_loss: 4.0483\n",
      "Epoch 1000/1500\n",
      "7089/7089 [==============================] - 5s 657us/step - loss: 1.4635 - note_output_loss: 0.3778 - length_output_loss: 2.1714 - val_loss: 9.1316 - val_note_output_loss: 7.1072 - val_length_output_loss: 4.0487\n",
      "Epoch 1001/1500\n",
      "7089/7089 [==============================] - 5s 642us/step - loss: 1.4592 - note_output_loss: 0.3736 - length_output_loss: 2.1712 - val_loss: 9.1566 - val_note_output_loss: 7.1359 - val_length_output_loss: 4.0413\n",
      "Epoch 1002/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.4597 - note_output_loss: 0.3755 - length_output_loss: 2.1683 - val_loss: 9.1658 - val_note_output_loss: 7.1437 - val_length_output_loss: 4.0442\n",
      "Epoch 1003/1500\n",
      "7089/7089 [==============================] - 5s 645us/step - loss: 1.4669 - note_output_loss: 0.3857 - length_output_loss: 2.1624 - val_loss: 9.1836 - val_note_output_loss: 7.1576 - val_length_output_loss: 4.0521\n",
      "Epoch 1004/1500\n",
      "7089/7089 [==============================] - 5s 659us/step - loss: 1.4601 - note_output_loss: 0.3770 - length_output_loss: 2.1660 - val_loss: 9.1849 - val_note_output_loss: 7.1618 - val_length_output_loss: 4.0461\n",
      "Epoch 1005/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.4572 - note_output_loss: 0.3755 - length_output_loss: 2.1634 - val_loss: 9.1940 - val_note_output_loss: 7.1590 - val_length_output_loss: 4.0699\n",
      "Epoch 1006/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 1.4598 - note_output_loss: 0.3770 - length_output_loss: 2.1656 - val_loss: 9.1617 - val_note_output_loss: 7.1351 - val_length_output_loss: 4.0533\n",
      "Epoch 1007/1500\n",
      "7089/7089 [==============================] - 5s 650us/step - loss: 1.4600 - note_output_loss: 0.3805 - length_output_loss: 2.1590 - val_loss: 9.2033 - val_note_output_loss: 7.1728 - val_length_output_loss: 4.0610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1008/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.4638 - note_output_loss: 0.3774 - length_output_loss: 2.1727 - val_loss: 9.1623 - val_note_output_loss: 7.1313 - val_length_output_loss: 4.0619\n",
      "Epoch 1009/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 1.4573 - note_output_loss: 0.3745 - length_output_loss: 2.1657 - val_loss: 9.1935 - val_note_output_loss: 7.1655 - val_length_output_loss: 4.0559\n",
      "Epoch 1010/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.4533 - note_output_loss: 0.3745 - length_output_loss: 2.1575 - val_loss: 9.2127 - val_note_output_loss: 7.1824 - val_length_output_loss: 4.0605\n",
      "Epoch 1011/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.4557 - note_output_loss: 0.3751 - length_output_loss: 2.1610 - val_loss: 9.1567 - val_note_output_loss: 7.1302 - val_length_output_loss: 4.0531\n",
      "Epoch 1012/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.4621 - note_output_loss: 0.3798 - length_output_loss: 2.1646 - val_loss: 9.1490 - val_note_output_loss: 7.1269 - val_length_output_loss: 4.0443\n",
      "Epoch 1013/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.4573 - note_output_loss: 0.3767 - length_output_loss: 2.1612 - val_loss: 9.1603 - val_note_output_loss: 7.1376 - val_length_output_loss: 4.0455\n",
      "Epoch 1014/1500\n",
      "7089/7089 [==============================] - 5s 643us/step - loss: 1.4725 - note_output_loss: 0.3866 - length_output_loss: 2.1718 - val_loss: 9.1723 - val_note_output_loss: 7.1422 - val_length_output_loss: 4.0603\n",
      "Epoch 1015/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.4414 - note_output_loss: 0.3555 - length_output_loss: 2.1718 - val_loss: 9.1882 - val_note_output_loss: 7.1576 - val_length_output_loss: 4.0612\n",
      "Epoch 1016/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.4575 - note_output_loss: 0.3764 - length_output_loss: 2.1623 - val_loss: 9.1858 - val_note_output_loss: 7.1544 - val_length_output_loss: 4.0627\n",
      "Epoch 1017/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.4624 - note_output_loss: 0.3775 - length_output_loss: 2.1699 - val_loss: 9.1798 - val_note_output_loss: 7.1477 - val_length_output_loss: 4.0642\n",
      "Epoch 1018/1500\n",
      "7089/7089 [==============================] - 5s 646us/step - loss: 1.4368 - note_output_loss: 0.3574 - length_output_loss: 2.1589 - val_loss: 9.2071 - val_note_output_loss: 7.1714 - val_length_output_loss: 4.0714\n",
      "Epoch 1019/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 1.4522 - note_output_loss: 0.3695 - length_output_loss: 2.1654 - val_loss: 9.2445 - val_note_output_loss: 7.2110 - val_length_output_loss: 4.0670\n",
      "Epoch 1020/1500\n",
      "7089/7089 [==============================] - 5s 704us/step - loss: 1.4556 - note_output_loss: 0.3739 - length_output_loss: 2.1633 - val_loss: 9.2079 - val_note_output_loss: 7.1778 - val_length_output_loss: 4.0603\n",
      "Epoch 1021/1500\n",
      "7089/7089 [==============================] - 5s 675us/step - loss: 1.4576 - note_output_loss: 0.3783 - length_output_loss: 2.1585 - val_loss: 9.2032 - val_note_output_loss: 7.1732 - val_length_output_loss: 4.0601\n",
      "Epoch 1022/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.4509 - note_output_loss: 0.3662 - length_output_loss: 2.1694 - val_loss: 9.2180 - val_note_output_loss: 7.1811 - val_length_output_loss: 4.0740\n",
      "Epoch 1023/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.4554 - note_output_loss: 0.3725 - length_output_loss: 2.1658 - val_loss: 9.2094 - val_note_output_loss: 7.1818 - val_length_output_loss: 4.0552\n",
      "Epoch 1024/1500\n",
      "7089/7089 [==============================] - 5s 652us/step - loss: 1.4444 - note_output_loss: 0.3664 - length_output_loss: 2.1561 - val_loss: 9.1972 - val_note_output_loss: 7.1655 - val_length_output_loss: 4.0632\n",
      "Epoch 1025/1500\n",
      "7089/7089 [==============================] - 5s 676us/step - loss: 1.4544 - note_output_loss: 0.3722 - length_output_loss: 2.1643 - val_loss: 9.2409 - val_note_output_loss: 7.2098 - val_length_output_loss: 4.0623\n",
      "Epoch 1026/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.4474 - note_output_loss: 0.3699 - length_output_loss: 2.1549 - val_loss: 9.1795 - val_note_output_loss: 7.1488 - val_length_output_loss: 4.0613\n",
      "Epoch 1027/1500\n",
      "7089/7089 [==============================] - 5s 687us/step - loss: 1.4581 - note_output_loss: 0.3771 - length_output_loss: 2.1619 - val_loss: 9.2344 - val_note_output_loss: 7.2013 - val_length_output_loss: 4.0663\n",
      "Epoch 1028/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.4373 - note_output_loss: 0.3597 - length_output_loss: 2.1552 - val_loss: 9.2017 - val_note_output_loss: 7.1681 - val_length_output_loss: 4.0672\n",
      "Epoch 1029/1500\n",
      "7089/7089 [==============================] - 5s 666us/step - loss: 1.4481 - note_output_loss: 0.3706 - length_output_loss: 2.1550 - val_loss: 9.2188 - val_note_output_loss: 7.1849 - val_length_output_loss: 4.0678\n",
      "Epoch 1030/1500\n",
      "7089/7089 [==============================] - 5s 649us/step - loss: 1.4450 - note_output_loss: 0.3681 - length_output_loss: 2.1539 - val_loss: 9.2172 - val_note_output_loss: 7.1844 - val_length_output_loss: 4.0656\n",
      "Epoch 1031/1500\n",
      "7089/7089 [==============================] - 5s 683us/step - loss: 1.4551 - note_output_loss: 0.3746 - length_output_loss: 2.1609 - val_loss: 9.2104 - val_note_output_loss: 7.1775 - val_length_output_loss: 4.0657\n",
      "Epoch 1032/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.4447 - note_output_loss: 0.3714 - length_output_loss: 2.1466 - val_loss: 9.2219 - val_note_output_loss: 7.1879 - val_length_output_loss: 4.0680\n",
      "Epoch 1033/1500\n",
      "7089/7089 [==============================] - 5s 665us/step - loss: 1.4370 - note_output_loss: 0.3613 - length_output_loss: 2.1515 - val_loss: 9.2097 - val_note_output_loss: 7.1681 - val_length_output_loss: 4.0833\n",
      "Epoch 1034/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.4411 - note_output_loss: 0.3651 - length_output_loss: 2.1520 - val_loss: 9.2598 - val_note_output_loss: 7.2220 - val_length_output_loss: 4.0756\n",
      "Epoch 1035/1500\n",
      "7089/7089 [==============================] - 5s 651us/step - loss: 1.4462 - note_output_loss: 0.3730 - length_output_loss: 2.1466 - val_loss: 9.2313 - val_note_output_loss: 7.1891 - val_length_output_loss: 4.0844\n",
      "Epoch 1036/1500\n",
      "7089/7089 [==============================] - 6s 794us/step - loss: 1.4475 - note_output_loss: 0.3666 - length_output_loss: 2.1618 - val_loss: 9.2550 - val_note_output_loss: 7.2168 - val_length_output_loss: 4.0762\n",
      "Epoch 1037/1500\n",
      "7089/7089 [==============================] - 6s 902us/step - loss: 1.4384 - note_output_loss: 0.3662 - length_output_loss: 2.1444 - val_loss: 9.2479 - val_note_output_loss: 7.2052 - val_length_output_loss: 4.0855\n",
      "Epoch 1038/1500\n",
      "7089/7089 [==============================] - 5s 702us/step - loss: 1.4335 - note_output_loss: 0.3599 - length_output_loss: 2.1471 - val_loss: 9.2477 - val_note_output_loss: 7.2125 - val_length_output_loss: 4.0705\n",
      "Epoch 1039/1500\n",
      "7089/7089 [==============================] - 5s 706us/step - loss: 1.4415 - note_output_loss: 0.3664 - length_output_loss: 2.1501 - val_loss: 9.2476 - val_note_output_loss: 7.2088 - val_length_output_loss: 4.0776\n",
      "Epoch 1040/1500\n",
      "7089/7089 [==============================] - 5s 639us/step - loss: 1.4342 - note_output_loss: 0.3600 - length_output_loss: 2.1485 - val_loss: 9.2140 - val_note_output_loss: 7.1761 - val_length_output_loss: 4.0758\n",
      "Epoch 1041/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.4338 - note_output_loss: 0.3611 - length_output_loss: 2.1455 - val_loss: 9.2084 - val_note_output_loss: 7.1770 - val_length_output_loss: 4.0628\n",
      "Epoch 1042/1500\n",
      "7089/7089 [==============================] - 5s 641us/step - loss: 1.4455 - note_output_loss: 0.3715 - length_output_loss: 2.1480 - val_loss: 9.2550 - val_note_output_loss: 7.2154 - val_length_output_loss: 4.0792\n",
      "Epoch 1043/1500\n",
      "7089/7089 [==============================] - 5s 673us/step - loss: 1.4240 - note_output_loss: 0.3580 - length_output_loss: 2.1322 - val_loss: 9.2625 - val_note_output_loss: 7.2183 - val_length_output_loss: 4.0883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1044/1500\n",
      "7089/7089 [==============================] - 1927s 272ms/step - loss: 1.4324 - note_output_loss: 0.3609 - length_output_loss: 2.1430 - val_loss: 9.2675 - val_note_output_loss: 7.2264 - val_length_output_loss: 4.0822\n",
      "Epoch 1045/1500\n",
      "7089/7089 [==============================] - 20s 3ms/step - loss: 1.4387 - note_output_loss: 0.3637 - length_output_loss: 2.1500 - val_loss: 9.2430 - val_note_output_loss: 7.1956 - val_length_output_loss: 4.0948\n",
      "Epoch 1046/1500\n",
      "7089/7089 [==============================] - 19s 3ms/step - loss: 1.4397 - note_output_loss: 0.3666 - length_output_loss: 2.1461 - val_loss: 9.2649 - val_note_output_loss: 7.2176 - val_length_output_loss: 4.0947\n",
      "Epoch 1047/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4337 - note_output_loss: 0.3649 - length_output_loss: 2.1374 - val_loss: 9.2567 - val_note_output_loss: 7.2162 - val_length_output_loss: 4.0809\n",
      "Epoch 1048/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4371 - note_output_loss: 0.3638 - length_output_loss: 2.1464 - val_loss: 9.2725 - val_note_output_loss: 7.2263 - val_length_output_loss: 4.0923\n",
      "Epoch 1049/1500\n",
      "7089/7089 [==============================] - 3184s 449ms/step - loss: 1.4319 - note_output_loss: 0.3580 - length_output_loss: 2.1480 - val_loss: 9.2924 - val_note_output_loss: 7.2498 - val_length_output_loss: 4.0852\n",
      "Epoch 1050/1500\n",
      "7089/7089 [==============================] - 4s 632us/step - loss: 1.4229 - note_output_loss: 0.3494 - length_output_loss: 2.1470 - val_loss: 9.2834 - val_note_output_loss: 7.2410 - val_length_output_loss: 4.0849\n",
      "Epoch 1051/1500\n",
      "7089/7089 [==============================] - 11s 2ms/step - loss: 1.4548 - note_output_loss: 0.3820 - length_output_loss: 2.1456 - val_loss: 9.2513 - val_note_output_loss: 7.2065 - val_length_output_loss: 4.0896\n",
      "Epoch 1052/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4273 - note_output_loss: 0.3550 - length_output_loss: 2.1445 - val_loss: 9.2491 - val_note_output_loss: 7.2074 - val_length_output_loss: 4.0835\n",
      "Epoch 1053/1500\n",
      "7089/7089 [==============================] - 19s 3ms/step - loss: 1.4289 - note_output_loss: 0.3552 - length_output_loss: 2.1474 - val_loss: 9.2552 - val_note_output_loss: 7.2137 - val_length_output_loss: 4.0830\n",
      "Epoch 1054/1500\n",
      "7089/7089 [==============================] - 3204s 452ms/step - loss: 1.4196 - note_output_loss: 0.3533 - length_output_loss: 2.1326 - val_loss: 9.3020 - val_note_output_loss: 7.2562 - val_length_output_loss: 4.0917\n",
      "Epoch 1055/1500\n",
      "7089/7089 [==============================] - 4s 617us/step - loss: 1.4208 - note_output_loss: 0.3519 - length_output_loss: 2.1378 - val_loss: 9.2704 - val_note_output_loss: 7.2250 - val_length_output_loss: 4.0907\n",
      "Epoch 1056/1500\n",
      "7089/7089 [==============================] - 11s 2ms/step - loss: 1.4288 - note_output_loss: 0.3600 - length_output_loss: 2.1376 - val_loss: 9.2705 - val_note_output_loss: 7.2254 - val_length_output_loss: 4.0902\n",
      "Epoch 1057/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4288 - note_output_loss: 0.3565 - length_output_loss: 2.1445 - val_loss: 9.2751 - val_note_output_loss: 7.2309 - val_length_output_loss: 4.0885\n",
      "Epoch 1058/1500\n",
      "7089/7089 [==============================] - 17s 2ms/step - loss: 1.4264 - note_output_loss: 0.3570 - length_output_loss: 2.1388 - val_loss: 9.2959 - val_note_output_loss: 7.2507 - val_length_output_loss: 4.0904\n",
      "Epoch 1059/1500\n",
      "7089/7089 [==============================] - 3206s 452ms/step - loss: 1.4317 - note_output_loss: 0.3565 - length_output_loss: 2.1504 - val_loss: 9.2990 - val_note_output_loss: 7.2529 - val_length_output_loss: 4.0922\n",
      "Epoch 1060/1500\n",
      "7089/7089 [==============================] - 4s 622us/step - loss: 1.4280 - note_output_loss: 0.3572 - length_output_loss: 2.1416 - val_loss: 9.2932 - val_note_output_loss: 7.2474 - val_length_output_loss: 4.0916\n",
      "Epoch 1061/1500\n",
      "7089/7089 [==============================] - 12s 2ms/step - loss: 1.4275 - note_output_loss: 0.3559 - length_output_loss: 2.1433 - val_loss: 9.2911 - val_note_output_loss: 7.2456 - val_length_output_loss: 4.0910\n",
      "Epoch 1062/1500\n",
      "7089/7089 [==============================] - 19s 3ms/step - loss: 1.4212 - note_output_loss: 0.3537 - length_output_loss: 2.1350 - val_loss: 9.2886 - val_note_output_loss: 7.2477 - val_length_output_loss: 4.0819\n",
      "Epoch 1063/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4373 - note_output_loss: 0.3633 - length_output_loss: 2.1479 - val_loss: 9.2654 - val_note_output_loss: 7.2254 - val_length_output_loss: 4.0800\n",
      "Epoch 1064/1500\n",
      "7089/7089 [==============================] - 3166s 447ms/step - loss: 1.4163 - note_output_loss: 0.3495 - length_output_loss: 2.1336 - val_loss: 9.2950 - val_note_output_loss: 7.2507 - val_length_output_loss: 4.0886\n",
      "Epoch 1065/1500\n",
      "7089/7089 [==============================] - 4s 619us/step - loss: 1.4268 - note_output_loss: 0.3588 - length_output_loss: 2.1361 - val_loss: 9.3199 - val_note_output_loss: 7.2730 - val_length_output_loss: 4.0938\n",
      "Epoch 1066/1500\n",
      "7089/7089 [==============================] - 12s 2ms/step - loss: 1.4385 - note_output_loss: 0.3658 - length_output_loss: 2.1454 - val_loss: 9.2657 - val_note_output_loss: 7.2201 - val_length_output_loss: 4.0912\n",
      "Epoch 1067/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4290 - note_output_loss: 0.3585 - length_output_loss: 2.1410 - val_loss: 9.2881 - val_note_output_loss: 7.2426 - val_length_output_loss: 4.0911\n",
      "Epoch 1068/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4191 - note_output_loss: 0.3481 - length_output_loss: 2.1420 - val_loss: 9.2939 - val_note_output_loss: 7.2470 - val_length_output_loss: 4.0937\n",
      "Epoch 1069/1500\n",
      "7089/7089 [==============================] - 1850s 261ms/step - loss: 1.4259 - note_output_loss: 0.3582 - length_output_loss: 2.1354 - val_loss: 9.2761 - val_note_output_loss: 7.2272 - val_length_output_loss: 4.0979\n",
      "Epoch 1070/1500\n",
      "7089/7089 [==============================] - 4s 621us/step - loss: 1.4303 - note_output_loss: 0.3621 - length_output_loss: 2.1363 - val_loss: 9.2836 - val_note_output_loss: 7.2348 - val_length_output_loss: 4.0977\n",
      "Epoch 1071/1500\n",
      "7089/7089 [==============================] - 10s 1ms/step - loss: 1.4285 - note_output_loss: 0.3538 - length_output_loss: 2.1495 - val_loss: 9.3384 - val_note_output_loss: 7.2893 - val_length_output_loss: 4.0981\n",
      "Epoch 1072/1500\n",
      "7089/7089 [==============================] - 19s 3ms/step - loss: 1.4214 - note_output_loss: 0.3516 - length_output_loss: 2.1396 - val_loss: 9.3015 - val_note_output_loss: 7.2524 - val_length_output_loss: 4.0981\n",
      "Epoch 1073/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4214 - note_output_loss: 0.3510 - length_output_loss: 2.1409 - val_loss: 9.3155 - val_note_output_loss: 7.2656 - val_length_output_loss: 4.0999\n",
      "Epoch 1074/1500\n",
      "7089/7089 [==============================] - 3205s 452ms/step - loss: 1.4293 - note_output_loss: 0.3612 - length_output_loss: 2.1362 - val_loss: 9.3120 - val_note_output_loss: 7.2618 - val_length_output_loss: 4.1002\n",
      "Epoch 1075/1500\n",
      "7089/7089 [==============================] - 4s 623us/step - loss: 1.4215 - note_output_loss: 0.3551 - length_output_loss: 2.1329 - val_loss: 9.3412 - val_note_output_loss: 7.2906 - val_length_output_loss: 4.1012\n",
      "Epoch 1076/1500\n",
      "7089/7089 [==============================] - 11s 2ms/step - loss: 1.4241 - note_output_loss: 0.3560 - length_output_loss: 2.1363 - val_loss: 9.3558 - val_note_output_loss: 7.3003 - val_length_output_loss: 4.1111\n",
      "Epoch 1077/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4236 - note_output_loss: 0.3598 - length_output_loss: 2.1276 - val_loss: 9.3693 - val_note_output_loss: 7.3164 - val_length_output_loss: 4.1059\n",
      "Epoch 1078/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4320 - note_output_loss: 0.3652 - length_output_loss: 2.1336 - val_loss: 9.3332 - val_note_output_loss: 7.2799 - val_length_output_loss: 4.1065\n",
      "Epoch 1079/1500\n",
      "7089/7089 [==============================] - 3206s 452ms/step - loss: 1.4182 - note_output_loss: 0.3489 - length_output_loss: 2.1386 - val_loss: 9.2903 - val_note_output_loss: 7.2381 - val_length_output_loss: 4.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1080/1500\n",
      "7089/7089 [==============================] - 4s 627us/step - loss: 1.4184 - note_output_loss: 0.3542 - length_output_loss: 2.1285 - val_loss: 9.3081 - val_note_output_loss: 7.2555 - val_length_output_loss: 4.1052\n",
      "Epoch 1081/1500\n",
      "7089/7089 [==============================] - 8s 1ms/step - loss: 1.4231 - note_output_loss: 0.3560 - length_output_loss: 2.1341 - val_loss: 9.3132 - val_note_output_loss: 7.2594 - val_length_output_loss: 4.1076\n",
      "Epoch 1082/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4223 - note_output_loss: 0.3499 - length_output_loss: 2.1447 - val_loss: 9.3199 - val_note_output_loss: 7.2659 - val_length_output_loss: 4.1080\n",
      "Epoch 1083/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4156 - note_output_loss: 0.3508 - length_output_loss: 2.1296 - val_loss: 9.3152 - val_note_output_loss: 7.2626 - val_length_output_loss: 4.1051\n",
      "Epoch 1084/1500\n",
      "7089/7089 [==============================] - 3208s 453ms/step - loss: 1.4235 - note_output_loss: 0.3505 - length_output_loss: 2.1462 - val_loss: 9.3299 - val_note_output_loss: 7.2771 - val_length_output_loss: 4.1056\n",
      "Epoch 1085/1500\n",
      "7089/7089 [==============================] - 4s 628us/step - loss: 1.4114 - note_output_loss: 0.3500 - length_output_loss: 2.1227 - val_loss: 9.3604 - val_note_output_loss: 7.3078 - val_length_output_loss: 4.1052\n",
      "Epoch 1086/1500\n",
      "7089/7089 [==============================] - 5s 737us/step - loss: 1.4137 - note_output_loss: 0.3472 - length_output_loss: 2.1330 - val_loss: 9.3544 - val_note_output_loss: 7.2985 - val_length_output_loss: 4.1118\n",
      "Epoch 1087/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4110 - note_output_loss: 0.3476 - length_output_loss: 2.1269 - val_loss: 9.3225 - val_note_output_loss: 7.2715 - val_length_output_loss: 4.1019\n",
      "Epoch 1088/1500\n",
      "7089/7089 [==============================] - 25s 3ms/step - loss: 1.4232 - note_output_loss: 0.3531 - length_output_loss: 2.1401 - val_loss: 9.3093 - val_note_output_loss: 7.2571 - val_length_output_loss: 4.1045\n",
      "Epoch 1089/1500\n",
      "7089/7089 [==============================] - 2121s 299ms/step - loss: 1.4182 - note_output_loss: 0.3534 - length_output_loss: 2.1297 - val_loss: 9.3090 - val_note_output_loss: 7.2591 - val_length_output_loss: 4.0997\n",
      "Epoch 1090/1500\n",
      "7089/7089 [==============================] - 5s 680us/step - loss: 1.4189 - note_output_loss: 0.3534 - length_output_loss: 2.1311 - val_loss: 9.3434 - val_note_output_loss: 7.2921 - val_length_output_loss: 4.1026\n",
      "Epoch 1091/1500\n",
      "7089/7089 [==============================] - 13s 2ms/step - loss: 1.4211 - note_output_loss: 0.3538 - length_output_loss: 2.1346 - val_loss: 9.3193 - val_note_output_loss: 7.2669 - val_length_output_loss: 4.1048\n",
      "Epoch 1092/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4125 - note_output_loss: 0.3523 - length_output_loss: 2.1203 - val_loss: 9.3165 - val_note_output_loss: 7.2626 - val_length_output_loss: 4.1079\n",
      "Epoch 1093/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4254 - note_output_loss: 0.3580 - length_output_loss: 2.1347 - val_loss: 9.3544 - val_note_output_loss: 7.2981 - val_length_output_loss: 4.1127\n",
      "Epoch 1094/1500\n",
      "7089/7089 [==============================] - 2008s 283ms/step - loss: 1.4226 - note_output_loss: 0.3558 - length_output_loss: 2.1337 - val_loss: 9.3943 - val_note_output_loss: 7.3378 - val_length_output_loss: 4.1129\n",
      "Epoch 1095/1500\n",
      "7089/7089 [==============================] - 4s 632us/step - loss: 1.4194 - note_output_loss: 0.3504 - length_output_loss: 2.1379 - val_loss: 9.3672 - val_note_output_loss: 7.3085 - val_length_output_loss: 4.1175\n",
      "Epoch 1096/1500\n",
      "7089/7089 [==============================] - 9s 1ms/step - loss: 1.4159 - note_output_loss: 0.3532 - length_output_loss: 2.1256 - val_loss: 9.3781 - val_note_output_loss: 7.3229 - val_length_output_loss: 4.1103\n",
      "Epoch 1097/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4005 - note_output_loss: 0.3375 - length_output_loss: 2.1260 - val_loss: 9.3686 - val_note_output_loss: 7.3123 - val_length_output_loss: 4.1126\n",
      "Epoch 1098/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4163 - note_output_loss: 0.3543 - length_output_loss: 2.1238 - val_loss: 9.3795 - val_note_output_loss: 7.3219 - val_length_output_loss: 4.1153\n",
      "Epoch 1099/1500\n",
      "7089/7089 [==============================] - 1872s 264ms/step - loss: 1.4137 - note_output_loss: 0.3515 - length_output_loss: 2.1244 - val_loss: 9.3208 - val_note_output_loss: 7.2660 - val_length_output_loss: 4.1097\n",
      "Epoch 1100/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.4109 - note_output_loss: 0.3493 - length_output_loss: 2.1232 - val_loss: 9.3510 - val_note_output_loss: 7.2933 - val_length_output_loss: 4.1153\n",
      "Epoch 1101/1500\n",
      "7089/7089 [==============================] - 7s 986us/step - loss: 1.4033 - note_output_loss: 0.3456 - length_output_loss: 2.1155 - val_loss: 9.3815 - val_note_output_loss: 7.3224 - val_length_output_loss: 4.1182\n",
      "Epoch 1102/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4072 - note_output_loss: 0.3445 - length_output_loss: 2.1254 - val_loss: 9.3715 - val_note_output_loss: 7.3159 - val_length_output_loss: 4.1111\n",
      "Epoch 1103/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4071 - note_output_loss: 0.3466 - length_output_loss: 2.1210 - val_loss: 9.3959 - val_note_output_loss: 7.3391 - val_length_output_loss: 4.1135\n",
      "Epoch 1104/1500\n",
      "7089/7089 [==============================] - 3210s 453ms/step - loss: 1.4235 - note_output_loss: 0.3603 - length_output_loss: 2.1264 - val_loss: 9.3906 - val_note_output_loss: 7.3329 - val_length_output_loss: 4.1153\n",
      "Epoch 1105/1500\n",
      "7089/7089 [==============================] - 5s 635us/step - loss: 1.4023 - note_output_loss: 0.3437 - length_output_loss: 2.1173 - val_loss: 9.3588 - val_note_output_loss: 7.3054 - val_length_output_loss: 4.1068\n",
      "Epoch 1106/1500\n",
      "7089/7089 [==============================] - 4s 613us/step - loss: 1.4172 - note_output_loss: 0.3553 - length_output_loss: 2.1237 - val_loss: 9.3772 - val_note_output_loss: 7.3210 - val_length_output_loss: 4.1123\n",
      "Epoch 1107/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4141 - note_output_loss: 0.3521 - length_output_loss: 2.1240 - val_loss: 9.3774 - val_note_output_loss: 7.3207 - val_length_output_loss: 4.1134\n",
      "Epoch 1108/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4032 - note_output_loss: 0.3425 - length_output_loss: 2.1215 - val_loss: 9.3625 - val_note_output_loss: 7.3029 - val_length_output_loss: 4.1191\n",
      "Epoch 1109/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4153 - note_output_loss: 0.3538 - length_output_loss: 2.1230 - val_loss: 9.4074 - val_note_output_loss: 7.3410 - val_length_output_loss: 4.1328\n",
      "Epoch 1110/1500\n",
      "7089/7089 [==============================] - 3198s 451ms/step - loss: 1.3991 - note_output_loss: 0.3423 - length_output_loss: 2.1137 - val_loss: 9.3721 - val_note_output_loss: 7.3151 - val_length_output_loss: 4.1139\n",
      "Epoch 1111/1500\n",
      "7089/7089 [==============================] - 4s 615us/step - loss: 1.4103 - note_output_loss: 0.3481 - length_output_loss: 2.1243 - val_loss: 9.3785 - val_note_output_loss: 7.3155 - val_length_output_loss: 4.1260\n",
      "Epoch 1112/1500\n",
      "7089/7089 [==============================] - 17s 2ms/step - loss: 1.4073 - note_output_loss: 0.3512 - length_output_loss: 2.1123 - val_loss: 9.4018 - val_note_output_loss: 7.3411 - val_length_output_loss: 4.1215\n",
      "Epoch 1113/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4090 - note_output_loss: 0.3470 - length_output_loss: 2.1239 - val_loss: 9.3829 - val_note_output_loss: 7.3202 - val_length_output_loss: 4.1253\n",
      "Epoch 1114/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.4057 - note_output_loss: 0.3506 - length_output_loss: 2.1102 - val_loss: 9.3641 - val_note_output_loss: 7.3114 - val_length_output_loss: 4.1055\n",
      "Epoch 1115/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4131 - note_output_loss: 0.3537 - length_output_loss: 2.1187 - val_loss: 9.3822 - val_note_output_loss: 7.3230 - val_length_output_loss: 4.1183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1116/1500\n",
      "7089/7089 [==============================] - 1828s 258ms/step - loss: 1.4061 - note_output_loss: 0.3479 - length_output_loss: 2.1164 - val_loss: 9.3808 - val_note_output_loss: 7.3221 - val_length_output_loss: 4.1173\n",
      "Epoch 1117/1500\n",
      "7089/7089 [==============================] - 4s 623us/step - loss: 1.4114 - note_output_loss: 0.3512 - length_output_loss: 2.1204 - val_loss: 9.3675 - val_note_output_loss: 7.3052 - val_length_output_loss: 4.1246\n",
      "Epoch 1118/1500\n",
      "7089/7089 [==============================] - 10s 1ms/step - loss: 1.4182 - note_output_loss: 0.3555 - length_output_loss: 2.1253 - val_loss: 9.3375 - val_note_output_loss: 7.2792 - val_length_output_loss: 4.1166\n",
      "Epoch 1119/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.3861 - note_output_loss: 0.3324 - length_output_loss: 2.1073 - val_loss: 9.4163 - val_note_output_loss: 7.3456 - val_length_output_loss: 4.1413\n",
      "Epoch 1120/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4048 - note_output_loss: 0.3483 - length_output_loss: 2.1129 - val_loss: 9.3862 - val_note_output_loss: 7.3222 - val_length_output_loss: 4.1280\n",
      "Epoch 1121/1500\n",
      "7089/7089 [==============================] - 3207s 452ms/step - loss: 1.3961 - note_output_loss: 0.3373 - length_output_loss: 2.1176 - val_loss: 9.4017 - val_note_output_loss: 7.3325 - val_length_output_loss: 4.1382\n",
      "Epoch 1122/1500\n",
      "7089/7089 [==============================] - 4s 632us/step - loss: 1.4138 - note_output_loss: 0.3566 - length_output_loss: 2.1144 - val_loss: 9.3711 - val_note_output_loss: 7.3061 - val_length_output_loss: 4.1300\n",
      "Epoch 1123/1500\n",
      "7089/7089 [==============================] - 9s 1ms/step - loss: 1.4112 - note_output_loss: 0.3510 - length_output_loss: 2.1204 - val_loss: 9.3796 - val_note_output_loss: 7.3182 - val_length_output_loss: 4.1228\n",
      "Epoch 1124/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.3914 - note_output_loss: 0.3384 - length_output_loss: 2.1059 - val_loss: 9.3896 - val_note_output_loss: 7.3260 - val_length_output_loss: 4.1273\n",
      "Epoch 1125/1500\n",
      "7089/7089 [==============================] - 17s 2ms/step - loss: 1.3908 - note_output_loss: 0.3384 - length_output_loss: 2.1048 - val_loss: 9.3998 - val_note_output_loss: 7.3330 - val_length_output_loss: 4.1335\n",
      "Epoch 1126/1500\n",
      "7089/7089 [==============================] - 3208s 452ms/step - loss: 1.3868 - note_output_loss: 0.3314 - length_output_loss: 2.1109 - val_loss: 9.4795 - val_note_output_loss: 7.4098 - val_length_output_loss: 4.1394\n",
      "Epoch 1127/1500\n",
      "7089/7089 [==============================] - 4s 625us/step - loss: 1.3946 - note_output_loss: 0.3377 - length_output_loss: 2.1139 - val_loss: 9.4476 - val_note_output_loss: 7.3789 - val_length_output_loss: 4.1375\n",
      "Epoch 1128/1500\n",
      "7089/7089 [==============================] - 6s 846us/step - loss: 1.3896 - note_output_loss: 0.3350 - length_output_loss: 2.1092 - val_loss: 9.3954 - val_note_output_loss: 7.3307 - val_length_output_loss: 4.1295\n",
      "Epoch 1129/1500\n",
      "7089/7089 [==============================] - 19s 3ms/step - loss: 1.3955 - note_output_loss: 0.3384 - length_output_loss: 2.1143 - val_loss: 9.4083 - val_note_output_loss: 7.3399 - val_length_output_loss: 4.1368\n",
      "Epoch 1130/1500\n",
      "7089/7089 [==============================] - 17s 2ms/step - loss: 1.4118 - note_output_loss: 0.3532 - length_output_loss: 2.1172 - val_loss: 9.4217 - val_note_output_loss: 7.3536 - val_length_output_loss: 4.1362\n",
      "Epoch 1131/1500\n",
      "7089/7089 [==============================] - 3210s 453ms/step - loss: 1.3952 - note_output_loss: 0.3386 - length_output_loss: 2.1133 - val_loss: 9.4519 - val_note_output_loss: 7.3856 - val_length_output_loss: 4.1325\n",
      "Epoch 1132/1500\n",
      "7089/7089 [==============================] - 5s 682us/step - loss: 1.3982 - note_output_loss: 0.3444 - length_output_loss: 2.1077 - val_loss: 9.4225 - val_note_output_loss: 7.3538 - val_length_output_loss: 4.1374\n",
      "Epoch 1133/1500\n",
      "7089/7089 [==============================] - 4s 614us/step - loss: 1.4063 - note_output_loss: 0.3493 - length_output_loss: 2.1138 - val_loss: 9.4057 - val_note_output_loss: 7.3369 - val_length_output_loss: 4.1377\n",
      "Epoch 1134/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.4132 - note_output_loss: 0.3545 - length_output_loss: 2.1174 - val_loss: 9.4241 - val_note_output_loss: 7.3570 - val_length_output_loss: 4.1342\n",
      "Epoch 1135/1500\n",
      "7089/7089 [==============================] - 17s 2ms/step - loss: 1.4044 - note_output_loss: 0.3485 - length_output_loss: 2.1117 - val_loss: 9.4137 - val_note_output_loss: 7.3447 - val_length_output_loss: 4.1381\n",
      "Epoch 1136/1500\n",
      "7089/7089 [==============================] - 18s 3ms/step - loss: 1.3926 - note_output_loss: 0.3394 - length_output_loss: 2.1064 - val_loss: 9.4228 - val_note_output_loss: 7.3554 - val_length_output_loss: 4.1347\n",
      "Epoch 1137/1500\n",
      "7089/7089 [==============================] - 3199s 451ms/step - loss: 1.4075 - note_output_loss: 0.3505 - length_output_loss: 2.1142 - val_loss: 9.3943 - val_note_output_loss: 7.3273 - val_length_output_loss: 4.1340\n",
      "Epoch 1138/1500\n",
      "7089/7089 [==============================] - 4s 611us/step - loss: 1.3990 - note_output_loss: 0.3492 - length_output_loss: 2.0996 - val_loss: 9.4404 - val_note_output_loss: 7.3751 - val_length_output_loss: 4.1306\n",
      "Epoch 1139/1500\n",
      "7089/7089 [==============================] - 15s 2ms/step - loss: 1.4072 - note_output_loss: 0.3472 - length_output_loss: 2.1200 - val_loss: 9.4422 - val_note_output_loss: 7.3689 - val_length_output_loss: 4.1467\n",
      "Epoch 1140/1500\n",
      "7089/7089 [==============================] - 17s 2ms/step - loss: 1.4018 - note_output_loss: 0.3420 - length_output_loss: 2.1196 - val_loss: 9.4224 - val_note_output_loss: 7.3533 - val_length_output_loss: 4.1382\n",
      "Epoch 1141/1500\n",
      "7089/7089 [==============================] - 18s 2ms/step - loss: 1.3947 - note_output_loss: 0.3424 - length_output_loss: 2.1047 - val_loss: 9.4375 - val_note_output_loss: 7.3658 - val_length_output_loss: 4.1434\n",
      "Epoch 1142/1500\n",
      "7089/7089 [==============================] - 3201s 452ms/step - loss: 1.3891 - note_output_loss: 0.3360 - length_output_loss: 2.1062 - val_loss: 9.4355 - val_note_output_loss: 7.3635 - val_length_output_loss: 4.1440\n",
      "Epoch 1143/1500\n",
      "7089/7089 [==============================] - 4s 618us/step - loss: 1.3951 - note_output_loss: 0.3401 - length_output_loss: 2.1100 - val_loss: 9.4154 - val_note_output_loss: 7.3463 - val_length_output_loss: 4.1382\n",
      "Epoch 1144/1500\n",
      "7089/7089 [==============================] - 13s 2ms/step - loss: 1.3930 - note_output_loss: 0.3421 - length_output_loss: 2.1019 - val_loss: 9.4561 - val_note_output_loss: 7.3826 - val_length_output_loss: 4.1469\n",
      "Epoch 1145/1500\n",
      "7089/7089 [==============================] - 17s 2ms/step - loss: 1.3928 - note_output_loss: 0.3394 - length_output_loss: 2.1069 - val_loss: 9.4507 - val_note_output_loss: 7.3762 - val_length_output_loss: 4.1492\n",
      "Epoch 1146/1500\n",
      "7089/7089 [==============================] - 20s 3ms/step - loss: 1.3967 - note_output_loss: 0.3462 - length_output_loss: 2.1011 - val_loss: 9.4379 - val_note_output_loss: 7.3672 - val_length_output_loss: 4.1413\n",
      "Epoch 1147/1500\n",
      "7089/7089 [==============================] - 1735s 245ms/step - loss: 1.3957 - note_output_loss: 0.3338 - length_output_loss: 2.1238 - val_loss: 9.4567 - val_note_output_loss: 7.3856 - val_length_output_loss: 4.1421\n",
      "Epoch 1148/1500\n",
      "7089/7089 [==============================] - 5s 741us/step - loss: 1.3851 - note_output_loss: 0.3330 - length_output_loss: 2.1043 - val_loss: 9.4373 - val_note_output_loss: 7.3646 - val_length_output_loss: 4.1454\n",
      "Epoch 1149/1500\n",
      "7089/7089 [==============================] - 5s 709us/step - loss: 1.3826 - note_output_loss: 0.3376 - length_output_loss: 2.0900 - val_loss: 9.4447 - val_note_output_loss: 7.3674 - val_length_output_loss: 4.1547\n",
      "Epoch 1150/1500\n",
      "7089/7089 [==============================] - 5s 670us/step - loss: 1.3853 - note_output_loss: 0.3303 - length_output_loss: 2.1100 - val_loss: 9.4838 - val_note_output_loss: 7.4044 - val_length_output_loss: 4.1587\n",
      "Epoch 1151/1500\n",
      "7089/7089 [==============================] - 5s 666us/step - loss: 1.3844 - note_output_loss: 0.3298 - length_output_loss: 2.1092 - val_loss: 9.4946 - val_note_output_loss: 7.4192 - val_length_output_loss: 4.1509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1152/1500\n",
      "7089/7089 [==============================] - 5s 655us/step - loss: 1.3912 - note_output_loss: 0.3365 - length_output_loss: 2.1093 - val_loss: 9.4772 - val_note_output_loss: 7.3979 - val_length_output_loss: 4.1584\n",
      "Epoch 1153/1500\n",
      "7089/7089 [==============================] - 5s 673us/step - loss: 1.3844 - note_output_loss: 0.3321 - length_output_loss: 2.1046 - val_loss: 9.4750 - val_note_output_loss: 7.3966 - val_length_output_loss: 4.1568\n",
      "Epoch 1154/1500\n",
      "7089/7089 [==============================] - 5s 654us/step - loss: 1.3792 - note_output_loss: 0.3275 - length_output_loss: 2.1034 - val_loss: 9.4505 - val_note_output_loss: 7.3718 - val_length_output_loss: 4.1574\n",
      "Epoch 1155/1500\n",
      "7089/7089 [==============================] - 6s 909us/step - loss: 1.3882 - note_output_loss: 0.3375 - length_output_loss: 2.1015 - val_loss: 9.4768 - val_note_output_loss: 7.3982 - val_length_output_loss: 4.1572\n",
      "Epoch 1156/1500\n",
      "7089/7089 [==============================] - 5s 653us/step - loss: 1.3816 - note_output_loss: 0.3322 - length_output_loss: 2.0987 - val_loss: 9.4446 - val_note_output_loss: 7.3734 - val_length_output_loss: 4.1425\n",
      "Epoch 1157/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.3934 - note_output_loss: 0.3438 - length_output_loss: 2.0991 - val_loss: 9.4789 - val_note_output_loss: 7.4020 - val_length_output_loss: 4.1539\n",
      "Epoch 1158/1500\n",
      "7089/7089 [==============================] - 5s 658us/step - loss: 1.3925 - note_output_loss: 0.3410 - length_output_loss: 2.1031 - val_loss: 9.4814 - val_note_output_loss: 7.4063 - val_length_output_loss: 4.1503\n",
      "Epoch 1159/1500\n",
      "7089/7089 [==============================] - 5s 661us/step - loss: 1.3934 - note_output_loss: 0.3394 - length_output_loss: 2.1079 - val_loss: 9.4825 - val_note_output_loss: 7.4053 - val_length_output_loss: 4.1544\n",
      "Epoch 1160/1500\n",
      "7089/7089 [==============================] - 6s 823us/step - loss: 1.3847 - note_output_loss: 0.3325 - length_output_loss: 2.1044 - val_loss: 9.4739 - val_note_output_loss: 7.3951 - val_length_output_loss: 4.1576\n",
      "Epoch 1161/1500\n",
      "7089/7089 [==============================] - 6s 816us/step - loss: 1.3924 - note_output_loss: 0.3431 - length_output_loss: 2.0986 - val_loss: 9.4728 - val_note_output_loss: 7.3942 - val_length_output_loss: 4.1572\n",
      "Epoch 1162/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.3814 - note_output_loss: 0.3333 - length_output_loss: 2.0960 - val_loss: 9.4700 - val_note_output_loss: 7.3957 - val_length_output_loss: 4.1485\n",
      "Epoch 1163/1500\n",
      "7089/7089 [==============================] - 5s 644us/step - loss: 1.3780 - note_output_loss: 0.3294 - length_output_loss: 2.0971 - val_loss: 9.5119 - val_note_output_loss: 7.4299 - val_length_output_loss: 4.1639\n",
      "Epoch 1164/1500\n",
      "7089/7089 [==============================] - 5s 648us/step - loss: 1.3774 - note_output_loss: 0.3293 - length_output_loss: 2.0963 - val_loss: 9.5140 - val_note_output_loss: 7.4345 - val_length_output_loss: 4.1592\n",
      "Epoch 1165/1500\n",
      "7089/7089 [==============================] - 5s 664us/step - loss: 1.3834 - note_output_loss: 0.3390 - length_output_loss: 2.0887 - val_loss: 9.4950 - val_note_output_loss: 7.4173 - val_length_output_loss: 4.1553\n",
      "Epoch 1166/1500\n",
      "7089/7089 [==============================] - 5s 656us/step - loss: 1.3834 - note_output_loss: 0.3336 - length_output_loss: 2.0996 - val_loss: 9.4976 - val_note_output_loss: 7.4202 - val_length_output_loss: 4.1548\n",
      "Epoch 1167/1500\n",
      "7089/7089 [==============================] - 5s 683us/step - loss: 1.3810 - note_output_loss: 0.3301 - length_output_loss: 2.1018 - val_loss: 9.4839 - val_note_output_loss: 7.4063 - val_length_output_loss: 4.1553\n",
      "Epoch 1168/1500\n",
      "7089/7089 [==============================] - 5s 668us/step - loss: 1.3716 - note_output_loss: 0.3252 - length_output_loss: 2.0929 - val_loss: 9.4896 - val_note_output_loss: 7.4115 - val_length_output_loss: 4.1562\n",
      "Epoch 1169/1500\n",
      "2560/7089 [=========>....................] - ETA: 2s - loss: 1.4012 - note_output_loss: 0.3378 - length_output_loss: 2.1267"
     ]
    }
   ],
   "source": [
    "logger('TRAINING')\n",
    "history = model.fit([note_x, note_name_x, interval_x, length_x], [note_y, length_y],\n",
    "          batch_size=batch_size,\n",
    "          epochs=1500,\n",
    "          validation_split=0.33,\n",
    "          callbacks=[\n",
    "#               listen_callback,\n",
    "              tensorboard,\n",
    "            ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_note_output_loss', 'val_length_output_loss', 'loss', 'note_output_loss', 'length_output_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_24.json and model_24.h5 to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'model_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
