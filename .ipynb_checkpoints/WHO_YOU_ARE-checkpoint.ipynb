{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from pandas import read_csv\n",
    "from Audio.Components.MidiPlayer import MidiPlayer\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from NN.networks.simple_model import create_model\n",
    "\n",
    "from Audio.Components.helpers.prepare_arrays import get_categorized_variables\n",
    "from Audio.Components.helpers.save_model import save_model\n",
    "from Audio.Components.helpers.make_encoded_prediction import make_encoded_prediction\n",
    "from Audio.Components.helpers.create_categorical_indicies import create_category_indicies, create_lookup_indicies\n",
    "from Audio.Components.helpers.generate_phrases import generate_phrases\n",
    "from Audio.Components.helpers.decode_predictions import decode_predictions\n",
    "from Audio.Components.helpers.play_generated_phrase import play_generated_phrase\n",
    "from Audio.Components.helpers.vectorize_phrases import vectorize_phrases\n",
    "from Audio.Components.helpers.logger import logger\n",
    "from Helpers.map_midi_to_note_number import map_midi_to_note_number\n",
    "from Helpers.map_midi_to_interval import map_midi_to_interval\n",
    "import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Danny Bus 1', 'Danny IAC Bus 2']\n"
     ]
    }
   ],
   "source": [
    "player = MidiPlayer()\n",
    "dropout = 0.5\n",
    "n_time_steps = constants.n_time_steps\n",
    "semi_redundancy_step = constants.semi_redundancy_step\n",
    "lstm_size = 24\n",
    "lr = constants.lr\n",
    "epochs = constants.epochs\n",
    "batch_size = constants.batch_size\n",
    "n_to_generate = constants.n_to_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            PREPROCESSING\n",
      "          **********************************\n",
      "corpus length: 10611\n"
     ]
    }
   ],
   "source": [
    "logger('PREPROCESSING')\n",
    "corpus = read_csv('Audio/data/input.csv', header=1)\n",
    "print('corpus length:', len(corpus))\n",
    "notes_corpus = corpus.values[:, 0]\n",
    "note_name_corpus = corpus.values[:, 1]\n",
    "interval_corpus = corpus.values[:, 2]\n",
    "length_corpus = corpus.values[:, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_variables = get_categorized_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_indicies = create_lookup_indicies(categorized_variables)\n",
    "\n",
    "note_phrases, next_note = generate_phrases(notes_corpus, n_time_steps, semi_redundancy_step)\n",
    "note_name_phrases, next_note_name = generate_phrases(note_name_corpus, n_time_steps, semi_redundancy_step)\n",
    "interval_phrases, next_interval = generate_phrases(interval_corpus, n_time_steps, semi_redundancy_step)\n",
    "length_phrases, next_length = generate_phrases(length_corpus, n_time_steps, semi_redundancy_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10581, 30, 128) note_x.shape\n",
      "(10581, 30, 141) length_x.shape\n",
      "(10581, 30, 49) interval_x.shape\n",
      "(10581, 30, 13) note_name_x.shape\n",
      "(10581, 128) note_y.shape\n",
      "(10581, 141) length_y.shape\n",
      "(10581, 49) interval_y.shape\n",
      "(10581, 13) note_name_y.shape\n"
     ]
    }
   ],
   "source": [
    "note_x, note_y = vectorize_phrases(\n",
    "    phrases=note_phrases,\n",
    "    n_categories=len(categorized_variables['note_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_index'],\n",
    "    next_lookup_index=next_note\n",
    "    )\n",
    "\n",
    "interval_x, interval_y = vectorize_phrases(\n",
    "    phrases=interval_phrases,\n",
    "    n_categories=len(categorized_variables['interval_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['interval_index'],\n",
    "    next_lookup_index=next_interval\n",
    ")\n",
    "\n",
    "note_name_x, note_name_y = vectorize_phrases(\n",
    "    phrases=note_name_phrases,\n",
    "    n_categories=len(categorized_variables['note_name_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['note_name_index'],\n",
    "    next_lookup_index=next_note_name\n",
    ")\n",
    "\n",
    "length_x, length_y = vectorize_phrases(\n",
    "    phrases=length_phrases,\n",
    "    n_categories=len(categorized_variables['length_categories']),\n",
    "    n_time_steps=n_time_steps,\n",
    "    lookup_index=lookup_indicies['length_index'],\n",
    "    next_lookup_index=next_length\n",
    ")\n",
    "\n",
    "print(note_x.shape, 'note_x.shape')\n",
    "print(length_x.shape, 'length_x.shape')\n",
    "print(interval_x.shape, 'interval_x.shape')\n",
    "print(note_name_x.shape, 'note_name_x.shape')\n",
    "print(note_y.shape, 'note_y.shape')\n",
    "print(length_y.shape, 'length_y.shape')\n",
    "print(interval_y.shape, 'interval_y.shape')\n",
    "print(note_name_y.shape, 'note_name_y.shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    categorized_variables=categorized_variables,\n",
    "    lstm_size=lstm_size,\n",
    "    lr=0.001,\n",
    "    n_time_steps=n_time_steps,\n",
    "    dropout=dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "note_input (InputLayer)         (None, 30, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "note_name_input (InputLayer)    (None, 30, 13)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "interval_input (InputLayer)     (None, 30, 49)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "length_input (InputLayer)       (None, 30, 141)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 30, 331)      0           note_input[0][0]                 \n",
      "                                                                 note_name_input[0][0]            \n",
      "                                                                 interval_input[0][0]             \n",
      "                                                                 length_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 30, 48)       68352       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 48)       0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 48)           14016       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "note_output (Dense)             (None, 128)          6272        bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "length_output (Dense)           (None, 141)          6909        bidirectional_12[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 95,549\n",
      "Trainable params: 95,549\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 709.91 410.00\" width=\"710pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 705.9106,-406 705.9106,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5268734192 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5268734192</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 145.4658,-401.5 145.4658,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"72.7329\" y=\"-379.3\">note_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5268737104 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5268737104</title>\n",
       "<polygon fill=\"none\" points=\"263.4136,-292.5 263.4136,-328.5 436.0522,-328.5 436.0522,-292.5 263.4136,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-306.3\">concatenate_6: Concatenate</text>\n",
       "</g>\n",
       "<!-- 5268734192&#45;&gt;5268737104 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5268734192-&gt;5268737104</title>\n",
       "<path d=\"M141.2048,-365.4551C180.6579,-355.0577 230.399,-341.949 271.4047,-331.1424\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"272.3108,-334.5232 281.0887,-328.5904 270.5269,-327.7544 272.3108,-334.5232\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5268736040 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5268736040</title>\n",
       "<polygon fill=\"none\" points=\"163.3413,-365.5 163.3413,-401.5 346.1245,-401.5 346.1245,-365.5 163.3413,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.7329\" y=\"-379.3\">note_name_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5268736040&#45;&gt;5268737104 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5268736040-&gt;5268737104</title>\n",
       "<path d=\"M278.2161,-365.4551C290.2054,-356.2422 304.965,-344.9006 317.956,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"320.3939,-337.4587 326.1907,-328.5904 316.1287,-331.9082 320.3939,-337.4587\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5268735256 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5268735256</title>\n",
       "<polygon fill=\"none\" points=\"363.6724,-365.5 363.6724,-401.5 527.7935,-401.5 527.7935,-365.5 363.6724,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445.7329\" y=\"-379.3\">interval_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5268735256&#45;&gt;5268737104 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5268735256-&gt;5268737104</title>\n",
       "<path d=\"M422.0026,-365.4551C409.887,-356.2422 394.9721,-344.9006 381.8443,-334.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"383.6016,-331.8573 373.523,-328.5904 379.3645,-337.4293 383.6016,-331.8573\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5268734584 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5268734584</title>\n",
       "<polygon fill=\"none\" points=\"545.5552,-365.5 545.5552,-401.5 701.9106,-401.5 701.9106,-365.5 545.5552,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.7329\" y=\"-379.3\">length_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5268734584&#45;&gt;5268737104 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5268734584-&gt;5268737104</title>\n",
       "<path d=\"M556.0026,-365.4551C517.0592,-355.0796 467.982,-342.0043 427.4696,-331.2109\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"428.1977,-327.7828 417.6337,-328.5904 426.3956,-334.5469 428.1977,-327.7828\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5268736880 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5268736880</title>\n",
       "<polygon fill=\"none\" points=\"205.5781,-219.5 205.5781,-255.5 493.8877,-255.5 493.8877,-219.5 205.5781,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-233.3\">bidirectional_11(lstm_11): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5268737104&#45;&gt;5268736880 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5268737104-&gt;5268736880</title>\n",
       "<path d=\"M349.7329,-292.4551C349.7329,-284.3828 349.7329,-274.6764 349.7329,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-265.5903 349.7329,-255.5904 346.233,-265.5904 353.233,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5133116416 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5133116416</title>\n",
       "<polygon fill=\"none\" points=\"285.9312,-146.5 285.9312,-182.5 413.5347,-182.5 413.5347,-146.5 285.9312,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-160.3\">dropout_6: Dropout</text>\n",
       "</g>\n",
       "<!-- 5268736880&#45;&gt;5133116416 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5268736880-&gt;5133116416</title>\n",
       "<path d=\"M349.7329,-219.4551C349.7329,-211.3828 349.7329,-201.6764 349.7329,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-192.5903 349.7329,-182.5904 346.233,-192.5904 353.233,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5270604880 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5270604880</title>\n",
       "<polygon fill=\"none\" points=\"205.0654,-73.5 205.0654,-109.5 494.4004,-109.5 494.4004,-73.5 205.0654,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.7329\" y=\"-87.3\">bidirectional_12(lstm_12): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5133116416&#45;&gt;5270604880 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5133116416-&gt;5270604880</title>\n",
       "<path d=\"M349.7329,-146.4551C349.7329,-138.3828 349.7329,-128.6764 349.7329,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.233,-119.5903 349.7329,-109.5904 346.233,-119.5904 353.233,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5271024136 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5271024136</title>\n",
       "<polygon fill=\"none\" points=\"213.1035,-.5 213.1035,-36.5 338.3623,-36.5 338.3623,-.5 213.1035,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.7329\" y=\"-14.3\">note_output: Dense</text>\n",
       "</g>\n",
       "<!-- 5270604880&#45;&gt;5271024136 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>5270604880-&gt;5271024136</title>\n",
       "<path d=\"M331.4408,-73.4551C322.3685,-64.5054 311.26,-53.547 301.3561,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"303.6481,-41.1215 294.0711,-36.5904 298.7321,-46.1049 303.6481,-41.1215\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5280840504 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>5280840504</title>\n",
       "<polygon fill=\"none\" points=\"356.6587,-.5 356.6587,-36.5 492.8071,-36.5 492.8071,-.5 356.6587,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.7329\" y=\"-14.3\">length_output: Dense</text>\n",
       "</g>\n",
       "<!-- 5270604880&#45;&gt;5280840504 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>5270604880-&gt;5280840504</title>\n",
       "<path d=\"M368.2722,-73.4551C377.4671,-64.5054 388.7258,-53.547 398.7634,-43.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"401.4221,-46.0734 406.1469,-36.5904 396.5397,-41.0572 401.4221,-46.0734\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.1\n",
    "\tdrop = 0.6\n",
    "\tepochs_drop = 25\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_callback(epoch, logs):\n",
    "    if epoch % 100 == 0 and epoch > -1: \n",
    "    # if epoch < -2:\n",
    "        print('----- Generating melody after Epoch: %d' % epoch)\n",
    "        \n",
    "        start_index = random.randint(0, 7000)\n",
    "        for diversity in [0.5]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            current_note_phrase = notes_corpus[start_index: start_index + n_time_steps]\n",
    "            current_interval_phrase = interval_corpus[start_index: start_index + n_time_steps]\n",
    "            current_note_name_phrase = note_name_corpus[start_index: start_index + n_time_steps]\n",
    "            current_length_phrase = length_corpus[start_index: start_index + n_time_steps]\n",
    "\n",
    "            phrases = {\n",
    "                'note_phrase': current_note_phrase, \n",
    "                'length_phrase': current_length_phrase,\n",
    "                'interval_phrase': current_interval_phrase,\n",
    "                'note_name_phrase': current_note_name_phrase,\n",
    "            }\n",
    "\n",
    "            generated_notes = []\n",
    "            generated_lengths = []\n",
    "            generated_notes.extend(current_note_phrase)\n",
    "            generated_lengths.extend(current_length_phrase)\n",
    "\n",
    "            # model, phrases,categorized_variables, lookup_indicies, n_time_steps, diversity, n_to_generate\n",
    "            for step in range(70):\n",
    "                encoded_prediction = make_encoded_prediction(\n",
    "                    model=model,\n",
    "                    phrases=phrases,\n",
    "                    categorized_variables=categorized_variables,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    n_time_steps=n_time_steps\n",
    "                )\n",
    "\n",
    "                predictions = decode_predictions(\n",
    "                    encoded_prediction=encoded_prediction,\n",
    "                    lookup_indicies=lookup_indicies,\n",
    "                    temperature=diversity\n",
    "                )\n",
    "\n",
    "                generated_notes.append(predictions['note_prediction']) \n",
    "                generated_lengths.append(predictions['length_prediction']) \n",
    "\n",
    "\n",
    "                last = generated_notes[0]\n",
    "                phrases['note_phrase'] = np.append(phrases['note_phrase'][1:], predictions['note_prediction'])\n",
    "                phrases['interval_phrase'] = map_midi_to_interval(phrases['note_phrase'], last)\n",
    "                phrases['note_name_phrase'] = map_midi_to_note_number(phrases['note_phrase'])\n",
    "                phrases['length_phrase'] = np.append(phrases['length_phrase'][1:], predictions['length_prediction'])\n",
    "\n",
    "                print\n",
    "                \n",
    "            play_generated_phrase(\n",
    "                generated_notes=generated_notes[10:],\n",
    "                generated_lengths=generated_lengths[10:],\n",
    "                player=player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(datetime.datetime.now()), histogram_freq=0, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "listen_callback = LambdaCallback(on_epoch_end=listen_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          **********************************\n",
      "            TRAINING\n",
      "          **********************************\n",
      "Epoch 1/1500\n",
      "10581/10581 [==============================] - 11s 1ms/step - loss: 5.6961 - note_output_loss: 3.7594 - length_output_loss: 3.8734\n",
      "----- Generating melody after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "59.0 | 0.09\n",
      "58.0 | 0.37\n",
      "59.0 | 0.23\n",
      "65.0 | 0.37\n",
      "64.0 | 0.42\n",
      "62.0 | 0.33\n",
      "60.0 | 0.37\n",
      "65.0 | 0.6\n",
      "0 | 0.56\n",
      "57.0 | 0.88\n",
      "64.0 | 0.42\n",
      "62.0 | 0.28\n",
      "60.0 | 0.28\n",
      "59.0 | 0.42\n",
      "63.0 | 0.33\n",
      "64.0 | 0.28\n",
      "55.0 | 0.74\n",
      "0 | 0.7\n",
      "62.0 | 0.28\n",
      "60.0 | 0.23\n",
      "59 | 0.33\n",
      "62 | 0.6\n",
      "59 | 0.37\n",
      "66 | 0.37\n",
      "59 | 0.28\n",
      "0 | 0.42\n",
      "56 | 0.93\n",
      "63 | 0.56\n",
      "65 | 0.33\n",
      "57 | 0.33\n",
      "50 | 0.33\n",
      "0 | 0.23\n",
      "58 | 0.23\n",
      "62 | 0.28\n",
      "60 | 0.42\n",
      "56 | 0.33\n",
      "63 | 0.28\n",
      "56 | 0.28\n",
      "62 | 0.28\n",
      "58 | 0.33\n",
      "72 | 0.09\n",
      "70 | 0.33\n",
      "58 | 0.56\n",
      "57 | 0.33\n",
      "0 | 0.28\n",
      "62 | 0.46\n",
      "0 | 0.33\n",
      "57 | 0.14\n",
      "54 | 0.33\n",
      "60 | 0.28\n",
      "61 | 0.28\n",
      "0 | 0.28\n",
      "62 | 0.42\n",
      "0 | 0.51\n",
      "0 | 0.37\n",
      "0 | 0.33\n",
      "0 | 0.37\n",
      "64 | 0.33\n",
      "64 | 0.42\n",
      "54 | 0.28\n",
      "58 | 0.28\n",
      "62 | 0.28\n",
      "66 | 0.37\n",
      "62 | 0.37\n",
      "58 | 0.14\n",
      "57 | 0.33\n",
      "56 | 0.28\n",
      "0 | 0.33\n",
      "0 | 0.28\n",
      "58 | 0.05\n",
      "62 | 0.33\n",
      "61 | 0.37\n",
      "59 | 0.51\n",
      "58 | 0.28\n",
      "68 | 0.51\n",
      "0 | 0.33\n",
      "60 | 0.05\n",
      "63 | 0.33\n",
      "0 | 0.23\n",
      "62 | 0.14\n",
      "62 | 0.51\n",
      "64 | 0.05\n",
      "61 | 0.28\n",
      "68 | 0.33\n",
      "53 | 0.33\n",
      "54 | 0.33\n",
      "65 | 0.46\n",
      "0 | 0.37\n",
      "56 | 0.79\n",
      "62 | 0.37\n",
      "Epoch 2/1500\n",
      "10581/10581 [==============================] - 6s 577us/step - loss: 4.8156 - note_output_loss: 3.2078 - length_output_loss: 3.2155\n",
      "Epoch 3/1500\n",
      "10581/10581 [==============================] - 6s 588us/step - loss: 4.7700 - note_output_loss: 3.1783 - length_output_loss: 3.1834\n",
      "Epoch 4/1500\n",
      "10581/10581 [==============================] - 6s 589us/step - loss: 4.7591 - note_output_loss: 3.1706 - length_output_loss: 3.1770\n",
      "Epoch 5/1500\n",
      "10581/10581 [==============================] - 6s 596us/step - loss: 4.7504 - note_output_loss: 3.1641 - length_output_loss: 3.1726\n",
      "Epoch 6/1500\n",
      "10581/10581 [==============================] - 6s 599us/step - loss: 4.7188 - note_output_loss: 3.1372 - length_output_loss: 3.1632\n",
      "Epoch 7/1500\n",
      "10581/10581 [==============================] - 6s 609us/step - loss: 4.6636 - note_output_loss: 3.0867 - length_output_loss: 3.1538\n",
      "Epoch 8/1500\n",
      "10581/10581 [==============================] - 6s 601us/step - loss: 4.6068 - note_output_loss: 3.0309 - length_output_loss: 3.1518\n",
      "Epoch 9/1500\n",
      "10581/10581 [==============================] - 6s 599us/step - loss: 4.5491 - note_output_loss: 2.9752 - length_output_loss: 3.1477\n",
      "Epoch 10/1500\n",
      "10581/10581 [==============================] - 6s 606us/step - loss: 4.4932 - note_output_loss: 2.9195 - length_output_loss: 3.1475\n",
      "Epoch 11/1500\n",
      "10581/10581 [==============================] - 6s 614us/step - loss: 4.4481 - note_output_loss: 2.8743 - length_output_loss: 3.1476\n",
      "Epoch 12/1500\n",
      "10581/10581 [==============================] - 6s 608us/step - loss: 4.4034 - note_output_loss: 2.8314 - length_output_loss: 3.1441\n",
      "Epoch 13/1500\n",
      "10581/10581 [==============================] - 6s 611us/step - loss: 4.3655 - note_output_loss: 2.7949 - length_output_loss: 3.1413\n",
      "Epoch 14/1500\n",
      "10581/10581 [==============================] - 8s 738us/step - loss: 4.3240 - note_output_loss: 2.7552 - length_output_loss: 3.1374\n",
      "Epoch 15/1500\n",
      "10581/10581 [==============================] - 7s 651us/step - loss: 4.2904 - note_output_loss: 2.7263 - length_output_loss: 3.1283\n",
      "Epoch 16/1500\n",
      "10581/10581 [==============================] - 6s 612us/step - loss: 4.2570 - note_output_loss: 2.6956 - length_output_loss: 3.1229\n",
      "Epoch 17/1500\n",
      "10581/10581 [==============================] - 7s 617us/step - loss: 4.2282 - note_output_loss: 2.6700 - length_output_loss: 3.1163\n",
      "Epoch 18/1500\n",
      "10581/10581 [==============================] - 7s 625us/step - loss: 4.1980 - note_output_loss: 2.6449 - length_output_loss: 3.1061\n",
      "Epoch 19/1500\n",
      "10581/10581 [==============================] - 7s 639us/step - loss: 4.1700 - note_output_loss: 2.6203 - length_output_loss: 3.0996\n",
      "Epoch 20/1500\n",
      "10581/10581 [==============================] - 6s 609us/step - loss: 4.1490 - note_output_loss: 2.6031 - length_output_loss: 3.0920\n",
      "Epoch 21/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 4.1285 - note_output_loss: 2.5859 - length_output_loss: 3.0852\n",
      "Epoch 22/1500\n",
      "10581/10581 [==============================] - 7s 627us/step - loss: 4.1108 - note_output_loss: 2.5718 - length_output_loss: 3.0780\n",
      "Epoch 23/1500\n",
      "10581/10581 [==============================] - 7s 637us/step - loss: 4.0941 - note_output_loss: 2.5558 - length_output_loss: 3.0767\n",
      "Epoch 24/1500\n",
      "10581/10581 [==============================] - 7s 620us/step - loss: 4.0768 - note_output_loss: 2.5432 - length_output_loss: 3.0673\n",
      "Epoch 25/1500\n",
      "10581/10581 [==============================] - 7s 619us/step - loss: 4.0624 - note_output_loss: 2.5301 - length_output_loss: 3.0646\n",
      "Epoch 26/1500\n",
      "10581/10581 [==============================] - 7s 629us/step - loss: 4.0466 - note_output_loss: 2.5165 - length_output_loss: 3.0603\n",
      "Epoch 27/1500\n",
      "10581/10581 [==============================] - 7s 617us/step - loss: 4.0302 - note_output_loss: 2.5029 - length_output_loss: 3.0545\n",
      "Epoch 28/1500\n",
      "10581/10581 [==============================] - 7s 618us/step - loss: 4.0203 - note_output_loss: 2.4943 - length_output_loss: 3.0521\n",
      "Epoch 29/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 4.0075 - note_output_loss: 2.4822 - length_output_loss: 3.0506\n",
      "Epoch 30/1500\n",
      "10581/10581 [==============================] - 7s 703us/step - loss: 3.9984 - note_output_loss: 2.4751 - length_output_loss: 3.0465\n",
      "Epoch 31/1500\n",
      "10581/10581 [==============================] - 7s 617us/step - loss: 3.9860 - note_output_loss: 2.4643 - length_output_loss: 3.0434\n",
      "Epoch 32/1500\n",
      "10581/10581 [==============================] - 7s 656us/step - loss: 3.9711 - note_output_loss: 2.4513 - length_output_loss: 3.0397\n",
      "Epoch 33/1500\n",
      "10581/10581 [==============================] - 7s 654us/step - loss: 3.9673 - note_output_loss: 2.4468 - length_output_loss: 3.0409\n",
      "Epoch 34/1500\n",
      "10581/10581 [==============================] - 7s 630us/step - loss: 3.9553 - note_output_loss: 2.4378 - length_output_loss: 3.0351\n",
      "Epoch 35/1500\n",
      "10581/10581 [==============================] - 7s 642us/step - loss: 3.9400 - note_output_loss: 2.4238 - length_output_loss: 3.0322\n",
      "Epoch 36/1500\n",
      "10581/10581 [==============================] - 7s 634us/step - loss: 3.9324 - note_output_loss: 2.4180 - length_output_loss: 3.0289\n",
      "Epoch 37/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 3.9209 - note_output_loss: 2.4074 - length_output_loss: 3.0271\n",
      "Epoch 38/1500\n",
      "10581/10581 [==============================] - 7s 656us/step - loss: 3.9103 - note_output_loss: 2.3998 - length_output_loss: 3.0210\n",
      "Epoch 39/1500\n",
      "10581/10581 [==============================] - 7s 623us/step - loss: 3.9007 - note_output_loss: 2.3899 - length_output_loss: 3.0218\n",
      "Epoch 40/1500\n",
      "10581/10581 [==============================] - 7s 633us/step - loss: 3.8954 - note_output_loss: 2.3861 - length_output_loss: 3.0186\n",
      "Epoch 41/1500\n",
      "10581/10581 [==============================] - 6s 594us/step - loss: 3.8834 - note_output_loss: 2.3755 - length_output_loss: 3.0157\n",
      "Epoch 42/1500\n",
      "10581/10581 [==============================] - 5s 492us/step - loss: 3.8747 - note_output_loss: 2.3678 - length_output_loss: 3.0137\n",
      "Epoch 43/1500\n",
      "10581/10581 [==============================] - 6s 524us/step - loss: 3.8661 - note_output_loss: 2.3596 - length_output_loss: 3.0129\n",
      "Epoch 44/1500\n",
      "10581/10581 [==============================] - 6s 610us/step - loss: 3.8532 - note_output_loss: 2.3482 - length_output_loss: 3.0099\n",
      "Epoch 45/1500\n",
      "10581/10581 [==============================] - 7s 632us/step - loss: 3.8458 - note_output_loss: 2.3427 - length_output_loss: 3.0061\n",
      "Epoch 46/1500\n",
      "10581/10581 [==============================] - 6s 606us/step - loss: 3.8430 - note_output_loss: 2.3400 - length_output_loss: 3.0061\n",
      "Epoch 47/1500\n",
      "10581/10581 [==============================] - 7s 617us/step - loss: 3.8300 - note_output_loss: 2.3274 - length_output_loss: 3.0051\n",
      "Epoch 48/1500\n",
      "10581/10581 [==============================] - 7s 621us/step - loss: 3.8238 - note_output_loss: 2.3238 - length_output_loss: 2.9999\n",
      "Epoch 49/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10581/10581 [==============================] - 7s 628us/step - loss: 3.8167 - note_output_loss: 2.3159 - length_output_loss: 3.0016\n",
      "Epoch 50/1500\n",
      "10581/10581 [==============================] - 7s 646us/step - loss: 3.8059 - note_output_loss: 2.3057 - length_output_loss: 3.0005\n",
      "Epoch 51/1500\n",
      "10581/10581 [==============================] - 7s 625us/step - loss: 3.8033 - note_output_loss: 2.3061 - length_output_loss: 2.9944\n",
      "Epoch 52/1500\n",
      "10581/10581 [==============================] - 7s 624us/step - loss: 3.7852 - note_output_loss: 2.2883 - length_output_loss: 2.9939\n",
      "Epoch 53/1500\n",
      "10581/10581 [==============================] - 7s 635us/step - loss: 3.7824 - note_output_loss: 2.2847 - length_output_loss: 2.9953\n",
      "Epoch 54/1500\n",
      "10581/10581 [==============================] - 7s 638us/step - loss: 3.7740 - note_output_loss: 2.2781 - length_output_loss: 2.9918\n",
      "Epoch 55/1500\n",
      "10581/10581 [==============================] - 7s 631us/step - loss: 3.7692 - note_output_loss: 2.2746 - length_output_loss: 2.9892\n",
      "Epoch 56/1500\n",
      "10581/10581 [==============================] - 7s 615us/step - loss: 3.7601 - note_output_loss: 2.2655 - length_output_loss: 2.9892\n",
      "Epoch 57/1500\n",
      "10581/10581 [==============================] - 8s 734us/step - loss: 3.7544 - note_output_loss: 2.2605 - length_output_loss: 2.9877\n",
      "Epoch 58/1500\n",
      "10581/10581 [==============================] - 7s 648us/step - loss: 3.7516 - note_output_loss: 2.2586 - length_output_loss: 2.9859\n",
      "Epoch 59/1500\n",
      "10581/10581 [==============================] - 7s 647us/step - loss: 3.7417 - note_output_loss: 2.2500 - length_output_loss: 2.9835\n",
      "Epoch 60/1500\n",
      "10581/10581 [==============================] - 7s 644us/step - loss: 3.7330 - note_output_loss: 2.2425 - length_output_loss: 2.9811\n",
      "Epoch 61/1500\n",
      "10581/10581 [==============================] - 7s 618us/step - loss: 3.7226 - note_output_loss: 2.2319 - length_output_loss: 2.9814\n",
      "Epoch 62/1500\n",
      "10581/10581 [==============================] - 7s 623us/step - loss: 3.7184 - note_output_loss: 2.2292 - length_output_loss: 2.9785\n",
      "Epoch 63/1500\n",
      "10581/10581 [==============================] - 7s 647us/step - loss: 3.7177 - note_output_loss: 2.2288 - length_output_loss: 2.9778\n",
      "Epoch 64/1500\n",
      "10581/10581 [==============================] - 7s 642us/step - loss: 3.7086 - note_output_loss: 2.2205 - length_output_loss: 2.9761\n",
      "Epoch 65/1500\n",
      "10581/10581 [==============================] - 7s 637us/step - loss: 3.6964 - note_output_loss: 2.2097 - length_output_loss: 2.9735\n",
      "Epoch 66/1500\n",
      "10581/10581 [==============================] - 7s 623us/step - loss: 3.6899 - note_output_loss: 2.2036 - length_output_loss: 2.9726\n",
      "Epoch 67/1500\n",
      "10581/10581 [==============================] - 7s 640us/step - loss: 3.6819 - note_output_loss: 2.1945 - length_output_loss: 2.9747\n",
      "Epoch 68/1500\n",
      "10581/10581 [==============================] - 7s 640us/step - loss: 3.6797 - note_output_loss: 2.1950 - length_output_loss: 2.9694\n",
      "Epoch 69/1500\n",
      "10581/10581 [==============================] - 7s 655us/step - loss: 3.6746 - note_output_loss: 2.1905 - length_output_loss: 2.9682\n",
      "Epoch 70/1500\n",
      "10581/10581 [==============================] - 6s 608us/step - loss: 3.6712 - note_output_loss: 2.1881 - length_output_loss: 2.9662\n",
      "Epoch 71/1500\n",
      "10581/10581 [==============================] - 7s 657us/step - loss: 3.6625 - note_output_loss: 2.1805 - length_output_loss: 2.9640\n",
      "Epoch 72/1500\n",
      "10581/10581 [==============================] - 7s 628us/step - loss: 3.6598 - note_output_loss: 2.1779 - length_output_loss: 2.9636\n",
      "Epoch 73/1500\n",
      "10581/10581 [==============================] - 7s 645us/step - loss: 3.6437 - note_output_loss: 2.1626 - length_output_loss: 2.9620\n",
      "Epoch 74/1500\n",
      "10581/10581 [==============================] - 7s 680us/step - loss: 3.6445 - note_output_loss: 2.1644 - length_output_loss: 2.9601\n",
      "Epoch 75/1500\n",
      "10581/10581 [==============================] - 7s 636us/step - loss: 3.6421 - note_output_loss: 2.1618 - length_output_loss: 2.9606\n",
      "Epoch 76/1500\n",
      "10581/10581 [==============================] - 7s 630us/step - loss: 3.6307 - note_output_loss: 2.1513 - length_output_loss: 2.9588\n",
      "Epoch 77/1500\n",
      "10581/10581 [==============================] - 7s 635us/step - loss: 3.6224 - note_output_loss: 2.1444 - length_output_loss: 2.9559\n",
      "Epoch 78/1500\n",
      "10581/10581 [==============================] - 7s 643us/step - loss: 3.6192 - note_output_loss: 2.1429 - length_output_loss: 2.9527\n",
      "Epoch 79/1500\n",
      "10581/10581 [==============================] - 7s 639us/step - loss: 3.6165 - note_output_loss: 2.1404 - length_output_loss: 2.9522\n",
      "Epoch 80/1500\n",
      "10581/10581 [==============================] - 7s 642us/step - loss: 3.6137 - note_output_loss: 2.1364 - length_output_loss: 2.9546\n",
      "Epoch 81/1500\n",
      "10581/10581 [==============================] - 7s 638us/step - loss: 3.6028 - note_output_loss: 2.1274 - length_output_loss: 2.9507\n",
      "Epoch 82/1500\n",
      "10581/10581 [==============================] - 7s 649us/step - loss: 3.5974 - note_output_loss: 2.1224 - length_output_loss: 2.9500\n",
      "Epoch 83/1500\n",
      "10581/10581 [==============================] - 7s 641us/step - loss: 3.6002 - note_output_loss: 2.1268 - length_output_loss: 2.9467\n",
      "Epoch 84/1500\n",
      "10581/10581 [==============================] - 6s 613us/step - loss: 3.5883 - note_output_loss: 2.1159 - length_output_loss: 2.9449\n",
      "Epoch 85/1500\n",
      "10581/10581 [==============================] - 7s 647us/step - loss: 3.5851 - note_output_loss: 2.1118 - length_output_loss: 2.9466\n",
      "Epoch 86/1500\n",
      "10581/10581 [==============================] - 6s 614us/step - loss: 3.5793 - note_output_loss: 2.1074 - length_output_loss: 2.9437\n",
      "Epoch 87/1500\n",
      "10581/10581 [==============================] - 7s 629us/step - loss: 3.5666 - note_output_loss: 2.0968 - length_output_loss: 2.9397\n",
      "Epoch 88/1500\n",
      "10581/10581 [==============================] - 7s 635us/step - loss: 3.5743 - note_output_loss: 2.1029 - length_output_loss: 2.9427\n",
      "Epoch 89/1500\n",
      "10581/10581 [==============================] - 7s 654us/step - loss: 3.5583 - note_output_loss: 2.0887 - length_output_loss: 2.9392\n",
      "Epoch 90/1500\n",
      "10581/10581 [==============================] - 7s 647us/step - loss: 3.5563 - note_output_loss: 2.0872 - length_output_loss: 2.9381\n",
      "Epoch 91/1500\n",
      "10581/10581 [==============================] - 7s 625us/step - loss: 3.5492 - note_output_loss: 2.0812 - length_output_loss: 2.9359\n",
      "Epoch 92/1500\n",
      "10581/10581 [==============================] - 7s 620us/step - loss: 3.5458 - note_output_loss: 2.0780 - length_output_loss: 2.9356\n",
      "Epoch 93/1500\n",
      "10581/10581 [==============================] - 7s 615us/step - loss: 3.5468 - note_output_loss: 2.0791 - length_output_loss: 2.9354\n",
      "Epoch 94/1500\n",
      "10581/10581 [==============================] - 7s 633us/step - loss: 3.5375 - note_output_loss: 2.0722 - length_output_loss: 2.9308\n",
      "Epoch 95/1500\n",
      "10581/10581 [==============================] - 7s 627us/step - loss: 3.5313 - note_output_loss: 2.0649 - length_output_loss: 2.9327\n",
      "Epoch 96/1500\n",
      "10581/10581 [==============================] - 7s 631us/step - loss: 3.5216 - note_output_loss: 2.0560 - length_output_loss: 2.9312\n",
      "Epoch 97/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 3.5232 - note_output_loss: 2.0588 - length_output_loss: 2.9288\n",
      "Epoch 98/1500\n",
      "10581/10581 [==============================] - 7s 650us/step - loss: 3.5174 - note_output_loss: 2.0530 - length_output_loss: 2.9290\n",
      "Epoch 99/1500\n",
      "10581/10581 [==============================] - 7s 645us/step - loss: 3.5080 - note_output_loss: 2.0452 - length_output_loss: 2.9255\n",
      "Epoch 100/1500\n",
      "10581/10581 [==============================] - 7s 645us/step - loss: 3.5053 - note_output_loss: 2.0435 - length_output_loss: 2.9236\n",
      "Epoch 101/1500\n",
      "10581/10581 [==============================] - 7s 636us/step - loss: 3.4979 - note_output_loss: 2.0369 - length_output_loss: 2.9219\n",
      "----- Generating melody after Epoch: 100\n",
      "----- diversity: 0.5\n",
      "63.0 | 0.19\n",
      "67.0 | 0.09\n",
      "66.0 | 0.14\n",
      "67.0 | 0.05\n",
      "66.0 | 0.32\n",
      "0 | 0.23\n",
      "57.0 | 0.88\n",
      "0 | 1.5\n",
      "58.0 | 0.6\n",
      "62.0 | 0.23\n",
      "60.0 | 0.23\n",
      "58.0 | 0.65\n",
      "53.0 | 0.51\n",
      "55.0 | 0.37\n",
      "62.0 | 0.14\n",
      "60.0 | 0.28\n",
      "58.0 | 0.6\n",
      "55.0 | 0.88\n",
      "0 | 0.05\n",
      "57.0 | 0.14\n",
      "57 | 0.42\n",
      "60 | 0.33\n",
      "58 | 0.37\n",
      "55 | 0.33\n",
      "58 | 0.37\n",
      "60 | 0.33\n",
      "58 | 0.37\n",
      "60 | 0.46\n",
      "58 | 0.33\n",
      "55 | 0.23\n",
      "51 | 0.33\n",
      "48 | 0.33\n",
      "48 | 0.46\n",
      "48 | 0.37\n",
      "53 | 0.33\n",
      "57 | 0.42\n",
      "58 | 0.37\n",
      "55 | 0.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 | 0.7\n",
      "0 | 0.88\n",
      "57 | 0.33\n",
      "62 | 0.46\n",
      "60 | 0.46\n",
      "57 | 0.6\n",
      "60 | 0.51\n",
      "62 | 0.65\n",
      "0 | 0.51\n",
      "0 | 0.65\n",
      "58 | 0.42\n",
      "58 | 0.33\n",
      "60 | 0.33\n",
      "62 | 0.28\n",
      "63 | 0.42\n",
      "67 | 0.33\n",
      "72 | 0.28\n",
      "72 | 0.51\n",
      "70 | 0.42\n",
      "65 | 0.37\n",
      "58 | 0.42\n",
      "57 | 0.46\n",
      "51 | 0.37\n",
      "55 | 0.37\n",
      "58 | 0.33\n",
      "60 | 0.37\n",
      "58 | 0.33\n",
      "58 | 0.37\n",
      "60 | 0.37\n",
      "58 | 0.33\n",
      "57 | 0.37\n",
      "57 | 0.23\n",
      "60 | 0.37\n",
      "62 | 0.37\n",
      "67 | 0.42\n",
      "65 | 0.37\n",
      "62 | 0.37\n",
      "58 | 0.37\n",
      "60 | 0.42\n",
      "58 | 0.19\n",
      "60 | 0.28\n",
      "58 | 0.33\n",
      "55 | 0.42\n",
      "58 | 0.37\n",
      "56 | 0.23\n",
      "58 | 0.23\n",
      "58 | 0.23\n",
      "56 | 0.33\n",
      "53 | 0.37\n",
      "53 | 0.28\n",
      "55 | 0.33\n",
      "60 | 0.28\n",
      "Epoch 102/1500\n",
      "10581/10581 [==============================] - 6s 594us/step - loss: 3.4965 - note_output_loss: 2.0370 - length_output_loss: 2.9190\n",
      "Epoch 103/1500\n",
      "10581/10581 [==============================] - 7s 617us/step - loss: 3.4885 - note_output_loss: 2.0280 - length_output_loss: 2.9210\n",
      "Epoch 104/1500\n",
      "10581/10581 [==============================] - 7s 630us/step - loss: 3.4872 - note_output_loss: 2.0258 - length_output_loss: 2.9228\n",
      "Epoch 105/1500\n",
      "10581/10581 [==============================] - 6s 606us/step - loss: 3.4838 - note_output_loss: 2.0237 - length_output_loss: 2.9202\n",
      "Epoch 106/1500\n",
      "10581/10581 [==============================] - 6s 613us/step - loss: 3.4806 - note_output_loss: 2.0225 - length_output_loss: 2.9163\n",
      "Epoch 107/1500\n",
      "10581/10581 [==============================] - 7s 621us/step - loss: 3.4709 - note_output_loss: 2.0129 - length_output_loss: 2.9160\n",
      "Epoch 108/1500\n",
      "10581/10581 [==============================] - 7s 641us/step - loss: 3.4684 - note_output_loss: 2.0120 - length_output_loss: 2.9130\n",
      "Epoch 109/1500\n",
      "10581/10581 [==============================] - 7s 616us/step - loss: 3.4638 - note_output_loss: 2.0081 - length_output_loss: 2.9112\n",
      "Epoch 110/1500\n",
      "10581/10581 [==============================] - 7s 630us/step - loss: 3.4642 - note_output_loss: 2.0056 - length_output_loss: 2.9171\n",
      "Epoch 111/1500\n",
      "10581/10581 [==============================] - 7s 634us/step - loss: 3.4577 - note_output_loss: 2.0021 - length_output_loss: 2.9112\n",
      "Epoch 112/1500\n",
      "10581/10581 [==============================] - 7s 632us/step - loss: 3.4557 - note_output_loss: 1.9980 - length_output_loss: 2.9154\n",
      "Epoch 113/1500\n",
      "10581/10581 [==============================] - 6s 598us/step - loss: 3.4521 - note_output_loss: 1.9961 - length_output_loss: 2.9120\n",
      "Epoch 114/1500\n",
      "10581/10581 [==============================] - 5s 492us/step - loss: 3.4447 - note_output_loss: 1.9904 - length_output_loss: 2.9087\n",
      "Epoch 115/1500\n",
      "10581/10581 [==============================] - 5s 490us/step - loss: 3.4424 - note_output_loss: 1.9884 - length_output_loss: 2.9080\n",
      "Epoch 116/1500\n",
      "10581/10581 [==============================] - 5s 492us/step - loss: 3.4371 - note_output_loss: 1.9836 - length_output_loss: 2.9070\n",
      "Epoch 117/1500\n",
      "10581/10581 [==============================] - 5s 489us/step - loss: 3.4333 - note_output_loss: 1.9802 - length_output_loss: 2.9062\n",
      "Epoch 118/1500\n",
      "10581/10581 [==============================] - 5s 499us/step - loss: 3.4319 - note_output_loss: 1.9791 - length_output_loss: 2.9055\n",
      "Epoch 119/1500\n",
      "10581/10581 [==============================] - 5s 493us/step - loss: 3.4170 - note_output_loss: 1.9658 - length_output_loss: 2.9025\n",
      "Epoch 120/1500\n",
      "10581/10581 [==============================] - 5s 490us/step - loss: 3.4156 - note_output_loss: 1.9657 - length_output_loss: 2.8998\n",
      "Epoch 121/1500\n",
      "10581/10581 [==============================] - 5s 487us/step - loss: 3.4058 - note_output_loss: 1.9562 - length_output_loss: 2.8993\n",
      "Epoch 122/1500\n",
      "10581/10581 [==============================] - 6s 530us/step - loss: 3.4135 - note_output_loss: 1.9647 - length_output_loss: 2.8976\n",
      "Epoch 123/1500\n",
      "10581/10581 [==============================] - 5s 497us/step - loss: 3.3959 - note_output_loss: 1.9464 - length_output_loss: 2.8991\n",
      "Epoch 124/1500\n",
      "10581/10581 [==============================] - 5s 496us/step - loss: 3.4024 - note_output_loss: 1.9520 - length_output_loss: 2.9009\n",
      "Epoch 125/1500\n",
      "10581/10581 [==============================] - 5s 491us/step - loss: 3.3986 - note_output_loss: 1.9497 - length_output_loss: 2.8977\n",
      "Epoch 126/1500\n",
      "10581/10581 [==============================] - 5s 482us/step - loss: 3.3981 - note_output_loss: 1.9489 - length_output_loss: 2.8985\n",
      "Epoch 127/1500\n",
      "10581/10581 [==============================] - 5s 484us/step - loss: 3.3935 - note_output_loss: 1.9451 - length_output_loss: 2.8968\n",
      "Epoch 128/1500\n",
      "10581/10581 [==============================] - 5s 496us/step - loss: 3.3844 - note_output_loss: 1.9369 - length_output_loss: 2.8949\n",
      "Epoch 129/1500\n",
      "10581/10581 [==============================] - 5s 476us/step - loss: 3.3805 - note_output_loss: 1.9327 - length_output_loss: 2.8956\n",
      "Epoch 130/1500\n",
      "10581/10581 [==============================] - 5s 493us/step - loss: 3.3754 - note_output_loss: 1.9280 - length_output_loss: 2.8949\n",
      "Epoch 131/1500\n",
      "10581/10581 [==============================] - 5s 500us/step - loss: 3.3778 - note_output_loss: 1.9316 - length_output_loss: 2.8925\n",
      "Epoch 132/1500\n",
      "10581/10581 [==============================] - 5s 505us/step - loss: 3.3714 - note_output_loss: 1.9248 - length_output_loss: 2.8931\n",
      "Epoch 133/1500\n",
      "10581/10581 [==============================] - 5s 489us/step - loss: 3.3634 - note_output_loss: 1.9189 - length_output_loss: 2.8891\n",
      "Epoch 134/1500\n",
      "10581/10581 [==============================] - 5s 492us/step - loss: 3.3593 - note_output_loss: 1.9128 - length_output_loss: 2.8930\n",
      "Epoch 135/1500\n",
      "10581/10581 [==============================] - 5s 501us/step - loss: 3.3573 - note_output_loss: 1.9146 - length_output_loss: 2.8853\n",
      "Epoch 136/1500\n",
      "10581/10581 [==============================] - 5s 494us/step - loss: 3.3531 - note_output_loss: 1.9082 - length_output_loss: 2.8898\n",
      "Epoch 137/1500\n",
      "10581/10581 [==============================] - 5s 497us/step - loss: 3.3472 - note_output_loss: 1.9035 - length_output_loss: 2.8874\n",
      "Epoch 138/1500\n",
      "10581/10581 [==============================] - 5s 486us/step - loss: 3.3468 - note_output_loss: 1.9041 - length_output_loss: 2.8855\n",
      "Epoch 139/1500\n",
      "10581/10581 [==============================] - 5s 484us/step - loss: 3.3467 - note_output_loss: 1.9065 - length_output_loss: 2.8805\n",
      "Epoch 140/1500\n",
      "10581/10581 [==============================] - 5s 488us/step - loss: 3.3360 - note_output_loss: 1.8941 - length_output_loss: 2.8837\n",
      "Epoch 141/1500\n",
      "10581/10581 [==============================] - 5s 490us/step - loss: 3.3324 - note_output_loss: 1.8917 - length_output_loss: 2.8815\n",
      "Epoch 142/1500\n",
      "10581/10581 [==============================] - 5s 485us/step - loss: 3.3382 - note_output_loss: 1.8976 - length_output_loss: 2.8811\n",
      "Epoch 143/1500\n",
      "10581/10581 [==============================] - 5s 510us/step - loss: 3.3246 - note_output_loss: 1.8839 - length_output_loss: 2.8814\n",
      "Epoch 144/1500\n",
      "10581/10581 [==============================] - 5s 485us/step - loss: 3.3276 - note_output_loss: 1.8885 - length_output_loss: 2.8782\n",
      "Epoch 145/1500\n",
      "10581/10581 [==============================] - 5s 485us/step - loss: 3.3181 - note_output_loss: 1.8789 - length_output_loss: 2.8783\n",
      "Epoch 146/1500\n",
      "10581/10581 [==============================] - 5s 498us/step - loss: 3.3092 - note_output_loss: 1.8717 - length_output_loss: 2.8750\n",
      "Epoch 147/1500\n",
      "10581/10581 [==============================] - 5s 508us/step - loss: 3.3208 - note_output_loss: 1.8816 - length_output_loss: 2.8784\n",
      "Epoch 148/1500\n",
      "10581/10581 [==============================] - 5s 497us/step - loss: 3.3081 - note_output_loss: 1.8707 - length_output_loss: 2.8747\n",
      "Epoch 149/1500\n",
      "10581/10581 [==============================] - 5s 494us/step - loss: 3.3057 - note_output_loss: 1.8675 - length_output_loss: 2.8763\n",
      "Epoch 150/1500\n",
      "10581/10581 [==============================] - 5s 494us/step - loss: 3.3037 - note_output_loss: 1.8669 - length_output_loss: 2.8736\n",
      "Epoch 151/1500\n",
      "10581/10581 [==============================] - 5s 518us/step - loss: 3.2984 - note_output_loss: 1.8623 - length_output_loss: 2.8722\n",
      "Epoch 152/1500\n",
      "10581/10581 [==============================] - 5s 488us/step - loss: 3.3014 - note_output_loss: 1.8644 - length_output_loss: 2.8740\n",
      "Epoch 153/1500\n",
      "10581/10581 [==============================] - 5s 490us/step - loss: 3.2887 - note_output_loss: 1.8525 - length_output_loss: 2.8723\n",
      "Epoch 154/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10581/10581 [==============================] - 5s 491us/step - loss: 3.2838 - note_output_loss: 1.8468 - length_output_loss: 2.8739\n",
      "Epoch 155/1500\n",
      "10581/10581 [==============================] - 5s 480us/step - loss: 3.2812 - note_output_loss: 1.8459 - length_output_loss: 2.8706\n",
      "Epoch 156/1500\n",
      "10581/10581 [==============================] - 5s 488us/step - loss: 3.2855 - note_output_loss: 1.8513 - length_output_loss: 2.8685\n",
      "Epoch 157/1500\n",
      "10581/10581 [==============================] - 5s 493us/step - loss: 3.2708 - note_output_loss: 1.8376 - length_output_loss: 2.8666\n",
      "Epoch 158/1500\n",
      "10581/10581 [==============================] - 5s 492us/step - loss: 3.2746 - note_output_loss: 1.8387 - length_output_loss: 2.8717\n",
      "Epoch 159/1500\n",
      "10581/10581 [==============================] - 5s 501us/step - loss: 3.2697 - note_output_loss: 1.8353 - length_output_loss: 2.8689\n",
      "Epoch 160/1500\n",
      "10581/10581 [==============================] - 5s 490us/step - loss: 3.2735 - note_output_loss: 1.8401 - length_output_loss: 2.8667\n",
      "Epoch 161/1500\n",
      "10581/10581 [==============================] - 5s 497us/step - loss: 3.2594 - note_output_loss: 1.8288 - length_output_loss: 2.8612\n",
      "Epoch 162/1500\n",
      "10581/10581 [==============================] - 5s 493us/step - loss: 3.2596 - note_output_loss: 1.8296 - length_output_loss: 2.8601\n",
      "Epoch 163/1500\n",
      "10581/10581 [==============================] - 6s 527us/step - loss: 3.2603 - note_output_loss: 1.8286 - length_output_loss: 2.8635\n",
      "Epoch 164/1500\n",
      "10581/10581 [==============================] - 7s 697us/step - loss: 3.2534 - note_output_loss: 1.8233 - length_output_loss: 2.8602\n",
      "Epoch 165/1500\n",
      "10581/10581 [==============================] - 7s 665us/step - loss: 3.2579 - note_output_loss: 1.8272 - length_output_loss: 2.8614\n",
      "Epoch 166/1500\n",
      "10581/10581 [==============================] - 7s 625us/step - loss: 3.2437 - note_output_loss: 1.8164 - length_output_loss: 2.8547\n",
      "Epoch 167/1500\n",
      "10581/10581 [==============================] - 7s 652us/step - loss: 3.2497 - note_output_loss: 1.8173 - length_output_loss: 2.8648\n",
      "Epoch 168/1500\n",
      "10581/10581 [==============================] - 7s 630us/step - loss: 3.2464 - note_output_loss: 1.8171 - length_output_loss: 2.8586\n",
      "Epoch 169/1500\n",
      "10581/10581 [==============================] - 7s 637us/step - loss: 3.2351 - note_output_loss: 1.8051 - length_output_loss: 2.8600\n",
      "Epoch 170/1500\n",
      "10581/10581 [==============================] - 7s 632us/step - loss: 3.2410 - note_output_loss: 1.8129 - length_output_loss: 2.8562\n",
      "Epoch 171/1500\n",
      "10581/10581 [==============================] - 7s 616us/step - loss: 3.2327 - note_output_loss: 1.8036 - length_output_loss: 2.8582\n",
      "Epoch 172/1500\n",
      "10581/10581 [==============================] - 7s 620us/step - loss: 3.2293 - note_output_loss: 1.8013 - length_output_loss: 2.8560\n",
      "Epoch 173/1500\n",
      "10581/10581 [==============================] - 7s 623us/step - loss: 3.2289 - note_output_loss: 1.8020 - length_output_loss: 2.8538\n",
      "Epoch 174/1500\n",
      "10581/10581 [==============================] - 7s 625us/step - loss: 3.2236 - note_output_loss: 1.7974 - length_output_loss: 2.8524\n",
      "Epoch 175/1500\n",
      "10581/10581 [==============================] - 7s 617us/step - loss: 3.2215 - note_output_loss: 1.7932 - length_output_loss: 2.8566\n",
      "Epoch 176/1500\n",
      "10581/10581 [==============================] - 7s 642us/step - loss: 3.2176 - note_output_loss: 1.7898 - length_output_loss: 2.8555\n",
      "Epoch 177/1500\n",
      "10581/10581 [==============================] - 8s 761us/step - loss: 3.2101 - note_output_loss: 1.7847 - length_output_loss: 2.8508\n",
      "Epoch 178/1500\n",
      "10581/10581 [==============================] - 7s 621us/step - loss: 3.2165 - note_output_loss: 1.7902 - length_output_loss: 2.8525\n",
      "Epoch 179/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 3.2046 - note_output_loss: 1.7777 - length_output_loss: 2.8537\n",
      "Epoch 180/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 3.2079 - note_output_loss: 1.7815 - length_output_loss: 2.8528\n",
      "Epoch 181/1500\n",
      "10581/10581 [==============================] - 7s 631us/step - loss: 3.2077 - note_output_loss: 1.7831 - length_output_loss: 2.8490\n",
      "Epoch 182/1500\n",
      "10581/10581 [==============================] - 7s 628us/step - loss: 3.2120 - note_output_loss: 1.7853 - length_output_loss: 2.8533\n",
      "Epoch 183/1500\n",
      "10581/10581 [==============================] - 7s 640us/step - loss: 3.1929 - note_output_loss: 1.7682 - length_output_loss: 2.8494\n",
      "Epoch 184/1500\n",
      "10581/10581 [==============================] - 7s 642us/step - loss: 3.1950 - note_output_loss: 1.7688 - length_output_loss: 2.8524\n",
      "Epoch 185/1500\n",
      "10581/10581 [==============================] - 7s 639us/step - loss: 3.1928 - note_output_loss: 1.7672 - length_output_loss: 2.8514\n",
      "Epoch 186/1500\n",
      "10581/10581 [==============================] - 7s 629us/step - loss: 3.1834 - note_output_loss: 1.7617 - length_output_loss: 2.8434\n",
      "Epoch 187/1500\n",
      "10581/10581 [==============================] - 6s 611us/step - loss: 3.1861 - note_output_loss: 1.7651 - length_output_loss: 2.8420\n",
      "Epoch 188/1500\n",
      "10581/10581 [==============================] - 7s 636us/step - loss: 3.1764 - note_output_loss: 1.7554 - length_output_loss: 2.8419\n",
      "Epoch 189/1500\n",
      "10581/10581 [==============================] - 7s 616us/step - loss: 3.1735 - note_output_loss: 1.7547 - length_output_loss: 2.8375\n",
      "Epoch 190/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 3.1787 - note_output_loss: 1.7562 - length_output_loss: 2.8450\n",
      "Epoch 191/1500\n",
      "10581/10581 [==============================] - 7s 678us/step - loss: 3.1693 - note_output_loss: 1.7479 - length_output_loss: 2.8429\n",
      "Epoch 192/1500\n",
      "10581/10581 [==============================] - 7s 625us/step - loss: 3.1784 - note_output_loss: 1.7586 - length_output_loss: 2.8396\n",
      "Epoch 193/1500\n",
      "10581/10581 [==============================] - 7s 628us/step - loss: 3.1665 - note_output_loss: 1.7468 - length_output_loss: 2.8394\n",
      "Epoch 194/1500\n",
      "10581/10581 [==============================] - 7s 634us/step - loss: 3.1587 - note_output_loss: 1.7395 - length_output_loss: 2.8384\n",
      "Epoch 195/1500\n",
      "10581/10581 [==============================] - 7s 629us/step - loss: 3.1626 - note_output_loss: 1.7403 - length_output_loss: 2.8446\n",
      "Epoch 196/1500\n",
      "10581/10581 [==============================] - 7s 635us/step - loss: 3.1616 - note_output_loss: 1.7423 - length_output_loss: 2.8386\n",
      "Epoch 197/1500\n",
      "10581/10581 [==============================] - 6s 613us/step - loss: 3.1527 - note_output_loss: 1.7338 - length_output_loss: 2.8377\n",
      "Epoch 198/1500\n",
      "10581/10581 [==============================] - 7s 629us/step - loss: 3.1499 - note_output_loss: 1.7306 - length_output_loss: 2.8387\n",
      "Epoch 199/1500\n",
      "10581/10581 [==============================] - 6s 612us/step - loss: 3.1449 - note_output_loss: 1.7239 - length_output_loss: 2.8419\n",
      "Epoch 200/1500\n",
      "10581/10581 [==============================] - 7s 634us/step - loss: 3.1512 - note_output_loss: 1.7327 - length_output_loss: 2.8371\n",
      "Epoch 201/1500\n",
      "10581/10581 [==============================] - 7s 641us/step - loss: 3.1507 - note_output_loss: 1.7300 - length_output_loss: 2.8414\n",
      "----- Generating melody after Epoch: 200\n",
      "----- diversity: 0.5\n",
      "58.0 | 0.33\n",
      "60.0 | 0.32\n",
      "62.0 | 0.65\n",
      "58.0 | 0.42\n",
      "55.0 | 0.33\n",
      "57.0 | 0.42\n",
      "53.0 | 0.7\n",
      "60.0 | 0.42\n",
      "57.0 | 0.14\n",
      "58.0 | 0.42\n",
      "55.0 | 0.93\n",
      "58.0 | 0.46\n",
      "55.0 | 0.28\n",
      "57.0 | 0.37\n",
      "53.0 | 0.6\n",
      "0 | 5.0\n",
      "62.0 | 0.74\n",
      "67.0 | 0.88\n",
      "57.0 | 0.6\n",
      "62.0 | 0.51\n",
      "62 | 0.65\n",
      "0 | 0.56\n",
      "62 | 0.42\n",
      "67 | 0.42\n",
      "67 | 0.33\n",
      "65 | 0.37\n",
      "64 | 0.42\n",
      "62 | 0.42\n",
      "60 | 0.42\n",
      "62 | 0.42\n",
      "63 | 0.33\n",
      "60 | 0.28\n",
      "57 | 0.28\n",
      "60 | 0.28\n",
      "58 | 0.42\n",
      "55 | 0.37\n",
      "50 | 0.37\n",
      "48 | 0.51\n",
      "0 | 0.98\n",
      "0 | 1.2\n",
      "65 | 0.33\n",
      "67 | 0.42\n",
      "72 | 0.42\n",
      "69 | 0.09\n",
      "65 | 0.74\n",
      "65 | 0.65\n",
      "65 | 1.8\n",
      "66 | 0.46\n",
      "65 | 0.56\n",
      "63 | 0.05\n",
      "62 | 0.65\n",
      "58 | 0.93\n",
      "0 | 2.0\n",
      "0 | 0.88\n",
      "58 | 0.46\n",
      "62 | 0.32\n",
      "60 | 0.46\n",
      "63 | 1.2\n",
      "70 | 0.42\n",
      "69 | 0.84\n",
      "65 | 1.6\n",
      "0 | 2.8\n",
      "72 | 0.7\n",
      "67 | 0.14\n",
      "69 | 1.6\n",
      "65 | 1.6\n",
      "0 | 0.14\n",
      "70 | 0.14\n",
      "67 | 0.42\n",
      "65 | 0.37\n",
      "63 | 0.28\n",
      "62 | 0.14\n",
      "60 | 0.32\n",
      "58 | 0.23\n",
      "60 | 0.28\n",
      "58 | 0.28\n",
      "62 | 0.23\n",
      "58 | 0.23\n",
      "60 | 0.23\n",
      "66 | 0.37\n",
      "65 | 0.42\n",
      "65 | 0.05\n",
      "67 | 0.46\n",
      "65 | 0.05\n",
      "66 | 0.28\n",
      "65 | 0.23\n",
      "63 | 0.37\n",
      "62 | 0.37\n",
      "60 | 0.28\n",
      "63 | 0.37\n",
      "Epoch 202/1500\n",
      "10581/10581 [==============================] - 7s 620us/step - loss: 3.1409 - note_output_loss: 1.7231 - length_output_loss: 2.8356\n",
      "Epoch 203/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10581/10581 [==============================] - 7s 662us/step - loss: 3.1412 - note_output_loss: 1.7233 - length_output_loss: 2.8357\n",
      "Epoch 204/1500\n",
      "10581/10581 [==============================] - 7s 620us/step - loss: 3.1356 - note_output_loss: 1.7207 - length_output_loss: 2.8298\n",
      "Epoch 205/1500\n",
      "10581/10581 [==============================] - 7s 615us/step - loss: 3.1339 - note_output_loss: 1.7155 - length_output_loss: 2.8367\n",
      "Epoch 206/1500\n",
      "10581/10581 [==============================] - 7s 619us/step - loss: 3.1313 - note_output_loss: 1.7155 - length_output_loss: 2.8316\n",
      "Epoch 207/1500\n",
      "10581/10581 [==============================] - 7s 620us/step - loss: 3.1202 - note_output_loss: 1.7053 - length_output_loss: 2.8299\n",
      "Epoch 208/1500\n",
      "10581/10581 [==============================] - 7s 627us/step - loss: 3.1271 - note_output_loss: 1.7102 - length_output_loss: 2.8339\n",
      "Epoch 209/1500\n",
      "10581/10581 [==============================] - 6s 607us/step - loss: 3.1215 - note_output_loss: 1.7060 - length_output_loss: 2.8310\n",
      "Epoch 210/1500\n",
      "10581/10581 [==============================] - 6s 608us/step - loss: 3.1254 - note_output_loss: 1.7090 - length_output_loss: 2.8329\n",
      "Epoch 211/1500\n",
      "10581/10581 [==============================] - 7s 619us/step - loss: 3.1172 - note_output_loss: 1.7008 - length_output_loss: 2.8329\n",
      "Epoch 212/1500\n",
      "10581/10581 [==============================] - 6s 603us/step - loss: 3.1107 - note_output_loss: 1.6954 - length_output_loss: 2.8306\n",
      "Epoch 213/1500\n",
      "10581/10581 [==============================] - 6s 605us/step - loss: 3.1108 - note_output_loss: 1.6975 - length_output_loss: 2.8265\n",
      "Epoch 214/1500\n",
      "10581/10581 [==============================] - 7s 615us/step - loss: 3.1093 - note_output_loss: 1.6948 - length_output_loss: 2.8289\n",
      "Epoch 215/1500\n",
      "10581/10581 [==============================] - 6s 613us/step - loss: 3.1043 - note_output_loss: 1.6923 - length_output_loss: 2.8241\n",
      "Epoch 216/1500\n",
      "10581/10581 [==============================] - 6s 612us/step - loss: 3.1095 - note_output_loss: 1.6954 - length_output_loss: 2.8283\n",
      "Epoch 217/1500\n",
      "10581/10581 [==============================] - 7s 630us/step - loss: 3.1059 - note_output_loss: 1.6913 - length_output_loss: 2.8291\n",
      "Epoch 218/1500\n",
      "10581/10581 [==============================] - 6s 599us/step - loss: 3.1017 - note_output_loss: 1.6891 - length_output_loss: 2.8252\n",
      "Epoch 219/1500\n",
      "10581/10581 [==============================] - 7s 637us/step - loss: 3.0914 - note_output_loss: 1.6789 - length_output_loss: 2.8251\n",
      "Epoch 220/1500\n",
      "10581/10581 [==============================] - 6s 606us/step - loss: 3.1011 - note_output_loss: 1.6868 - length_output_loss: 2.8287\n",
      "Epoch 221/1500\n",
      "10581/10581 [==============================] - 6s 614us/step - loss: 3.0915 - note_output_loss: 1.6804 - length_output_loss: 2.8222\n",
      "Epoch 222/1500\n",
      "10581/10581 [==============================] - 6s 605us/step - loss: 3.0916 - note_output_loss: 1.6782 - length_output_loss: 2.8268\n",
      "Epoch 223/1500\n",
      "10581/10581 [==============================] - 7s 618us/step - loss: 3.0880 - note_output_loss: 1.6781 - length_output_loss: 2.8198\n",
      "Epoch 224/1500\n",
      "10581/10581 [==============================] - 7s 619us/step - loss: 3.0834 - note_output_loss: 1.6711 - length_output_loss: 2.8245\n",
      "Epoch 225/1500\n",
      "10581/10581 [==============================] - 7s 638us/step - loss: 3.0886 - note_output_loss: 1.6767 - length_output_loss: 2.8236\n",
      "Epoch 226/1500\n",
      "10581/10581 [==============================] - 7s 692us/step - loss: 3.0895 - note_output_loss: 1.6779 - length_output_loss: 2.8232\n",
      "Epoch 227/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 3.0884 - note_output_loss: 1.6756 - length_output_loss: 2.8256\n",
      "Epoch 228/1500\n",
      "10581/10581 [==============================] - 7s 632us/step - loss: 3.0760 - note_output_loss: 1.6655 - length_output_loss: 2.8209\n",
      "Epoch 229/1500\n",
      "10581/10581 [==============================] - 7s 644us/step - loss: 3.0751 - note_output_loss: 1.6665 - length_output_loss: 2.8171\n",
      "Epoch 230/1500\n",
      "10581/10581 [==============================] - 7s 637us/step - loss: 3.0716 - note_output_loss: 1.6611 - length_output_loss: 2.8211\n",
      "Epoch 231/1500\n",
      "10581/10581 [==============================] - 7s 641us/step - loss: 3.0668 - note_output_loss: 1.6577 - length_output_loss: 2.8182\n",
      "Epoch 232/1500\n",
      "10581/10581 [==============================] - 7s 640us/step - loss: 3.0682 - note_output_loss: 1.6568 - length_output_loss: 2.8229\n",
      "Epoch 233/1500\n",
      "10581/10581 [==============================] - 7s 631us/step - loss: 3.0646 - note_output_loss: 1.6552 - length_output_loss: 2.8189\n",
      "Epoch 234/1500\n",
      "10581/10581 [==============================] - 6s 611us/step - loss: 3.0661 - note_output_loss: 1.6575 - length_output_loss: 2.8172\n",
      "Epoch 235/1500\n",
      "10581/10581 [==============================] - 7s 702us/step - loss: 3.0640 - note_output_loss: 1.6548 - length_output_loss: 2.8184\n",
      "Epoch 236/1500\n",
      "10581/10581 [==============================] - 10s 944us/step - loss: 3.0568 - note_output_loss: 1.6479 - length_output_loss: 2.8178\n",
      "Epoch 237/1500\n",
      "10581/10581 [==============================] - 10s 919us/step - loss: 3.0571 - note_output_loss: 1.6507 - length_output_loss: 2.8129\n",
      "Epoch 238/1500\n",
      "10581/10581 [==============================] - 9s 883us/step - loss: 3.0458 - note_output_loss: 1.6395 - length_output_loss: 2.8126\n",
      "Epoch 239/1500\n",
      "10581/10581 [==============================] - 9s 871us/step - loss: 3.0539 - note_output_loss: 1.6456 - length_output_loss: 2.8166\n",
      "Epoch 240/1500\n",
      "10581/10581 [==============================] - 9s 861us/step - loss: 3.0494 - note_output_loss: 1.6437 - length_output_loss: 2.8114\n",
      "Epoch 241/1500\n",
      "10581/10581 [==============================] - 9s 854us/step - loss: 3.0333 - note_output_loss: 1.6294 - length_output_loss: 2.8076\n",
      "Epoch 242/1500\n",
      "10581/10581 [==============================] - 7s 702us/step - loss: 3.0446 - note_output_loss: 1.6371 - length_output_loss: 2.8150\n",
      "Epoch 243/1500\n",
      "10581/10581 [==============================] - 7s 676us/step - loss: 3.0425 - note_output_loss: 1.6356 - length_output_loss: 2.8138\n",
      "Epoch 244/1500\n",
      "10581/10581 [==============================] - 7s 616us/step - loss: 3.0341 - note_output_loss: 1.6297 - length_output_loss: 2.8087\n",
      "Epoch 245/1500\n",
      "10581/10581 [==============================] - 6s 609us/step - loss: 3.0357 - note_output_loss: 1.6318 - length_output_loss: 2.8080\n",
      "Epoch 246/1500\n",
      "10581/10581 [==============================] - 7s 632us/step - loss: 3.0370 - note_output_loss: 1.6324 - length_output_loss: 2.8093\n",
      "Epoch 247/1500\n",
      "10581/10581 [==============================] - 7s 656us/step - loss: 3.0330 - note_output_loss: 1.6270 - length_output_loss: 2.8120\n",
      "Epoch 248/1500\n",
      "10581/10581 [==============================] - 7s 672us/step - loss: 3.0328 - note_output_loss: 1.6272 - length_output_loss: 2.8113\n",
      "Epoch 249/1500\n",
      "10581/10581 [==============================] - 7s 652us/step - loss: 3.0313 - note_output_loss: 1.6267 - length_output_loss: 2.8092\n",
      "Epoch 250/1500\n",
      "10581/10581 [==============================] - 7s 647us/step - loss: 3.0117 - note_output_loss: 1.6084 - length_output_loss: 2.8067\n",
      "Epoch 251/1500\n",
      "10581/10581 [==============================] - 7s 636us/step - loss: 3.0140 - note_output_loss: 1.6101 - length_output_loss: 2.8078\n",
      "Epoch 252/1500\n",
      "10581/10581 [==============================] - 8s 724us/step - loss: 3.0252 - note_output_loss: 1.6217 - length_output_loss: 2.8071\n",
      "Epoch 253/1500\n",
      "10581/10581 [==============================] - 7s 664us/step - loss: 3.0183 - note_output_loss: 1.6139 - length_output_loss: 2.8088\n",
      "Epoch 254/1500\n",
      "10581/10581 [==============================] - 7s 624us/step - loss: 3.0129 - note_output_loss: 1.6088 - length_output_loss: 2.8083\n",
      "Epoch 255/1500\n",
      "10581/10581 [==============================] - 7s 679us/step - loss: 3.0136 - note_output_loss: 1.6106 - length_output_loss: 2.8060\n",
      "Epoch 256/1500\n",
      "10581/10581 [==============================] - 8s 709us/step - loss: 3.0123 - note_output_loss: 1.6092 - length_output_loss: 2.8061\n",
      "Epoch 257/1500\n",
      "10581/10581 [==============================] - 7s 659us/step - loss: 2.9948 - note_output_loss: 1.5936 - length_output_loss: 2.8024\n",
      "Epoch 258/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10581/10581 [==============================] - 7s 651us/step - loss: 3.0068 - note_output_loss: 1.6052 - length_output_loss: 2.8032\n",
      "Epoch 259/1500\n",
      "10581/10581 [==============================] - 7s 621us/step - loss: 3.0065 - note_output_loss: 1.6037 - length_output_loss: 2.8057\n",
      "Epoch 260/1500\n",
      "10581/10581 [==============================] - 7s 624us/step - loss: 3.0036 - note_output_loss: 1.6026 - length_output_loss: 2.8020\n",
      "Epoch 261/1500\n",
      "10581/10581 [==============================] - 7s 626us/step - loss: 2.9974 - note_output_loss: 1.5940 - length_output_loss: 2.8069\n",
      "Epoch 262/1500\n",
      "10581/10581 [==============================] - 7s 644us/step - loss: 3.0060 - note_output_loss: 1.6039 - length_output_loss: 2.8042\n",
      "Epoch 263/1500\n",
      "10581/10581 [==============================] - 7s 616us/step - loss: 2.9932 - note_output_loss: 1.5918 - length_output_loss: 2.8028\n",
      "Epoch 264/1500\n",
      "10581/10581 [==============================] - 7s 619us/step - loss: 2.9956 - note_output_loss: 1.5917 - length_output_loss: 2.8078\n",
      "Epoch 265/1500\n",
      " 4096/10581 [==========>...................] - ETA: 4s - loss: 2.9721 - note_output_loss: 1.5731 - length_output_loss: 2.7979"
     ]
    }
   ],
   "source": [
    "logger('TRAINING')\n",
    "model.fit([note_x, note_name_x, interval_x, length_x], [note_y, length_y],\n",
    "          batch_size=batch_size,\n",
    "          epochs=1500,\n",
    "          callbacks=[\n",
    "              listen_callback,\n",
    "#               tensorboard,\n",
    "            ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_16.json and model_16.h5 to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'model_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
