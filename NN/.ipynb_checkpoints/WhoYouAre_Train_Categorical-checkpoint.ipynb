{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from numpy import concatenate, array, asarray\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.core import Activation\n",
    "from keras.callbacks import ReduceLROnPlateau, LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from TimeSeriesModel import TimeSeriesModel\n",
    "from MidiPlayer import MidiPlayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 128\n",
    "n_features = 2\n",
    "n_train_hours = None\n",
    "n_divisions = 4\n",
    "batch_size = n_hours\n",
    "epochs = 100\n",
    "player = MidiPlayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('music_data.csv', header=0)\n",
    "values = dataset.values\n",
    "values = values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify columns to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [0, 1]\n",
    "i = 1\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert series to supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = read_csv('music_data.csv', header=1)\n",
    "n_train_hours = int(len(dataset) * 0.75)\n",
    "values = dataset.values\n",
    "values = values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    start = time.time()\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(values)\n",
    "scaled = scaler.transform(values)\n",
    "print(scaled[20:21])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = reframed.values\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[:, :n_obs]\n",
    "# print(train_X)\n",
    "\n",
    "train_y_notes = train[:, -n_features]\n",
    "train_y_volume = train[:, -n_features -1]\n",
    "\n",
    "test_X = test[:, :n_obs]\n",
    "# print(test_X)\n",
    "test_y_notes = test[:, -n_features]\n",
    "test_y_volume = test[:, -n_features -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "# print(train_X[0:10])\n",
    "\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y_notes.shape, test_X.shape, test_y_notes.shape)\n",
    "print(test_X[0:1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visible = Input(name='input', shape=(n_hours, n_features))\n",
    "ts_model = TimeSeriesModel(visible, n_hours, n_features, n_divisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ts_model.model()\n",
    "\n",
    "output_notes = Dense(1, activation='sigmoid', name='output_notes')(model)\n",
    "output_volume = Dense(1, activation='sigmoid', name='output_volume')(model)\n",
    "# output_length = Dense(1, activation='sigmoid', name='output_length')(hidden_Z)\n",
    "\n",
    "model = Model(inputs=[visible], outputs=[\n",
    "                                         output_notes, \n",
    "                                         output_volume, \n",
    "#                                          output_length\n",
    "                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mae', optimizer=optimizer)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cache = dataset.values[30:n_hours + 30].tolist()\n",
    "test_data = test_cache.copy()\n",
    "array_to_play = test_cache.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(testx):\n",
    "    testx = DataFrame(data = testx)\n",
    "    testx = testx.values\n",
    "    testx = testx.astype('float32')\n",
    "    testx = scaler.transform(testx)\n",
    "    return(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    global test_cache\n",
    "    global test_data\n",
    "    global array_to_play\n",
    "#     if epoch % 5 == 0:\n",
    "    start = time.time()\n",
    "    print('----- Generating sound after: %d' % epoch)\n",
    "    for i in range(500):\n",
    "        data = process_data(test_data)\n",
    "        data = data.reshape(1,n_hours,2)\n",
    "        prediction = model.predict(data)\n",
    "        prediction = asarray(prediction).ravel().reshape(-1,n_features)\n",
    "        prediction = scaler.inverse_transform(prediction)\n",
    "        prediction = prediction.astype('int')\n",
    "        prediction = prediction[0].tolist()\n",
    "        test_data.append(prediction)\n",
    "        test_data.pop(0)\n",
    "        array_to_play.append(prediction)\n",
    "    end = time.time()\n",
    "    print('time:', end - start)\n",
    "    print('len array_to_play', len(array_to_play))\n",
    "    print(array_to_play)\n",
    "    for value in array_to_play:\n",
    "        player.play(value[0], .03, value[1])\n",
    "    test_data = test_cache.copy()\n",
    "    array_to_play = test_cache.copy()\n",
    "\n",
    "    \n",
    "play_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "            {'input': train_X},\n",
    "            {\n",
    "                'output_notes': train_y_notes, \n",
    "                'output_volume': train_y_volume, \n",
    "            },\n",
    "            validation_data=({'input': test_X},\n",
    "                             {\n",
    "                                 'output_notes': test_y_notes, \n",
    "                                 'output_volume': test_y_volume, \n",
    "                             }), \n",
    "            verbose=1,\n",
    "            shuffle=False,\n",
    "            epochs=epochs, \n",
    "            batch_size=int(batch_size),\n",
    "            callbacks=[play_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print('Saved scaler to disk.')\n",
    "frame as supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
